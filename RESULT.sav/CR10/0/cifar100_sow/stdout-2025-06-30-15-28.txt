============================================================================================================
Arguments =
	approach: sow
	batch_size: 64
	clipping: 1.0
	datasets: ['cifar100']
	eval_on_train: True
	exp_name: None
	fix_bn: True
	gpu: 1
	gridsearch_tasks: -1
	keep_existing_head: False
	last_layer_analysis: False
	log: ['disk']
	lr: 0.0263039750973134
	lr_factor: 3.0
	lr_first: None
	lr_min: 1e-05
	lr_patience: 30
	momentum: 0.9
	multi_softmax: True
	nc_first_task: None
	nepochs: 100
	network: resnet50_32sow
	no_cudnn_deterministic: False
	num_tasks: 10
	num_workers: 4
	pin_memory: True
	pretrained: False
	results_path: ../RESULT_AAAI2025/CR10/0
	save_models: True
	seed: 0
	stop_at_task: 0
	validation: 0.1
	warmup_lr_factor: 1.0
	warmup_nepochs: 0
	weight_decay: 0.0
============================================================================================================
	device: cuda:1
============================================================================================================
Network arguments =
	dropout: 0.417598542370663
	fix_features: True
	load_features: True
	pretrained_path: ../Conv-Model/ResNet50-TinyImageNet.pt
============================================================================================================
../src/networks/INIT/1024.dict: loading..
  ptbl: torch.Size([1047552]) torch.int32 cuda:1
  ranks: tensor([   1,    2,    3,    4,    6,    8,   12,   16,   24,   32,   48,   64,
          96,  128,  192,  256,  384,  512,  768, 1024], device='cuda:1',
       dtype=torch.int32)
  ttbl: torch.Size([10475520]) torch.int32 cuda:1
  S_max: tensor(1000., device='cuda:1', dtype=torch.float64)
  a: torch.Size([1024]) torch.float64 cuda:1
  tan_2phi: torch.Size([523776]) torch.float64 cuda:1
  tan_2theta: torch.Size([523776]) torch.float64 cuda:1
../src/networks/INIT/1024.dict: loading..
ResNet50_32SOW,__init__: features is loaded (../Conv-Model/ResNet50-TinyImageNet.pt)
Fix_Features: Done
Approach arguments =
	acc_margin: 0.004
	all_outputs: False
	loss_margin: 0.006
	sow_lr: 0.05
	sow_mo: 0.9
============================================================================================================
Exemplars dataset arguments =
	exemplar_selection: random
	num_exemplars: 0
	num_exemplars_per_class: 0
============================================================================================================
class_indices: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
[(0, 10), (1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10), (8, 10), (9, 10)]
************************************************************************************************************
Task  0
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=True, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  3.4s/  1.9s | Train: loss=1.371, TAw acc= 53.6% | Valid: time=  0.4s loss=1.088, TAw acc= 59.4% | *
| Epoch   2, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.276, TAw acc= 57.5% | Valid: time=  0.4s loss=0.876, TAw acc= 70.0% | *
| Epoch   3, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.191, TAw acc= 59.1% | Valid: time=  0.4s loss=0.825, TAw acc= 70.0% | *
| Epoch   4, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.227, TAw acc= 56.7% | Valid: time=  0.4s loss=0.820, TAw acc= 70.8% | *
| Epoch   5, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.144, TAw acc= 62.4% | Valid: time=  0.4s loss=0.815, TAw acc= 72.2% | *
| Epoch   6, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.141, TAw acc= 62.2% | Valid: time=  0.4s loss=0.770, TAw acc= 72.6% | *
| Epoch   7, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.181, TAw acc= 60.5% | Valid: time=  0.4s loss=0.743, TAw acc= 75.2% | *
| Epoch   8, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.139, TAw acc= 61.4% | Valid: time=  0.4s loss=0.770, TAw acc= 74.4% |
| Epoch   9, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.121, TAw acc= 62.1% | Valid: time=  0.4s loss=0.758, TAw acc= 73.4% |
| Epoch  10, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.170, TAw acc= 60.1% | Valid: time=  0.4s loss=0.906, TAw acc= 70.0% |
| Epoch  11, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.082, TAw acc= 64.4% | Valid: time=  0.4s loss=0.712, TAw acc= 73.8% | *
| Epoch  12, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.126, TAw acc= 61.2% | Valid: time=  0.4s loss=0.779, TAw acc= 72.4% |
| Epoch  13, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.112, TAw acc= 63.1% | Valid: time=  0.4s loss=0.760, TAw acc= 73.8% |
| Epoch  14, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.078, TAw acc= 64.2% | Valid: time=  0.4s loss=0.724, TAw acc= 73.0% |
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.086, TAw acc= 63.6% | Valid: time=  0.4s loss=0.743, TAw acc= 75.2% |
| Epoch  16, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.069, TAw acc= 64.4% | Valid: time=  0.4s loss=0.693, TAw acc= 75.6% | *
| Epoch  17, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.020, TAw acc= 65.6% | Valid: time=  0.4s loss=0.767, TAw acc= 74.4% |
| Epoch  18, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.028, TAw acc= 65.0% | Valid: time=  0.4s loss=0.665, TAw acc= 77.4% | *
| Epoch  19, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.062, TAw acc= 63.9% | Valid: time=  0.4s loss=0.689, TAw acc= 75.6% |
| Epoch  20, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.033, TAw acc= 65.2% | Valid: time=  0.4s loss=0.805, TAw acc= 70.8% |
| Epoch  21, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.058, TAw acc= 64.9% | Valid: time=  0.4s loss=0.729, TAw acc= 74.4% |
| Epoch  22, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.036, TAw acc= 64.7% | Valid: time=  0.4s loss=0.618, TAw acc= 79.4% | *
| Epoch  23, lr=2.6e-02 time=  3.0s/  1.9s | Train: loss=1.022, TAw acc= 67.2% | Valid: time=  0.4s loss=0.707, TAw acc= 75.8% |
| Epoch  24, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.027, TAw acc= 65.3% | Valid: time=  0.4s loss=0.687, TAw acc= 75.6% |
| Epoch  25, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.026, TAw acc= 65.8% | Valid: time=  0.4s loss=0.639, TAw acc= 78.0% |
| Epoch  26, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.004, TAw acc= 66.8% | Valid: time=  0.4s loss=0.698, TAw acc= 76.2% |
| Epoch  27, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.027, TAw acc= 65.8% | Valid: time=  0.4s loss=0.757, TAw acc= 73.2% |
| Epoch  28, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.049, TAw acc= 65.7% | Valid: time=  0.4s loss=0.644, TAw acc= 79.4% |
| Epoch  29, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.025, TAw acc= 66.0% | Valid: time=  0.4s loss=0.693, TAw acc= 74.4% |
| Epoch  30, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.009, TAw acc= 66.7% | Valid: time=  0.4s loss=0.711, TAw acc= 75.6% |
| Epoch  31, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=0.992, TAw acc= 67.0% | Valid: time=  0.4s loss=0.660, TAw acc= 77.8% |
| Epoch  32, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.011, TAw acc= 66.0% | Valid: time=  0.4s loss=0.660, TAw acc= 77.6% |
| Epoch  33, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.978, TAw acc= 66.4% | Valid: time=  0.4s loss=0.697, TAw acc= 74.8% |
| Epoch  34, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.070, TAw acc= 62.9% | Valid: time=  0.4s loss=0.687, TAw acc= 75.8% |
| Epoch  35, lr=2.6e-02 time=  3.0s/  1.8s | Train: loss=1.018, TAw acc= 65.2% | Valid: time=  0.4s loss=0.735, TAw acc= 75.4% |
| Epoch  36, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.023, TAw acc= 65.0% | Valid: time=  0.4s loss=0.682, TAw acc= 77.6% |
| Epoch  37, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.029, TAw acc= 64.1% | Valid: time=  0.4s loss=0.728, TAw acc= 74.6% |
| Epoch  38, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.981, TAw acc= 66.4% | Valid: time=  0.4s loss=0.681, TAw acc= 75.8% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.995, TAw acc= 65.1% | Valid: time=  0.4s loss=0.726, TAw acc= 74.0% |
| Epoch  40, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.018, TAw acc= 66.6% | Valid: time=  0.4s loss=0.632, TAw acc= 77.4% |
| Epoch  41, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.992, TAw acc= 67.0% | Valid: time=  0.4s loss=0.663, TAw acc= 77.0% |
| Epoch  42, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.014, TAw acc= 66.0% | Valid: time=  0.4s loss=0.662, TAw acc= 77.8% |
| Epoch  43, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.030, TAw acc= 64.6% | Valid: time=  0.4s loss=0.756, TAw acc= 75.0% |
| Epoch  44, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.008, TAw acc= 67.6% | Valid: time=  0.4s loss=0.725, TAw acc= 75.0% |
| Epoch  45, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.035, TAw acc= 65.3% | Valid: time=  0.4s loss=0.664, TAw acc= 77.0% |
| Epoch  46, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=1.068, TAw acc= 62.9% | Valid: time=  0.4s loss=0.754, TAw acc= 72.8% |
| Epoch  47, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.987, TAw acc= 67.5% | Valid: time=  0.4s loss=0.677, TAw acc= 78.6% |
| Epoch  48, lr=2.6e-02 time=  3.0s/  1.9s | Train: loss=0.967, TAw acc= 67.5% | Valid: time=  0.4s loss=0.637, TAw acc= 77.2% |
| Epoch  49, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.979, TAw acc= 68.5% | Valid: time=  0.4s loss=0.695, TAw acc= 77.0% |
| Epoch  50, lr=2.6e-02 time=  2.9s/  1.8s | Train: loss=0.971, TAw acc= 66.7% | Valid: time=  0.4s loss=0.652, TAw acc= 77.2% |
| Epoch  51, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.028, TAw acc= 65.2% | Valid: time=  0.4s loss=0.623, TAw acc= 79.6% |
| Epoch  52, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.957, TAw acc= 68.2% | Valid: time=  0.4s loss=0.623, TAw acc= 78.8% | lr=8.8e-03
| Epoch  53, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=1.015, TAw acc= 65.8% | Valid: time=  0.4s loss=0.665, TAw acc= 76.4% |
| Epoch  54, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.129, TAw acc= 61.5% | Valid: time=  0.4s loss=0.791, TAw acc= 73.2% |
| Epoch  55, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.046, TAw acc= 65.0% | Valid: time=  0.4s loss=0.698, TAw acc= 75.6% |
| Epoch  56, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=1.046, TAw acc= 64.7% | Valid: time=  0.4s loss=0.675, TAw acc= 76.6% |
| Epoch  57, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=1.024, TAw acc= 65.0% | Valid: time=  0.4s loss=0.754, TAw acc= 72.2% |
| Epoch  58, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.019, TAw acc= 65.3% | Valid: time=  0.4s loss=0.680, TAw acc= 76.2% |
| Epoch  59, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.007, TAw acc= 66.4% | Valid: time=  0.4s loss=0.650, TAw acc= 77.8% |
| Epoch  60, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.974, TAw acc= 67.1% | Valid: time=  0.4s loss=0.704, TAw acc= 75.2% |
| Epoch  61, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.966, TAw acc= 68.1% | Valid: time=  0.4s loss=0.684, TAw acc= 76.6% |
| Epoch  62, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.012, TAw acc= 65.2% | Valid: time=  0.4s loss=0.638, TAw acc= 78.8% |
| Epoch  63, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.986, TAw acc= 67.8% | Valid: time=  0.4s loss=0.666, TAw acc= 77.2% |
| Epoch  64, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.002, TAw acc= 66.3% | Valid: time=  0.4s loss=0.659, TAw acc= 77.2% |
| Epoch  65, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.978, TAw acc= 67.9% | Valid: time=  0.4s loss=0.653, TAw acc= 76.2% |
| Epoch  66, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.984, TAw acc= 67.5% | Valid: time=  0.4s loss=0.648, TAw acc= 77.4% |
| Epoch  67, lr=8.8e-03 time=  3.0s/  1.9s | Train: loss=0.995, TAw acc= 67.5% | Valid: time=  0.4s loss=0.723, TAw acc= 75.6% |
| Epoch  68, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.006, TAw acc= 65.2% | Valid: time=  0.4s loss=0.763, TAw acc= 74.8% |
| Epoch  69, lr=8.8e-03 time=  3.0s/  1.9s | Train: loss=0.993, TAw acc= 66.6% | Valid: time=  0.4s loss=0.678, TAw acc= 76.4% |
| Epoch  70, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.966, TAw acc= 67.8% | Valid: time=  0.4s loss=0.664, TAw acc= 77.2% |
| Epoch  71, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.987, TAw acc= 66.6% | Valid: time=  0.4s loss=0.684, TAw acc= 74.8% |
| Epoch  72, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.983, TAw acc= 67.0% | Valid: time=  0.4s loss=0.665, TAw acc= 76.4% |
| Epoch  73, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.961, TAw acc= 68.4% | Valid: time=  0.4s loss=0.654, TAw acc= 76.4% |
| Epoch  74, lr=8.8e-03 time=  3.0s/  1.8s | Train: loss=1.005, TAw acc= 66.5% | Valid: time=  0.4s loss=0.613, TAw acc= 79.2% | *
| Epoch  75, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.961, TAw acc= 67.7% | Valid: time=  0.4s loss=0.658, TAw acc= 77.2% |
| Epoch  76, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.977, TAw acc= 67.2% | Valid: time=  0.4s loss=0.674, TAw acc= 75.6% |
| Epoch  77, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.971, TAw acc= 66.9% | Valid: time=  0.4s loss=0.672, TAw acc= 75.6% |
| Epoch  78, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=1.008, TAw acc= 66.2% | Valid: time=  0.4s loss=0.616, TAw acc= 78.6% |
| Epoch  79, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.921, TAw acc= 69.6% | Valid: time=  0.4s loss=0.706, TAw acc= 76.0% |
| Epoch  80, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.970, TAw acc= 67.5% | Valid: time=  0.4s loss=0.685, TAw acc= 75.8% |
| Epoch  81, lr=8.8e-03 time=  3.0s/  1.8s | Train: loss=0.962, TAw acc= 67.4% | Valid: time=  0.4s loss=0.667, TAw acc= 76.0% |
| Epoch  82, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.948, TAw acc= 68.0% | Valid: time=  0.4s loss=0.651, TAw acc= 77.6% |
| Epoch  83, lr=8.8e-03 time=  3.0s/  1.9s | Train: loss=0.970, TAw acc= 67.0% | Valid: time=  0.4s loss=0.726, TAw acc= 75.2% |
| Epoch  84, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.959, TAw acc= 67.6% | Valid: time=  0.4s loss=0.704, TAw acc= 76.2% |
| Epoch  85, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.945, TAw acc= 69.7% | Valid: time=  0.4s loss=0.718, TAw acc= 76.4% |
| Epoch  86, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.990, TAw acc= 66.2% | Valid: time=  0.4s loss=0.583, TAw acc= 79.2% | *
| Epoch  87, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.972, TAw acc= 67.5% | Valid: time=  0.4s loss=0.657, TAw acc= 77.6% |
| Epoch  88, lr=8.8e-03 time=  3.0s/  1.8s | Train: loss=0.952, TAw acc= 67.8% | Valid: time=  0.4s loss=0.605, TAw acc= 78.6% |
| Epoch  89, lr=8.8e-03 time=  2.9s/  1.8s | Train: loss=0.962, TAw acc= 66.9% | Valid: time=  0.4s loss=0.743, TAw acc= 73.6% |
| Epoch  90, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.969, TAw acc= 67.0% | Valid: time=  0.4s loss=0.692, TAw acc= 75.6% |
| Epoch  91, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.970, TAw acc= 67.2% | Valid: time=  0.4s loss=0.628, TAw acc= 78.6% |
| Epoch  92, lr=8.8e-03 time=  3.0s/  1.9s | Train: loss=0.941, TAw acc= 68.4% | Valid: time=  0.4s loss=0.670, TAw acc= 76.2% |
| Epoch  93, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.946, TAw acc= 68.0% | Valid: time=  0.4s loss=0.681, TAw acc= 75.8% |
| Epoch  94, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.984, TAw acc= 66.3% | Valid: time=  0.4s loss=0.715, TAw acc= 74.8% |
| Epoch  95, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.933, TAw acc= 69.6% | Valid: time=  0.4s loss=0.644, TAw acc= 77.2% |
| Epoch  96, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.959, TAw acc= 68.2% | Valid: time=  0.4s loss=0.596, TAw acc= 78.0% |
| Epoch  97, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.929, TAw acc= 68.9% | Valid: time=  0.4s loss=0.726, TAw acc= 74.6% |
| Epoch  98, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.005, TAw acc= 65.1% | Valid: time=  0.4s loss=0.691, TAw acc= 77.0% |
| Epoch  99, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.938, TAw acc= 68.6% | Valid: time=  0.4s loss=0.636, TAw acc= 78.2% |
| Epoch 100, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.891, TAw acc= 71.1% | Valid: time=  0.4s loss=0.591, TAw acc= 80.0% |
== Rank Reduction [task:0] ==
best_loss=0.583,  best_acc=0.792
 r=256, loss=0.603, acc=0.788
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.596, acc=0.790
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.576, acc=0.802
 loss_margin=0.006, acc_margin=0.004
best_r=320, loss=0.576, acc=0.802
== Header Training for Low Rank [task:0] ==
loss=0.576 acc=0.802
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.935, TAw acc= 69.4% | Valid: time=  0.4s loss=0.632, TAw acc= 78.8% |
| Epoch   2, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.932, TAw acc= 69.3% | Valid: time=  0.4s loss=0.627, TAw acc= 78.6% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.919, TAw acc= 69.3% | Valid: time=  0.4s loss=0.603, TAw acc= 80.6% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.882, TAw acc= 70.9% | Valid: time=  0.4s loss=0.612, TAw acc= 80.4% |
| Epoch   5, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.910, TAw acc= 69.5% | Valid: time=  0.4s loss=0.605, TAw acc= 81.2% |
| Epoch   6, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.898, TAw acc= 69.8% | Valid: time=  0.4s loss=0.658, TAw acc= 77.8% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 70.3% | Valid: time=  0.4s loss=0.620, TAw acc= 80.6% |
| Epoch   8, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.860, TAw acc= 71.0% | Valid: time=  0.4s loss=0.613, TAw acc= 79.6% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.905, TAw acc= 69.7% | Valid: time=  0.4s loss=0.621, TAw acc= 79.6% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.909, TAw acc= 69.4% | Valid: time=  0.4s loss=0.652, TAw acc= 77.2% |
| Epoch  11, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.877, TAw acc= 71.2% | Valid: time=  0.4s loss=0.625, TAw acc= 80.0% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 70.5% | Valid: time=  0.4s loss=0.615, TAw acc= 79.2% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.838, TAw acc= 72.2% | Valid: time=  0.4s loss=0.629, TAw acc= 80.2% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 71.2% | Valid: time=  0.4s loss=0.629, TAw acc= 79.0% |
| Epoch  15, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.844, TAw acc= 72.3% | Valid: time=  0.4s loss=0.643, TAw acc= 78.6% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 71.7% | Valid: time=  0.4s loss=0.623, TAw acc= 80.0% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.852, TAw acc= 71.7% | Valid: time=  0.4s loss=0.625, TAw acc= 80.4% |
| Epoch  18, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.849, TAw acc= 71.6% | Valid: time=  0.4s loss=0.617, TAw acc= 80.6% |
| Epoch  19, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.838, TAw acc= 71.9% | Valid: time=  0.4s loss=0.622, TAw acc= 79.0% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.824, TAw acc= 72.1% | Valid: time=  0.4s loss=0.644, TAw acc= 79.0% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.831, TAw acc= 72.1% | Valid: time=  0.4s loss=0.622, TAw acc= 79.8% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.850, TAw acc= 71.7% | Valid: time=  0.4s loss=0.607, TAw acc= 80.6% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.8s | Train: loss=0.842, TAw acc= 71.8% | Valid: time=  0.4s loss=0.634, TAw acc= 78.8% |
| Epoch  24, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.805, TAw acc= 72.9% | Valid: time=  0.4s loss=0.642, TAw acc= 79.8% |
| Epoch  25, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.830, TAw acc= 72.2% | Valid: time=  0.4s loss=0.627, TAw acc= 79.6% |
| Epoch  26, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.810, TAw acc= 72.6% | Valid: time=  0.4s loss=0.636, TAw acc= 78.8% |
| Epoch  27, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.829, TAw acc= 72.6% | Valid: time=  0.4s loss=0.614, TAw acc= 80.0% |
| Epoch  28, lr=8.8e-03 time=  1.6s/  1.8s | Train: loss=0.833, TAw acc= 71.4% | Valid: time=  0.4s loss=0.650, TAw acc= 79.6% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.820, TAw acc= 72.6% | Valid: time=  0.4s loss=0.617, TAw acc= 80.2% |
| Epoch  30, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=0.825, TAw acc= 72.4% | Valid: time=  0.4s loss=0.637, TAw acc= 79.2% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.4% | Valid: time=  0.4s loss=0.628, TAw acc= 79.8% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.8s | Train: loss=0.937, TAw acc= 69.1% | Valid: time=  0.4s loss=0.632, TAw acc= 79.0% |
| Epoch  33, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.933, TAw acc= 69.7% | Valid: time=  0.4s loss=0.631, TAw acc= 78.8% |
| Epoch  34, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.931, TAw acc= 69.6% | Valid: time=  0.4s loss=0.618, TAw acc= 80.0% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.8s | Train: loss=0.924, TAw acc= 69.5% | Valid: time=  0.4s loss=0.627, TAw acc= 79.8% |
| Epoch  36, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.919, TAw acc= 70.2% | Valid: time=  0.4s loss=0.624, TAw acc= 79.4% |
| Epoch  37, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.921, TAw acc= 69.6% | Valid: time=  0.4s loss=0.621, TAw acc= 78.6% |
| Epoch  38, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.899, TAw acc= 70.3% | Valid: time=  0.4s loss=0.618, TAw acc= 79.4% |
| Epoch  39, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.912, TAw acc= 70.2% | Valid: time=  0.4s loss=0.608, TAw acc= 79.6% |
| Epoch  40, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.903, TAw acc= 70.0% | Valid: time=  0.4s loss=0.610, TAw acc= 79.2% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.906, TAw acc= 70.3% | Valid: time=  0.4s loss=0.609, TAw acc= 79.6% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 70.0% | Valid: time=  0.4s loss=0.609, TAw acc= 80.4% |
| Epoch  43, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.902, TAw acc= 70.5% | Valid: time=  0.4s loss=0.634, TAw acc= 78.0% |
| Epoch  44, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.886, TAw acc= 70.2% | Valid: time=  0.4s loss=0.611, TAw acc= 80.4% |
| Epoch  45, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.879, TAw acc= 71.0% | Valid: time=  0.4s loss=0.618, TAw acc= 79.6% |
| Epoch  46, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.887, TAw acc= 70.3% | Valid: time=  0.4s loss=0.620, TAw acc= 79.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.8s | Train: loss=0.883, TAw acc= 70.6% | Valid: time=  0.4s loss=0.608, TAw acc= 79.6% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.865, TAw acc= 71.9% | Valid: time=  0.4s loss=0.620, TAw acc= 79.6% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 71.0% | Valid: time=  0.4s loss=0.611, TAw acc= 80.4% |
| Epoch  50, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.869, TAw acc= 71.2% | Valid: time=  0.4s loss=0.630, TAw acc= 78.2% |
| Epoch  51, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.880, TAw acc= 71.0% | Valid: time=  0.4s loss=0.624, TAw acc= 79.6% |
| Epoch  52, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.884, TAw acc= 70.6% | Valid: time=  0.4s loss=0.611, TAw acc= 81.0% |
| Epoch  53, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.875, TAw acc= 70.3% | Valid: time=  0.4s loss=0.625, TAw acc= 80.0% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.8s | Train: loss=0.874, TAw acc= 70.6% | Valid: time=  0.4s loss=0.632, TAw acc= 79.0% |
| Epoch  55, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.877, TAw acc= 71.0% | Valid: time=  0.4s loss=0.603, TAw acc= 80.8% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 70.9% | Valid: time=  0.4s loss=0.607, TAw acc= 80.4% |
| Epoch  57, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.892, TAw acc= 69.6% | Valid: time=  0.4s loss=0.610, TAw acc= 79.6% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 71.0% | Valid: time=  0.4s loss=0.609, TAw acc= 80.4% |
| Epoch  59, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.846, TAw acc= 72.8% | Valid: time=  0.4s loss=0.609, TAw acc= 80.2% |
| Epoch  60, lr=2.9e-03 time=  1.6s/  1.8s | Train: loss=0.853, TAw acc= 71.4% | Valid: time=  0.4s loss=0.610, TAw acc= 81.0% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.997, TAw acc= 66.0% | Valid: time=  0.4s loss=0.587, TAw acc= 80.0% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 67.6% | Valid: time=  0.4s loss=0.607, TAw acc= 80.8% |
| Epoch  63, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.959, TAw acc= 67.8% | Valid: time=  0.4s loss=0.620, TAw acc= 80.2% |
| Epoch  64, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.979, TAw acc= 67.0% | Valid: time=  0.4s loss=0.623, TAw acc= 80.0% |
| Epoch  65, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.954, TAw acc= 69.1% | Valid: time=  0.4s loss=0.623, TAw acc= 80.0% |
| Epoch  66, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.941, TAw acc= 69.0% | Valid: time=  0.4s loss=0.623, TAw acc= 79.0% |
| Epoch  67, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.955, TAw acc= 67.6% | Valid: time=  0.4s loss=0.628, TAw acc= 79.2% |
| Epoch  68, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.928, TAw acc= 69.7% | Valid: time=  0.4s loss=0.623, TAw acc= 79.6% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.905, TAw acc= 70.3% | Valid: time=  0.4s loss=0.625, TAw acc= 79.6% |
| Epoch  70, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.933, TAw acc= 70.2% | Valid: time=  0.4s loss=0.619, TAw acc= 80.2% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.934, TAw acc= 69.3% | Valid: time=  0.4s loss=0.619, TAw acc= 80.4% |
| Epoch  72, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.949, TAw acc= 68.5% | Valid: time=  0.4s loss=0.622, TAw acc= 79.8% |
| Epoch  73, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.926, TAw acc= 70.5% | Valid: time=  0.4s loss=0.621, TAw acc= 79.4% |
| Epoch  74, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.911, TAw acc= 69.7% | Valid: time=  0.4s loss=0.619, TAw acc= 80.6% |
| Epoch  75, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.918, TAw acc= 69.6% | Valid: time=  0.4s loss=0.616, TAw acc= 80.6% |
| Epoch  76, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.921, TAw acc= 69.7% | Valid: time=  0.4s loss=0.616, TAw acc= 80.2% |
| Epoch  77, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.936, TAw acc= 69.2% | Valid: time=  0.4s loss=0.621, TAw acc= 79.4% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.916, TAw acc= 69.8% | Valid: time=  0.4s loss=0.618, TAw acc= 79.6% |
| Epoch  79, lr=9.7e-04 time=  1.6s/  1.8s | Train: loss=0.920, TAw acc= 69.8% | Valid: time=  0.4s loss=0.616, TAw acc= 80.2% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.924, TAw acc= 70.2% | Valid: time=  0.4s loss=0.619, TAw acc= 79.8% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.919, TAw acc= 71.0% | Valid: time=  0.4s loss=0.619, TAw acc= 80.0% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.913, TAw acc= 70.1% | Valid: time=  0.4s loss=0.619, TAw acc= 79.6% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.923, TAw acc= 68.9% | Valid: time=  0.4s loss=0.622, TAw acc= 79.6% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.917, TAw acc= 69.4% | Valid: time=  0.4s loss=0.621, TAw acc= 79.6% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.936, TAw acc= 68.8% | Valid: time=  0.4s loss=0.612, TAw acc= 80.2% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.913, TAw acc= 69.4% | Valid: time=  0.4s loss=0.615, TAw acc= 80.2% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.903, TAw acc= 70.2% | Valid: time=  0.4s loss=0.614, TAw acc= 79.6% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.908, TAw acc= 70.0% | Valid: time=  0.4s loss=0.621, TAw acc= 79.6% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=0.922, TAw acc= 70.1% | Valid: time=  0.4s loss=0.612, TAw acc= 80.0% |
| Epoch  90, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.927, TAw acc= 69.6% | Valid: time=  0.4s loss=0.612, TAw acc= 80.0% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.014, TAw acc= 66.0% | Valid: time=  0.4s loss=0.575, TAw acc= 80.2% | *
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.007, TAw acc= 66.7% | Valid: time=  0.4s loss=0.579, TAw acc= 80.0% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.4% | Valid: time=  0.4s loss=0.587, TAw acc= 80.0% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.8s | Train: loss=0.965, TAw acc= 68.4% | Valid: time=  0.4s loss=0.595, TAw acc= 81.4% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.960, TAw acc= 68.2% | Valid: time=  0.4s loss=0.600, TAw acc= 81.4% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.946, TAw acc= 69.2% | Valid: time=  0.4s loss=0.605, TAw acc= 81.2% |
| Epoch  97, lr=3.2e-04 time=  1.6s/  1.9s | Train: loss=0.952, TAw acc= 69.4% | Valid: time=  0.4s loss=0.610, TAw acc= 81.4% |
| Epoch  98, lr=3.2e-04 time=  1.6s/  1.9s | Train: loss=0.952, TAw acc= 68.4% | Valid: time=  0.4s loss=0.612, TAw acc= 80.8% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.948, TAw acc= 69.0% | Valid: time=  0.4s loss=0.614, TAw acc= 80.8% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.947, TAw acc= 69.2% | Valid: time=  0.4s loss=0.615, TAw acc= 80.2% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.661 | TAw acc= 77.3%, forg=  0.0%| TAg acc= 77.3%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  1
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-1): 2 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.436, TAw acc= 50.1% | Valid: time=  0.4s loss=1.083, TAw acc= 63.0% | *
| Epoch   2, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.364, TAw acc= 53.6% | Valid: time=  0.4s loss=1.059, TAw acc= 62.8% | *
| Epoch   3, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.337, TAw acc= 53.5% | Valid: time=  0.4s loss=1.083, TAw acc= 63.8% |
| Epoch   4, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.386, TAw acc= 51.0% | Valid: time=  0.4s loss=1.079, TAw acc= 63.2% |
| Epoch   5, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.306, TAw acc= 55.8% | Valid: time=  0.4s loss=0.996, TAw acc= 65.6% | *
| Epoch   6, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.360, TAw acc= 51.4% | Valid: time=  0.4s loss=1.043, TAw acc= 63.2% |
| Epoch   7, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.265, TAw acc= 56.4% | Valid: time=  0.4s loss=1.076, TAw acc= 65.4% |
| Epoch   8, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.284, TAw acc= 55.7% | Valid: time=  0.4s loss=1.072, TAw acc= 63.0% |
| Epoch   9, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.273, TAw acc= 55.6% | Valid: time=  0.4s loss=1.001, TAw acc= 67.4% |
| Epoch  10, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.292, TAw acc= 55.5% | Valid: time=  0.4s loss=1.058, TAw acc= 65.4% |
| Epoch  11, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.258, TAw acc= 56.4% | Valid: time=  0.4s loss=1.022, TAw acc= 66.2% |
| Epoch  12, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.247, TAw acc= 56.8% | Valid: time=  0.4s loss=1.017, TAw acc= 65.2% |
| Epoch  13, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.246, TAw acc= 56.5% | Valid: time=  0.4s loss=1.076, TAw acc= 63.2% |
| Epoch  14, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.249, TAw acc= 56.0% | Valid: time=  0.4s loss=0.973, TAw acc= 66.0% | *
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.233, TAw acc= 58.0% | Valid: time=  0.4s loss=1.032, TAw acc= 65.6% |
| Epoch  16, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.263, TAw acc= 55.0% | Valid: time=  0.4s loss=1.101, TAw acc= 63.8% |
| Epoch  17, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.241, TAw acc= 58.0% | Valid: time=  0.4s loss=0.983, TAw acc= 65.4% |
| Epoch  18, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.231, TAw acc= 57.0% | Valid: time=  0.4s loss=1.067, TAw acc= 65.0% |
| Epoch  19, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.236, TAw acc= 57.0% | Valid: time=  0.4s loss=1.074, TAw acc= 63.6% |
| Epoch  20, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.237, TAw acc= 56.1% | Valid: time=  0.4s loss=0.994, TAw acc= 66.0% |
| Epoch  21, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.244, TAw acc= 57.4% | Valid: time=  0.4s loss=0.999, TAw acc= 65.4% |
| Epoch  22, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.234, TAw acc= 56.6% | Valid: time=  0.4s loss=1.001, TAw acc= 67.2% |
| Epoch  23, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.219, TAw acc= 58.8% | Valid: time=  0.4s loss=1.010, TAw acc= 63.8% |
| Epoch  24, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.227, TAw acc= 57.8% | Valid: time=  0.4s loss=1.004, TAw acc= 64.8% |
| Epoch  25, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.216, TAw acc= 57.5% | Valid: time=  0.4s loss=0.946, TAw acc= 66.4% | *
| Epoch  26, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.220, TAw acc= 57.9% | Valid: time=  0.4s loss=0.924, TAw acc= 67.6% | *
| Epoch  27, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.259, TAw acc= 57.7% | Valid: time=  0.4s loss=0.946, TAw acc= 68.6% |
| Epoch  28, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.189, TAw acc= 57.9% | Valid: time=  0.4s loss=1.034, TAw acc= 64.8% |
| Epoch  29, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.199, TAw acc= 57.2% | Valid: time=  0.4s loss=1.079, TAw acc= 67.0% |
| Epoch  30, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.182, TAw acc= 59.6% | Valid: time=  0.4s loss=1.044, TAw acc= 65.4% |
| Epoch  31, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.198, TAw acc= 58.5% | Valid: time=  0.4s loss=0.942, TAw acc= 68.0% |
| Epoch  32, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.184, TAw acc= 58.5% | Valid: time=  0.4s loss=1.059, TAw acc= 66.2% |
| Epoch  33, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.215, TAw acc= 58.8% | Valid: time=  0.4s loss=0.962, TAw acc= 67.2% |
| Epoch  34, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.225, TAw acc= 56.8% | Valid: time=  0.4s loss=1.033, TAw acc= 65.2% |
| Epoch  35, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.185, TAw acc= 59.2% | Valid: time=  0.4s loss=1.089, TAw acc= 65.2% |
| Epoch  36, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.197, TAw acc= 57.8% | Valid: time=  0.4s loss=1.056, TAw acc= 66.8% |
| Epoch  37, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.202, TAw acc= 58.5% | Valid: time=  0.4s loss=0.998, TAw acc= 65.8% |
| Epoch  38, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.210, TAw acc= 58.5% | Valid: time=  0.4s loss=0.944, TAw acc= 66.6% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.179, TAw acc= 59.1% | Valid: time=  0.4s loss=0.969, TAw acc= 68.4% |
| Epoch  40, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.173, TAw acc= 59.3% | Valid: time=  0.4s loss=0.938, TAw acc= 68.6% |
| Epoch  41, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.180, TAw acc= 59.6% | Valid: time=  0.4s loss=0.987, TAw acc= 66.4% |
| Epoch  42, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.171, TAw acc= 59.2% | Valid: time=  0.4s loss=0.964, TAw acc= 67.2% |
| Epoch  43, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.166, TAw acc= 60.3% | Valid: time=  0.4s loss=1.007, TAw acc= 65.4% |
| Epoch  44, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.148, TAw acc= 60.2% | Valid: time=  0.4s loss=0.940, TAw acc= 68.0% |
| Epoch  45, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.178, TAw acc= 59.4% | Valid: time=  0.4s loss=0.990, TAw acc= 67.8% |
| Epoch  46, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.144, TAw acc= 60.1% | Valid: time=  0.4s loss=0.989, TAw acc= 67.0% |
| Epoch  47, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.162, TAw acc= 60.2% | Valid: time=  0.4s loss=0.979, TAw acc= 65.2% |
| Epoch  48, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.156, TAw acc= 60.8% | Valid: time=  0.4s loss=0.964, TAw acc= 67.6% |
| Epoch  49, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.169, TAw acc= 59.8% | Valid: time=  0.4s loss=0.932, TAw acc= 68.6% |
| Epoch  50, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.174, TAw acc= 60.1% | Valid: time=  0.4s loss=0.924, TAw acc= 68.8% | *
| Epoch  51, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.152, TAw acc= 60.7% | Valid: time=  0.4s loss=0.979, TAw acc= 68.0% |
| Epoch  52, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.131, TAw acc= 60.2% | Valid: time=  0.4s loss=0.959, TAw acc= 67.0% |
| Epoch  53, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.161, TAw acc= 59.5% | Valid: time=  0.4s loss=0.957, TAw acc= 68.2% |
| Epoch  54, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.158, TAw acc= 59.8% | Valid: time=  0.4s loss=0.917, TAw acc= 68.0% | *
| Epoch  55, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.157, TAw acc= 59.5% | Valid: time=  0.4s loss=0.978, TAw acc= 66.8% |
| Epoch  56, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.155, TAw acc= 59.9% | Valid: time=  0.4s loss=0.914, TAw acc= 68.2% | *
| Epoch  57, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.130, TAw acc= 60.6% | Valid: time=  0.4s loss=0.960, TAw acc= 67.4% |
| Epoch  58, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.156, TAw acc= 60.4% | Valid: time=  0.4s loss=0.954, TAw acc= 64.8% |
| Epoch  59, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.130, TAw acc= 60.6% | Valid: time=  0.4s loss=0.957, TAw acc= 68.0% |
| Epoch  60, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.157, TAw acc= 60.5% | Valid: time=  0.4s loss=0.935, TAw acc= 65.6% |
| Epoch  61, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.160, TAw acc= 60.1% | Valid: time=  0.4s loss=0.924, TAw acc= 67.0% |
| Epoch  62, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.151, TAw acc= 60.8% | Valid: time=  0.4s loss=0.940, TAw acc= 68.4% |
| Epoch  63, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.151, TAw acc= 59.3% | Valid: time=  0.4s loss=1.014, TAw acc= 66.0% |
| Epoch  64, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.157, TAw acc= 59.7% | Valid: time=  0.4s loss=0.965, TAw acc= 68.6% |
| Epoch  65, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.139, TAw acc= 59.9% | Valid: time=  0.4s loss=1.010, TAw acc= 66.2% |
| Epoch  66, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.149, TAw acc= 61.3% | Valid: time=  0.4s loss=0.942, TAw acc= 69.2% |
| Epoch  67, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.144, TAw acc= 61.8% | Valid: time=  0.4s loss=0.949, TAw acc= 68.6% |
| Epoch  68, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.129, TAw acc= 60.9% | Valid: time=  0.4s loss=0.957, TAw acc= 69.2% |
| Epoch  69, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.169, TAw acc= 59.9% | Valid: time=  0.4s loss=0.957, TAw acc= 67.4% |
| Epoch  70, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.153, TAw acc= 60.9% | Valid: time=  0.4s loss=1.008, TAw acc= 65.2% |
| Epoch  71, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.137, TAw acc= 62.0% | Valid: time=  0.4s loss=0.920, TAw acc= 68.2% |
| Epoch  72, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.135, TAw acc= 62.2% | Valid: time=  0.4s loss=0.954, TAw acc= 67.2% |
| Epoch  73, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.167, TAw acc= 60.5% | Valid: time=  0.4s loss=0.913, TAw acc= 69.0% | *
| Epoch  74, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.131, TAw acc= 62.0% | Valid: time=  0.4s loss=0.908, TAw acc= 67.4% | *
| Epoch  75, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.144, TAw acc= 59.7% | Valid: time=  0.4s loss=0.945, TAw acc= 67.0% |
| Epoch  76, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.155, TAw acc= 60.9% | Valid: time=  0.4s loss=0.922, TAw acc= 67.2% |
| Epoch  77, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.170, TAw acc= 60.5% | Valid: time=  0.4s loss=0.925, TAw acc= 68.8% |
| Epoch  78, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.138, TAw acc= 60.0% | Valid: time=  0.4s loss=0.971, TAw acc= 68.4% |
| Epoch  79, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.121, TAw acc= 61.2% | Valid: time=  0.4s loss=0.983, TAw acc= 66.4% |
| Epoch  80, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.107, TAw acc= 61.7% | Valid: time=  0.4s loss=0.933, TAw acc= 69.0% |
| Epoch  81, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.137, TAw acc= 60.3% | Valid: time=  0.4s loss=0.931, TAw acc= 67.2% |
| Epoch  82, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.156, TAw acc= 59.8% | Valid: time=  0.4s loss=0.962, TAw acc= 67.8% |
| Epoch  83, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.132, TAw acc= 61.1% | Valid: time=  0.4s loss=0.926, TAw acc= 69.6% |
| Epoch  84, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.133, TAw acc= 61.1% | Valid: time=  0.4s loss=0.939, TAw acc= 69.0% |
| Epoch  85, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.163, TAw acc= 59.8% | Valid: time=  0.4s loss=1.017, TAw acc= 68.0% |
| Epoch  86, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.163, TAw acc= 59.8% | Valid: time=  0.4s loss=1.036, TAw acc= 64.6% |
| Epoch  87, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.132, TAw acc= 61.3% | Valid: time=  0.4s loss=0.940, TAw acc= 70.0% |
| Epoch  88, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.148, TAw acc= 60.2% | Valid: time=  0.4s loss=1.053, TAw acc= 65.4% |
| Epoch  89, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.109, TAw acc= 60.9% | Valid: time=  0.4s loss=1.024, TAw acc= 68.6% |
| Epoch  90, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.119, TAw acc= 62.2% | Valid: time=  0.4s loss=0.975, TAw acc= 69.4% |
| Epoch  91, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.140, TAw acc= 61.6% | Valid: time=  0.4s loss=0.901, TAw acc= 70.2% | *
| Epoch  92, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.143, TAw acc= 61.3% | Valid: time=  0.4s loss=0.946, TAw acc= 69.8% |
| Epoch  93, lr=2.6e-02 time=  6.3s/  1.9s | Train: loss=1.135, TAw acc= 61.0% | Valid: time=  0.4s loss=0.924, TAw acc= 69.4% |
| Epoch  94, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.151, TAw acc= 59.6% | Valid: time=  0.4s loss=1.006, TAw acc= 67.0% |
| Epoch  95, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.122, TAw acc= 61.7% | Valid: time=  0.4s loss=0.962, TAw acc= 68.2% |
| Epoch  96, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.101, TAw acc= 61.9% | Valid: time=  0.4s loss=0.988, TAw acc= 68.0% |
| Epoch  97, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.123, TAw acc= 63.1% | Valid: time=  0.4s loss=0.924, TAw acc= 68.8% |
| Epoch  98, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.139, TAw acc= 60.2% | Valid: time=  0.4s loss=1.033, TAw acc= 67.2% |
| Epoch  99, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.107, TAw acc= 61.7% | Valid: time=  0.4s loss=1.074, TAw acc= 65.2% |
| Epoch 100, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.144, TAw acc= 59.6% | Valid: time=  0.4s loss=0.983, TAw acc= 67.2% |
== Rank Reduction [task:1] ==
best_loss=0.901,  best_acc=0.702
 r=256, loss=0.909, acc=0.698
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.909, acc=0.700
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.911, acc=0.698
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.912, acc=0.702
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.894, acc=0.708
 loss_margin=0.006, acc_margin=0.004
best_r=384, loss=0.894, acc=0.708
== Header Training for Low Rank [task:1] ==
loss=0.894 acc=0.708
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.129, TAw acc= 61.1% | Valid: time=  0.4s loss=0.949, TAw acc= 68.4% |
| Epoch   2, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=1.137, TAw acc= 61.6% | Valid: time=  0.4s loss=0.953, TAw acc= 69.0% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.112, TAw acc= 62.1% | Valid: time=  0.4s loss=0.945, TAw acc= 69.2% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.133, TAw acc= 61.1% | Valid: time=  0.4s loss=0.936, TAw acc= 69.6% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.127, TAw acc= 61.6% | Valid: time=  0.4s loss=0.945, TAw acc= 68.8% |
| Epoch   6, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=1.120, TAw acc= 62.2% | Valid: time=  0.4s loss=0.945, TAw acc= 69.2% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.112, TAw acc= 61.4% | Valid: time=  0.4s loss=0.943, TAw acc= 69.8% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.090, TAw acc= 63.3% | Valid: time=  0.4s loss=0.936, TAw acc= 69.8% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.121, TAw acc= 61.5% | Valid: time=  0.4s loss=0.946, TAw acc= 70.2% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.112, TAw acc= 61.9% | Valid: time=  0.4s loss=0.942, TAw acc= 69.6% |
| Epoch  11, lr=8.8e-03 time=  1.6s/  1.9s | Train: loss=1.095, TAw acc= 63.0% | Valid: time=  0.4s loss=0.940, TAw acc= 70.0% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.077, TAw acc= 63.8% | Valid: time=  0.4s loss=0.934, TAw acc= 69.8% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.107, TAw acc= 62.3% | Valid: time=  0.4s loss=0.947, TAw acc= 69.8% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.109, TAw acc= 62.5% | Valid: time=  0.4s loss=0.933, TAw acc= 70.0% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.087, TAw acc= 63.1% | Valid: time=  0.4s loss=0.937, TAw acc= 69.4% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.092, TAw acc= 63.0% | Valid: time=  0.4s loss=0.944, TAw acc= 70.2% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.101, TAw acc= 62.3% | Valid: time=  0.4s loss=0.948, TAw acc= 70.2% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.105, TAw acc= 62.6% | Valid: time=  0.4s loss=0.940, TAw acc= 69.8% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.103, TAw acc= 62.6% | Valid: time=  0.4s loss=0.949, TAw acc= 69.6% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.072, TAw acc= 63.6% | Valid: time=  0.4s loss=0.949, TAw acc= 70.2% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.078, TAw acc= 62.9% | Valid: time=  0.4s loss=0.948, TAw acc= 70.0% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.106, TAw acc= 61.9% | Valid: time=  0.4s loss=0.948, TAw acc= 70.8% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.081, TAw acc= 62.9% | Valid: time=  0.4s loss=0.948, TAw acc= 70.2% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.067, TAw acc= 63.4% | Valid: time=  0.4s loss=0.953, TAw acc= 69.8% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.088, TAw acc= 62.0% | Valid: time=  0.4s loss=0.955, TAw acc= 69.6% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.067, TAw acc= 63.5% | Valid: time=  0.4s loss=0.944, TAw acc= 70.6% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.083, TAw acc= 62.5% | Valid: time=  0.4s loss=0.949, TAw acc= 70.8% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.107, TAw acc= 62.6% | Valid: time=  0.4s loss=0.949, TAw acc= 70.8% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.081, TAw acc= 63.2% | Valid: time=  0.4s loss=0.959, TAw acc= 69.8% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.073, TAw acc= 63.6% | Valid: time=  0.4s loss=0.957, TAw acc= 70.6% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.154, TAw acc= 60.9% | Valid: time=  0.4s loss=0.913, TAw acc= 69.8% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.142, TAw acc= 61.5% | Valid: time=  0.4s loss=0.932, TAw acc= 69.2% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.140, TAw acc= 61.1% | Valid: time=  0.4s loss=0.943, TAw acc= 68.8% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.133, TAw acc= 61.3% | Valid: time=  0.4s loss=0.947, TAw acc= 68.8% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.127, TAw acc= 61.8% | Valid: time=  0.4s loss=0.951, TAw acc= 69.2% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.120, TAw acc= 62.0% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.123, TAw acc= 62.3% | Valid: time=  0.4s loss=0.941, TAw acc= 69.2% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.110, TAw acc= 62.6% | Valid: time=  0.4s loss=0.941, TAw acc= 69.6% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.125, TAw acc= 61.5% | Valid: time=  0.4s loss=0.948, TAw acc= 68.8% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.110, TAw acc= 62.5% | Valid: time=  0.4s loss=0.947, TAw acc= 68.8% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.103, TAw acc= 61.9% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.106, TAw acc= 62.8% | Valid: time=  0.4s loss=0.949, TAw acc= 68.8% |
| Epoch  43, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=1.128, TAw acc= 62.1% | Valid: time=  0.4s loss=0.947, TAw acc= 69.4% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.105, TAw acc= 61.8% | Valid: time=  0.4s loss=0.944, TAw acc= 69.8% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.111, TAw acc= 62.6% | Valid: time=  0.4s loss=0.942, TAw acc= 69.4% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.102, TAw acc= 62.5% | Valid: time=  0.4s loss=0.942, TAw acc= 70.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.138, TAw acc= 61.5% | Valid: time=  0.4s loss=0.944, TAw acc= 70.0% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.117, TAw acc= 62.4% | Valid: time=  0.4s loss=0.942, TAw acc= 70.0% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.105, TAw acc= 62.2% | Valid: time=  0.4s loss=0.944, TAw acc= 69.6% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.113, TAw acc= 62.5% | Valid: time=  0.4s loss=0.943, TAw acc= 70.2% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.107, TAw acc= 61.9% | Valid: time=  0.4s loss=0.939, TAw acc= 70.4% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.108, TAw acc= 62.6% | Valid: time=  0.4s loss=0.934, TAw acc= 69.6% |
| Epoch  53, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=1.101, TAw acc= 62.5% | Valid: time=  0.4s loss=0.940, TAw acc= 70.2% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.109, TAw acc= 61.9% | Valid: time=  0.4s loss=0.943, TAw acc= 69.8% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.110, TAw acc= 62.5% | Valid: time=  0.4s loss=0.944, TAw acc= 69.6% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.104, TAw acc= 62.2% | Valid: time=  0.4s loss=0.946, TAw acc= 69.6% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.083, TAw acc= 62.7% | Valid: time=  0.4s loss=0.945, TAw acc= 69.8% |
| Epoch  58, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=1.112, TAw acc= 62.4% | Valid: time=  0.4s loss=0.943, TAw acc= 70.2% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.101, TAw acc= 62.6% | Valid: time=  0.4s loss=0.943, TAw acc= 70.0% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.125, TAw acc= 62.0% | Valid: time=  0.4s loss=0.941, TAw acc= 70.0% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.168, TAw acc= 59.6% | Valid: time=  0.4s loss=0.897, TAw acc= 70.2% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.155, TAw acc= 60.0% | Valid: time=  0.4s loss=0.904, TAw acc= 70.2% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.141, TAw acc= 61.9% | Valid: time=  0.4s loss=0.913, TAw acc= 69.8% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.135, TAw acc= 61.5% | Valid: time=  0.4s loss=0.920, TAw acc= 69.8% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.146, TAw acc= 60.9% | Valid: time=  0.4s loss=0.927, TAw acc= 69.2% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.111, TAw acc= 62.9% | Valid: time=  0.4s loss=0.933, TAw acc= 69.0% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.8s | Train: loss=1.143, TAw acc= 60.7% | Valid: time=  0.4s loss=0.937, TAw acc= 68.8% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.136, TAw acc= 61.2% | Valid: time=  0.4s loss=0.941, TAw acc= 69.0% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.134, TAw acc= 62.0% | Valid: time=  0.4s loss=0.942, TAw acc= 69.2% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.145, TAw acc= 60.9% | Valid: time=  0.4s loss=0.943, TAw acc= 68.8% |
| Epoch  71, lr=9.7e-04 time=  1.8s/  1.9s | Train: loss=1.134, TAw acc= 61.5% | Valid: time=  0.4s loss=0.945, TAw acc= 69.2% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.104, TAw acc= 62.7% | Valid: time=  0.4s loss=0.945, TAw acc= 69.0% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.129, TAw acc= 61.7% | Valid: time=  0.4s loss=0.946, TAw acc= 69.0% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.128, TAw acc= 62.3% | Valid: time=  0.4s loss=0.948, TAw acc= 69.4% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.117, TAw acc= 62.4% | Valid: time=  0.4s loss=0.948, TAw acc= 69.0% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.118, TAw acc= 62.8% | Valid: time=  0.4s loss=0.948, TAw acc= 69.2% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.126, TAw acc= 61.1% | Valid: time=  0.4s loss=0.949, TAw acc= 69.0% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.126, TAw acc= 62.0% | Valid: time=  0.4s loss=0.950, TAw acc= 69.0% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.117, TAw acc= 62.0% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.129, TAw acc= 61.9% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.103, TAw acc= 62.5% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.137, TAw acc= 60.7% | Valid: time=  0.4s loss=0.951, TAw acc= 68.6% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.122, TAw acc= 62.0% | Valid: time=  0.4s loss=0.949, TAw acc= 69.0% |
| Epoch  84, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=1.136, TAw acc= 61.5% | Valid: time=  0.4s loss=0.950, TAw acc= 68.8% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.143, TAw acc= 61.3% | Valid: time=  0.5s loss=0.949, TAw acc= 68.8% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.109, TAw acc= 62.3% | Valid: time=  0.4s loss=0.951, TAw acc= 69.0% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.099, TAw acc= 62.6% | Valid: time=  0.4s loss=0.951, TAw acc= 68.6% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.104, TAw acc= 62.9% | Valid: time=  0.4s loss=0.950, TAw acc= 69.0% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.108, TAw acc= 62.8% | Valid: time=  0.4s loss=0.949, TAw acc= 69.2% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.114, TAw acc= 62.5% | Valid: time=  0.4s loss=0.948, TAw acc= 69.0% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.152, TAw acc= 60.4% | Valid: time=  0.4s loss=0.894, TAw acc= 70.4% |
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.152, TAw acc= 60.4% | Valid: time=  0.4s loss=0.896, TAw acc= 70.4% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.154, TAw acc= 60.0% | Valid: time=  0.4s loss=0.898, TAw acc= 70.4% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.162, TAw acc= 60.7% | Valid: time=  0.4s loss=0.900, TAw acc= 70.6% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.147, TAw acc= 61.5% | Valid: time=  0.4s loss=0.903, TAw acc= 70.2% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.139, TAw acc= 61.3% | Valid: time=  0.4s loss=0.905, TAw acc= 70.2% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.150, TAw acc= 61.3% | Valid: time=  0.4s loss=0.908, TAw acc= 70.2% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.133, TAw acc= 62.0% | Valid: time=  0.4s loss=0.910, TAw acc= 70.0% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.142, TAw acc= 61.7% | Valid: time=  0.4s loss=0.913, TAw acc= 69.8% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.147, TAw acc= 60.8% | Valid: time=  0.4s loss=0.916, TAw acc= 69.8% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.807 | TAw acc= 72.0%, forg=  5.3%| TAg acc= 32.0%, forg= 45.3% <<<
>>> Test on task  1 : loss=0.958 | TAw acc= 69.2%, forg=  0.0%| TAg acc= 65.4%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  2
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-2): 3 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.171, TAw acc= 59.6% | Valid: time=  0.4s loss=0.774, TAw acc= 72.8% | *
| Epoch   2, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.067, TAw acc= 63.5% | Valid: time=  0.4s loss=0.643, TAw acc= 76.4% | *
| Epoch   3, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.041, TAw acc= 64.6% | Valid: time=  0.4s loss=0.805, TAw acc= 72.2% |
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.034, TAw acc= 65.0% | Valid: time=  0.4s loss=0.665, TAw acc= 76.8% |
| Epoch   5, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.009, TAw acc= 66.2% | Valid: time=  0.4s loss=0.613, TAw acc= 80.2% | *
| Epoch   6, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.975, TAw acc= 67.3% | Valid: time=  0.4s loss=0.614, TAw acc= 79.8% |
| Epoch   7, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.959, TAw acc= 67.0% | Valid: time=  0.4s loss=0.582, TAw acc= 80.6% | *
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.948, TAw acc= 68.2% | Valid: time=  0.4s loss=0.621, TAw acc= 77.4% |
| Epoch   9, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.955, TAw acc= 67.0% | Valid: time=  0.4s loss=0.616, TAw acc= 78.8% |
| Epoch  10, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.944, TAw acc= 68.4% | Valid: time=  0.4s loss=0.583, TAw acc= 81.2% |
| Epoch  11, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.943, TAw acc= 68.4% | Valid: time=  0.4s loss=0.587, TAw acc= 78.2% |
| Epoch  12, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.944, TAw acc= 67.6% | Valid: time=  0.4s loss=0.633, TAw acc= 78.2% |
| Epoch  13, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.945, TAw acc= 67.3% | Valid: time=  0.4s loss=0.555, TAw acc= 81.4% | *
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.934, TAw acc= 69.7% | Valid: time=  0.4s loss=0.542, TAw acc= 80.2% | *
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.986, TAw acc= 66.9% | Valid: time=  0.4s loss=0.642, TAw acc= 77.2% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.907, TAw acc= 69.4% | Valid: time=  0.4s loss=0.587, TAw acc= 79.0% |
| Epoch  17, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.900, TAw acc= 69.8% | Valid: time=  0.4s loss=0.569, TAw acc= 79.6% |
| Epoch  18, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.880, TAw acc= 70.2% | Valid: time=  0.4s loss=0.503, TAw acc= 83.2% | *
| Epoch  19, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.896, TAw acc= 69.6% | Valid: time=  0.4s loss=0.507, TAw acc= 82.0% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.877, TAw acc= 69.9% | Valid: time=  0.4s loss=0.577, TAw acc= 81.0% |
| Epoch  21, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.918, TAw acc= 69.2% | Valid: time=  0.4s loss=0.603, TAw acc= 79.8% |
| Epoch  22, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.910, TAw acc= 68.2% | Valid: time=  0.4s loss=0.544, TAw acc= 81.4% |
| Epoch  23, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.891, TAw acc= 70.3% | Valid: time=  0.4s loss=0.569, TAw acc= 81.4% |
| Epoch  24, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.888, TAw acc= 68.9% | Valid: time=  0.4s loss=0.609, TAw acc= 79.8% |
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.902, TAw acc= 69.6% | Valid: time=  0.4s loss=0.559, TAw acc= 80.6% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.906, TAw acc= 69.0% | Valid: time=  0.4s loss=0.568, TAw acc= 79.4% |
| Epoch  27, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.889, TAw acc= 70.0% | Valid: time=  0.4s loss=0.566, TAw acc= 81.0% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.857, TAw acc= 71.0% | Valid: time=  0.4s loss=0.574, TAw acc= 79.6% |
| Epoch  29, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.878, TAw acc= 69.8% | Valid: time=  0.4s loss=0.584, TAw acc= 80.4% |
| Epoch  30, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.875, TAw acc= 70.9% | Valid: time=  0.4s loss=0.526, TAw acc= 81.6% |
| Epoch  31, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.865, TAw acc= 71.5% | Valid: time=  0.4s loss=0.520, TAw acc= 82.2% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.840, TAw acc= 70.9% | Valid: time=  0.4s loss=0.538, TAw acc= 82.2% |
| Epoch  33, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.849, TAw acc= 70.3% | Valid: time=  0.4s loss=0.635, TAw acc= 78.6% |
| Epoch  34, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.874, TAw acc= 71.0% | Valid: time=  0.4s loss=0.571, TAw acc= 81.8% |
| Epoch  35, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.878, TAw acc= 69.8% | Valid: time=  0.4s loss=0.556, TAw acc= 81.0% |
| Epoch  36, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.867, TAw acc= 70.6% | Valid: time=  0.4s loss=0.595, TAw acc= 80.6% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.850, TAw acc= 71.6% | Valid: time=  0.4s loss=0.547, TAw acc= 83.6% |
| Epoch  38, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.869, TAw acc= 70.6% | Valid: time=  0.4s loss=0.574, TAw acc= 81.4% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.881, TAw acc= 70.5% | Valid: time=  0.4s loss=0.584, TAw acc= 80.0% |
| Epoch  40, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.872, TAw acc= 70.0% | Valid: time=  0.4s loss=0.534, TAw acc= 82.8% |
| Epoch  41, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.851, TAw acc= 71.2% | Valid: time=  0.4s loss=0.593, TAw acc= 80.8% |
| Epoch  42, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.846, TAw acc= 71.2% | Valid: time=  0.4s loss=0.613, TAw acc= 78.2% |
| Epoch  43, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.842, TAw acc= 71.4% | Valid: time=  0.4s loss=0.557, TAw acc= 81.4% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.847, TAw acc= 71.1% | Valid: time=  0.4s loss=0.596, TAw acc= 81.0% |
| Epoch  45, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.846, TAw acc= 71.3% | Valid: time=  0.4s loss=0.555, TAw acc= 79.0% |
| Epoch  46, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.825, TAw acc= 72.0% | Valid: time=  0.4s loss=0.617, TAw acc= 79.8% |
| Epoch  47, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.844, TAw acc= 71.1% | Valid: time=  0.4s loss=0.553, TAw acc= 82.0% |
| Epoch  48, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.867, TAw acc= 70.8% | Valid: time=  0.4s loss=0.540, TAw acc= 80.8% | lr=8.8e-03
| Epoch  49, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.869, TAw acc= 70.4% | Valid: time=  0.4s loss=0.611, TAw acc= 80.2% |
| Epoch  50, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 70.6% | Valid: time=  0.4s loss=0.546, TAw acc= 81.2% |
| Epoch  51, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.848, TAw acc= 71.3% | Valid: time=  0.4s loss=0.603, TAw acc= 80.0% |
| Epoch  52, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.888, TAw acc= 68.7% | Valid: time=  0.4s loss=0.577, TAw acc= 80.0% |
| Epoch  53, lr=8.8e-03 time=  2.9s/  2.0s | Train: loss=0.878, TAw acc= 70.1% | Valid: time=  0.4s loss=0.556, TAw acc= 81.2% |
| Epoch  54, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.894, TAw acc= 69.9% | Valid: time=  0.4s loss=0.531, TAw acc= 79.8% |
| Epoch  55, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.823, TAw acc= 71.9% | Valid: time=  0.4s loss=0.551, TAw acc= 80.8% |
| Epoch  56, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.873, TAw acc= 70.5% | Valid: time=  0.4s loss=0.574, TAw acc= 80.8% |
| Epoch  57, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.862, TAw acc= 69.7% | Valid: time=  0.4s loss=0.614, TAw acc= 81.4% |
| Epoch  58, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.855, TAw acc= 71.4% | Valid: time=  0.4s loss=0.527, TAw acc= 82.4% |
| Epoch  59, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.840, TAw acc= 71.6% | Valid: time=  0.4s loss=0.557, TAw acc= 81.4% |
| Epoch  60, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.868, TAw acc= 70.4% | Valid: time=  0.4s loss=0.573, TAw acc= 79.2% |
| Epoch  61, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.849, TAw acc= 70.8% | Valid: time=  0.4s loss=0.569, TAw acc= 80.2% |
| Epoch  62, lr=8.8e-03 time=  3.0s/  1.9s | Train: loss=0.856, TAw acc= 71.4% | Valid: time=  0.4s loss=0.545, TAw acc= 81.0% |
| Epoch  63, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.863, TAw acc= 71.6% | Valid: time=  0.4s loss=0.560, TAw acc= 82.4% |
| Epoch  64, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.833, TAw acc= 72.3% | Valid: time=  0.4s loss=0.538, TAw acc= 81.4% |
| Epoch  65, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.841, TAw acc= 72.0% | Valid: time=  0.4s loss=0.540, TAw acc= 82.8% |
| Epoch  66, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.868, TAw acc= 71.4% | Valid: time=  0.4s loss=0.547, TAw acc= 82.0% |
| Epoch  67, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.843, TAw acc= 71.6% | Valid: time=  0.4s loss=0.555, TAw acc= 82.2% |
| Epoch  68, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.855, TAw acc= 71.4% | Valid: time=  0.4s loss=0.533, TAw acc= 82.6% |
| Epoch  69, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.801, TAw acc= 72.1% | Valid: time=  0.4s loss=0.537, TAw acc= 81.8% |
| Epoch  70, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.834, TAw acc= 71.8% | Valid: time=  0.4s loss=0.531, TAw acc= 82.6% |
| Epoch  71, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.863, TAw acc= 72.2% | Valid: time=  0.4s loss=0.586, TAw acc= 80.2% |
| Epoch  72, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.815, TAw acc= 73.0% | Valid: time=  0.4s loss=0.508, TAw acc= 83.6% |
| Epoch  73, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.841, TAw acc= 72.1% | Valid: time=  0.4s loss=0.536, TAw acc= 81.4% |
| Epoch  74, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.828, TAw acc= 72.1% | Valid: time=  0.4s loss=0.574, TAw acc= 80.2% |
| Epoch  75, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.830, TAw acc= 71.9% | Valid: time=  0.4s loss=0.554, TAw acc= 79.6% |
| Epoch  76, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.819, TAw acc= 73.1% | Valid: time=  0.4s loss=0.555, TAw acc= 82.0% |
| Epoch  77, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.824, TAw acc= 72.0% | Valid: time=  0.4s loss=0.565, TAw acc= 80.2% |
| Epoch  78, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.812, TAw acc= 73.2% | Valid: time=  0.4s loss=0.534, TAw acc= 80.8% | lr=2.9e-03
| Epoch  79, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.875, TAw acc= 70.1% | Valid: time=  0.4s loss=0.545, TAw acc= 81.2% |
| Epoch  80, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.893, TAw acc= 68.1% | Valid: time=  0.4s loss=0.548, TAw acc= 81.2% |
| Epoch  81, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.855, TAw acc= 71.0% | Valid: time=  0.4s loss=0.564, TAw acc= 81.4% |
| Epoch  82, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.859, TAw acc= 71.8% | Valid: time=  0.4s loss=0.564, TAw acc= 80.6% |
| Epoch  83, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.867, TAw acc= 71.1% | Valid: time=  0.4s loss=0.563, TAw acc= 79.4% |
| Epoch  84, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.876, TAw acc= 71.5% | Valid: time=  0.4s loss=0.543, TAw acc= 80.4% |
| Epoch  85, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.886, TAw acc= 69.8% | Valid: time=  0.4s loss=0.589, TAw acc= 79.6% |
| Epoch  86, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.839, TAw acc= 71.6% | Valid: time=  0.4s loss=0.562, TAw acc= 81.2% |
| Epoch  87, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.844, TAw acc= 71.6% | Valid: time=  0.4s loss=0.514, TAw acc= 82.4% |
| Epoch  88, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.850, TAw acc= 71.3% | Valid: time=  0.4s loss=0.538, TAw acc= 82.4% |
| Epoch  89, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.876, TAw acc= 70.4% | Valid: time=  0.4s loss=0.572, TAw acc= 80.6% |
| Epoch  90, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.832, TAw acc= 72.0% | Valid: time=  0.4s loss=0.522, TAw acc= 82.4% |
| Epoch  91, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.836, TAw acc= 71.4% | Valid: time=  0.4s loss=0.503, TAw acc= 83.4% |
| Epoch  92, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.849, TAw acc= 71.1% | Valid: time=  0.4s loss=0.540, TAw acc= 81.4% |
| Epoch  93, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.839, TAw acc= 71.7% | Valid: time=  0.4s loss=0.563, TAw acc= 81.2% |
| Epoch  94, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.847, TAw acc= 71.8% | Valid: time=  0.4s loss=0.549, TAw acc= 82.8% |
| Epoch  95, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.825, TAw acc= 71.9% | Valid: time=  0.4s loss=0.580, TAw acc= 81.4% |
| Epoch  96, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.859, TAw acc= 71.4% | Valid: time=  0.4s loss=0.532, TAw acc= 82.2% |
| Epoch  97, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.824, TAw acc= 72.6% | Valid: time=  0.4s loss=0.534, TAw acc= 82.0% |
| Epoch  98, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.859, TAw acc= 71.4% | Valid: time=  0.4s loss=0.534, TAw acc= 82.0% |
| Epoch  99, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.829, TAw acc= 72.8% | Valid: time=  0.4s loss=0.538, TAw acc= 82.4% |
| Epoch 100, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.832, TAw acc= 72.5% | Valid: time=  0.4s loss=0.516, TAw acc= 81.6% |
== Rank Reduction [task:2] ==
best_loss=0.503,  best_acc=0.832
 r=256, loss=0.533, acc=0.812
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.520, acc=0.806
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.524, acc=0.808
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.528, acc=0.812
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.529, acc=0.816
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.521, acc=0.818
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.517, acc=0.822
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.519, acc=0.824
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.518, acc=0.818
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.518, acc=0.826
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.509, acc=0.828
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.505, acc=0.824
 loss_margin=0.006, acc_margin=0.004
 r=640, loss=0.505, acc=0.832
 loss_margin=0.006, acc_margin=0.004
best_r=640, loss=0.505, acc=0.832
== Header Training for Low Rank [task:2] ==
loss=0.505 acc=0.832
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 70.5% | Valid: time=  0.4s loss=0.529, TAw acc= 81.2% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.4% | Valid: time=  0.4s loss=0.515, TAw acc= 81.6% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.849, TAw acc= 71.6% | Valid: time=  0.4s loss=0.515, TAw acc= 81.6% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 71.2% | Valid: time=  0.4s loss=0.523, TAw acc= 81.2% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.849, TAw acc= 71.2% | Valid: time=  0.4s loss=0.527, TAw acc= 82.4% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.841, TAw acc= 71.5% | Valid: time=  0.4s loss=0.521, TAw acc= 81.0% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.841, TAw acc= 71.8% | Valid: time=  0.4s loss=0.522, TAw acc= 82.0% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.821, TAw acc= 71.9% | Valid: time=  0.4s loss=0.520, TAw acc= 82.0% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.828, TAw acc= 71.9% | Valid: time=  0.4s loss=0.520, TAw acc= 81.0% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.838, TAw acc= 72.3% | Valid: time=  0.4s loss=0.529, TAw acc= 81.4% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.811, TAw acc= 72.3% | Valid: time=  0.4s loss=0.534, TAw acc= 81.2% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.838, TAw acc= 71.8% | Valid: time=  0.4s loss=0.536, TAw acc= 80.4% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.805, TAw acc= 72.6% | Valid: time=  0.4s loss=0.521, TAw acc= 81.6% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.796, TAw acc= 72.8% | Valid: time=  0.4s loss=0.530, TAw acc= 81.6% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.809, TAw acc= 73.2% | Valid: time=  0.4s loss=0.538, TAw acc= 80.2% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.813, TAw acc= 72.6% | Valid: time=  0.4s loss=0.532, TAw acc= 81.8% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.830, TAw acc= 71.8% | Valid: time=  0.4s loss=0.532, TAw acc= 81.8% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.803, TAw acc= 72.9% | Valid: time=  0.4s loss=0.546, TAw acc= 82.0% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.822, TAw acc= 71.8% | Valid: time=  0.4s loss=0.533, TAw acc= 81.0% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.785, TAw acc= 73.2% | Valid: time=  0.4s loss=0.544, TAw acc= 81.2% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.796, TAw acc= 72.2% | Valid: time=  0.4s loss=0.540, TAw acc= 81.4% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.789, TAw acc= 73.2% | Valid: time=  0.4s loss=0.539, TAw acc= 81.4% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.822, TAw acc= 72.5% | Valid: time=  0.4s loss=0.534, TAw acc= 81.4% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.800, TAw acc= 73.2% | Valid: time=  0.4s loss=0.532, TAw acc= 80.8% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.801, TAw acc= 73.3% | Valid: time=  0.4s loss=0.519, TAw acc= 81.8% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.797, TAw acc= 72.8% | Valid: time=  0.4s loss=0.523, TAw acc= 82.2% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.797, TAw acc= 73.5% | Valid: time=  0.4s loss=0.529, TAw acc= 81.8% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.804, TAw acc= 72.5% | Valid: time=  0.4s loss=0.524, TAw acc= 81.2% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.792, TAw acc= 73.1% | Valid: time=  0.4s loss=0.514, TAw acc= 81.8% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.800, TAw acc= 72.5% | Valid: time=  0.4s loss=0.543, TAw acc= 81.2% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 71.0% | Valid: time=  0.4s loss=0.515, TAw acc= 80.8% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 70.7% | Valid: time=  0.4s loss=0.512, TAw acc= 81.4% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.865, TAw acc= 71.3% | Valid: time=  0.4s loss=0.517, TAw acc= 81.4% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.858, TAw acc= 70.9% | Valid: time=  0.4s loss=0.516, TAw acc= 81.4% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 71.3% | Valid: time=  0.4s loss=0.519, TAw acc= 81.8% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 70.9% | Valid: time=  0.4s loss=0.517, TAw acc= 81.6% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.838, TAw acc= 72.0% | Valid: time=  0.4s loss=0.515, TAw acc= 81.8% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.0% | Valid: time=  0.4s loss=0.513, TAw acc= 81.4% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.835, TAw acc= 72.0% | Valid: time=  0.4s loss=0.516, TAw acc= 81.8% |
| Epoch  40, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.836, TAw acc= 71.8% | Valid: time=  0.4s loss=0.519, TAw acc= 81.6% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.844, TAw acc= 71.9% | Valid: time=  0.4s loss=0.513, TAw acc= 80.8% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.845, TAw acc= 71.9% | Valid: time=  0.4s loss=0.513, TAw acc= 80.8% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.835, TAw acc= 71.6% | Valid: time=  0.4s loss=0.509, TAw acc= 81.4% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 70.3% | Valid: time=  0.4s loss=0.517, TAw acc= 82.0% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.846, TAw acc= 71.6% | Valid: time=  0.4s loss=0.511, TAw acc= 82.4% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.841, TAw acc= 70.8% | Valid: time=  0.4s loss=0.516, TAw acc= 82.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 70.3% | Valid: time=  0.4s loss=0.515, TAw acc= 81.6% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.845, TAw acc= 71.0% | Valid: time=  0.4s loss=0.518, TAw acc= 81.8% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.840, TAw acc= 72.3% | Valid: time=  0.4s loss=0.519, TAw acc= 81.4% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.835, TAw acc= 72.2% | Valid: time=  0.4s loss=0.518, TAw acc= 81.6% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.844, TAw acc= 71.4% | Valid: time=  0.4s loss=0.517, TAw acc= 81.4% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.821, TAw acc= 71.9% | Valid: time=  0.4s loss=0.520, TAw acc= 81.4% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.837, TAw acc= 71.7% | Valid: time=  0.4s loss=0.518, TAw acc= 81.8% |
| Epoch  54, lr=2.9e-03 time=  1.6s/  1.9s | Train: loss=0.856, TAw acc= 70.9% | Valid: time=  0.4s loss=0.522, TAw acc= 81.6% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.829, TAw acc= 71.7% | Valid: time=  0.4s loss=0.521, TAw acc= 81.4% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.832, TAw acc= 72.2% | Valid: time=  0.4s loss=0.520, TAw acc= 82.0% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.828, TAw acc= 72.8% | Valid: time=  0.4s loss=0.521, TAw acc= 81.6% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.834, TAw acc= 71.6% | Valid: time=  0.4s loss=0.517, TAw acc= 81.8% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.819, TAw acc= 73.0% | Valid: time=  0.4s loss=0.521, TAw acc= 81.8% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.831, TAw acc= 71.6% | Valid: time=  0.4s loss=0.522, TAw acc= 81.6% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.898, TAw acc= 70.2% | Valid: time=  0.4s loss=0.510, TAw acc= 81.4% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 70.7% | Valid: time=  0.4s loss=0.515, TAw acc= 80.4% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 71.9% | Valid: time=  0.4s loss=0.517, TAw acc= 80.0% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 71.1% | Valid: time=  0.4s loss=0.515, TAw acc= 80.6% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 70.7% | Valid: time=  0.4s loss=0.512, TAw acc= 81.0% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 71.1% | Valid: time=  0.4s loss=0.512, TAw acc= 80.8% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.857, TAw acc= 71.6% | Valid: time=  0.4s loss=0.512, TAw acc= 80.6% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 71.5% | Valid: time=  0.4s loss=0.512, TAw acc= 81.0% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.868, TAw acc= 70.7% | Valid: time=  0.4s loss=0.513, TAw acc= 81.2% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.3% | Valid: time=  0.4s loss=0.513, TAw acc= 81.4% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 70.8% | Valid: time=  0.4s loss=0.515, TAw acc= 81.2% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 71.8% | Valid: time=  0.4s loss=0.514, TAw acc= 81.4% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 71.9% | Valid: time=  0.4s loss=0.517, TAw acc= 81.0% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.860, TAw acc= 71.7% | Valid: time=  0.4s loss=0.517, TAw acc= 81.2% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.868, TAw acc= 70.4% | Valid: time=  0.4s loss=0.517, TAw acc= 81.2% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 70.1% | Valid: time=  0.4s loss=0.517, TAw acc= 81.2% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 70.4% | Valid: time=  0.4s loss=0.516, TAw acc= 81.4% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 71.6% | Valid: time=  0.4s loss=0.514, TAw acc= 81.8% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 71.8% | Valid: time=  0.4s loss=0.516, TAw acc= 82.0% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 71.7% | Valid: time=  0.4s loss=0.516, TAw acc= 81.8% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 71.0% | Valid: time=  0.4s loss=0.517, TAw acc= 81.8% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.865, TAw acc= 71.2% | Valid: time=  0.4s loss=0.515, TAw acc= 81.6% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.863, TAw acc= 72.0% | Valid: time=  0.4s loss=0.513, TAw acc= 81.6% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.831, TAw acc= 72.8% | Valid: time=  0.4s loss=0.514, TAw acc= 81.6% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.855, TAw acc= 71.0% | Valid: time=  0.4s loss=0.514, TAw acc= 81.8% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.841, TAw acc= 71.8% | Valid: time=  0.4s loss=0.515, TAw acc= 81.8% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 70.0% | Valid: time=  0.4s loss=0.514, TAw acc= 81.8% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 71.0% | Valid: time=  0.4s loss=0.516, TAw acc= 81.4% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 71.6% | Valid: time=  0.4s loss=0.513, TAw acc= 81.8% |
| Epoch  90, lr=9.7e-04 time=  1.6s/  1.9s | Train: loss=0.856, TAw acc= 71.7% | Valid: time=  0.4s loss=0.515, TAw acc= 81.6% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 70.4% | Valid: time=  0.4s loss=0.506, TAw acc= 82.2% |
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 70.8% | Valid: time=  0.5s loss=0.508, TAw acc= 81.4% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.885, TAw acc= 70.2% | Valid: time=  0.4s loss=0.509, TAw acc= 81.6% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 70.2% | Valid: time=  0.4s loss=0.510, TAw acc= 81.0% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.896, TAw acc= 69.8% | Valid: time=  0.4s loss=0.511, TAw acc= 80.8% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.863, TAw acc= 71.0% | Valid: time=  0.4s loss=0.512, TAw acc= 81.0% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.893, TAw acc= 70.5% | Valid: time=  0.4s loss=0.514, TAw acc= 80.6% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 69.7% | Valid: time=  0.4s loss=0.514, TAw acc= 80.6% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.4% | Valid: time=  0.4s loss=0.514, TAw acc= 80.8% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.9% | Valid: time=  0.4s loss=0.514, TAw acc= 80.8% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc= 24.1%, forg= 53.2% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 60.6%, forg=  4.8% <<<
>>> Test on task  2 : loss=0.603 | TAw acc= 79.7%, forg=  0.0%| TAg acc= 38.5%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  3
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.149, TAw acc= 60.5% | Valid: time=  0.4s loss=0.838, TAw acc= 68.2% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.133, TAw acc= 61.2% | Valid: time=  0.4s loss=0.808, TAw acc= 70.6% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.081, TAw acc= 63.6% | Valid: time=  0.4s loss=0.729, TAw acc= 73.2% | *
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.073, TAw acc= 64.1% | Valid: time=  0.4s loss=0.710, TAw acc= 71.6% | *
| Epoch   5, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.057, TAw acc= 62.7% | Valid: time=  0.4s loss=0.763, TAw acc= 70.6% |
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.055, TAw acc= 63.8% | Valid: time=  0.4s loss=0.709, TAw acc= 72.8% | *
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.029, TAw acc= 63.8% | Valid: time=  0.4s loss=0.692, TAw acc= 73.6% | *
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.043, TAw acc= 65.5% | Valid: time=  0.4s loss=0.726, TAw acc= 71.6% |
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.012, TAw acc= 65.9% | Valid: time=  0.4s loss=0.717, TAw acc= 73.8% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.009, TAw acc= 63.9% | Valid: time=  0.4s loss=0.686, TAw acc= 75.0% | *
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 66.6% | Valid: time=  0.4s loss=0.679, TAw acc= 74.8% | *
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.035, TAw acc= 63.9% | Valid: time=  0.4s loss=0.772, TAw acc= 71.2% |
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.996, TAw acc= 64.9% | Valid: time=  0.4s loss=0.688, TAw acc= 72.8% |
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 66.3% | Valid: time=  0.4s loss=0.679, TAw acc= 72.2% | *
| Epoch  15, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 65.2% | Valid: time=  0.4s loss=0.716, TAw acc= 73.4% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.963, TAw acc= 66.4% | Valid: time=  0.4s loss=0.703, TAw acc= 73.4% |
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 65.6% | Valid: time=  0.4s loss=0.689, TAw acc= 73.0% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.975, TAw acc= 66.9% | Valid: time=  0.4s loss=0.708, TAw acc= 74.4% |
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.975, TAw acc= 67.0% | Valid: time=  0.4s loss=0.710, TAw acc= 73.8% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.965, TAw acc= 66.8% | Valid: time=  0.4s loss=0.768, TAw acc= 72.4% |
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.977, TAw acc= 65.8% | Valid: time=  0.4s loss=0.712, TAw acc= 74.2% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.977, TAw acc= 66.4% | Valid: time=  0.4s loss=0.704, TAw acc= 73.8% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.979, TAw acc= 65.7% | Valid: time=  0.4s loss=0.723, TAw acc= 72.2% |
| Epoch  24, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.962, TAw acc= 66.9% | Valid: time=  0.4s loss=0.643, TAw acc= 75.0% | *
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 66.4% | Valid: time=  0.4s loss=0.676, TAw acc= 75.2% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 67.2% | Valid: time=  0.4s loss=0.664, TAw acc= 75.8% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.953, TAw acc= 68.1% | Valid: time=  0.4s loss=0.698, TAw acc= 74.2% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.956, TAw acc= 67.8% | Valid: time=  0.4s loss=0.698, TAw acc= 73.0% |
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.941, TAw acc= 67.5% | Valid: time=  0.4s loss=0.670, TAw acc= 74.6% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.973, TAw acc= 66.8% | Valid: time=  0.4s loss=0.731, TAw acc= 71.6% |
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.956, TAw acc= 67.5% | Valid: time=  0.4s loss=0.685, TAw acc= 73.8% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.952, TAw acc= 66.2% | Valid: time=  0.4s loss=0.691, TAw acc= 74.6% |
| Epoch  33, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.929, TAw acc= 67.9% | Valid: time=  0.4s loss=0.699, TAw acc= 74.2% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.943, TAw acc= 67.1% | Valid: time=  0.4s loss=0.703, TAw acc= 73.4% |
| Epoch  35, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.936, TAw acc= 68.7% | Valid: time=  0.4s loss=0.686, TAw acc= 74.4% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.930, TAw acc= 68.7% | Valid: time=  0.4s loss=0.679, TAw acc= 73.6% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 67.8% | Valid: time=  0.4s loss=0.694, TAw acc= 73.0% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.958, TAw acc= 67.4% | Valid: time=  0.4s loss=0.690, TAw acc= 73.0% |
| Epoch  39, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.968, TAw acc= 67.0% | Valid: time=  0.4s loss=0.726, TAw acc= 72.6% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.947, TAw acc= 67.7% | Valid: time=  0.4s loss=0.708, TAw acc= 74.8% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.936, TAw acc= 67.6% | Valid: time=  0.4s loss=0.657, TAw acc= 73.2% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.926, TAw acc= 67.4% | Valid: time=  0.4s loss=0.663, TAw acc= 75.4% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.935, TAw acc= 67.5% | Valid: time=  0.4s loss=0.660, TAw acc= 73.8% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.910, TAw acc= 68.0% | Valid: time=  0.4s loss=0.649, TAw acc= 75.2% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.905, TAw acc= 68.5% | Valid: time=  0.4s loss=0.713, TAw acc= 74.2% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.948, TAw acc= 67.6% | Valid: time=  0.4s loss=0.656, TAw acc= 75.4% |
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.910, TAw acc= 68.7% | Valid: time=  0.4s loss=0.693, TAw acc= 75.0% |
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.931, TAw acc= 67.4% | Valid: time=  0.4s loss=0.651, TAw acc= 76.0% |
| Epoch  49, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.931, TAw acc= 67.7% | Valid: time=  0.4s loss=0.739, TAw acc= 72.8% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.958, TAw acc= 66.0% | Valid: time=  0.4s loss=0.723, TAw acc= 73.4% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.922, TAw acc= 68.0% | Valid: time=  0.4s loss=0.665, TAw acc= 75.2% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.933, TAw acc= 67.2% | Valid: time=  0.4s loss=0.673, TAw acc= 75.6% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 68.2% | Valid: time=  0.4s loss=0.696, TAw acc= 75.8% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.943, TAw acc= 67.3% | Valid: time=  0.4s loss=0.672, TAw acc= 75.6% | lr=8.8e-03
| Epoch  55, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.951, TAw acc= 67.2% | Valid: time=  0.4s loss=0.707, TAw acc= 73.0% |
| Epoch  56, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.953, TAw acc= 66.8% | Valid: time=  0.4s loss=0.713, TAw acc= 72.6% |
| Epoch  57, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.012, TAw acc= 66.8% | Valid: time=  0.4s loss=0.665, TAw acc= 74.6% |
| Epoch  58, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.910, TAw acc= 67.7% | Valid: time=  0.4s loss=0.700, TAw acc= 73.0% |
| Epoch  59, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 67.8% | Valid: time=  0.4s loss=0.679, TAw acc= 73.6% |
| Epoch  60, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.928, TAw acc= 67.9% | Valid: time=  0.4s loss=0.666, TAw acc= 75.2% |
| Epoch  61, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.967, TAw acc= 67.2% | Valid: time=  0.4s loss=0.654, TAw acc= 75.8% |
| Epoch  62, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.952, TAw acc= 67.5% | Valid: time=  0.4s loss=0.679, TAw acc= 74.2% |
| Epoch  63, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.939, TAw acc= 67.0% | Valid: time=  0.4s loss=0.715, TAw acc= 74.6% |
| Epoch  64, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.959, TAw acc= 66.7% | Valid: time=  0.4s loss=0.708, TAw acc= 74.0% |
| Epoch  65, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.929, TAw acc= 68.2% | Valid: time=  0.4s loss=0.673, TAw acc= 75.0% |
| Epoch  66, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.942, TAw acc= 67.7% | Valid: time=  0.4s loss=0.659, TAw acc= 75.2% |
| Epoch  67, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.926, TAw acc= 68.0% | Valid: time=  0.4s loss=0.665, TAw acc= 75.2% |
| Epoch  68, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.932, TAw acc= 68.6% | Valid: time=  0.4s loss=0.664, TAw acc= 74.8% |
| Epoch  69, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.933, TAw acc= 67.9% | Valid: time=  0.4s loss=0.674, TAw acc= 74.4% |
| Epoch  70, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.944, TAw acc= 67.9% | Valid: time=  0.4s loss=0.654, TAw acc= 76.0% |
| Epoch  71, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.922, TAw acc= 68.6% | Valid: time=  0.4s loss=0.688, TAw acc= 74.8% |
| Epoch  72, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.946, TAw acc= 67.2% | Valid: time=  0.4s loss=0.668, TAw acc= 74.6% |
| Epoch  73, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.919, TAw acc= 68.8% | Valid: time=  0.4s loss=0.685, TAw acc= 74.6% |
| Epoch  74, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.947, TAw acc= 67.8% | Valid: time=  0.4s loss=0.659, TAw acc= 75.6% |
| Epoch  75, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 69.2% | Valid: time=  0.4s loss=0.656, TAw acc= 76.6% |
| Epoch  76, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.958, TAw acc= 67.3% | Valid: time=  0.4s loss=0.673, TAw acc= 75.6% |
| Epoch  77, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.925, TAw acc= 67.5% | Valid: time=  0.4s loss=0.696, TAw acc= 75.8% |
| Epoch  78, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.919, TAw acc= 68.4% | Valid: time=  0.4s loss=0.670, TAw acc= 75.0% |
| Epoch  79, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.901, TAw acc= 69.0% | Valid: time=  0.4s loss=0.678, TAw acc= 75.2% |
| Epoch  80, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.930, TAw acc= 68.1% | Valid: time=  0.4s loss=0.697, TAw acc= 73.8% |
| Epoch  81, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.942, TAw acc= 67.5% | Valid: time=  0.4s loss=0.675, TAw acc= 75.2% |
| Epoch  82, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.904, TAw acc= 69.0% | Valid: time=  0.4s loss=0.665, TAw acc= 75.6% |
| Epoch  83, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.937, TAw acc= 67.9% | Valid: time=  0.4s loss=0.687, TAw acc= 73.2% |
| Epoch  84, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.928, TAw acc= 68.4% | Valid: time=  0.4s loss=0.650, TAw acc= 75.4% | lr=2.9e-03
| Epoch  85, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.967, TAw acc= 67.0% | Valid: time=  0.4s loss=0.660, TAw acc= 75.6% |
| Epoch  86, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.942, TAw acc= 67.6% | Valid: time=  0.4s loss=0.690, TAw acc= 73.2% |
| Epoch  87, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.958, TAw acc= 67.3% | Valid: time=  0.4s loss=0.675, TAw acc= 75.0% |
| Epoch  88, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.989, TAw acc= 66.7% | Valid: time=  0.4s loss=0.658, TAw acc= 75.0% |
| Epoch  89, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.950, TAw acc= 67.1% | Valid: time=  0.4s loss=0.679, TAw acc= 74.6% |
| Epoch  90, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.966, TAw acc= 67.6% | Valid: time=  0.4s loss=0.664, TAw acc= 75.4% |
| Epoch  91, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 67.7% | Valid: time=  0.4s loss=0.663, TAw acc= 74.6% |
| Epoch  92, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 67.4% | Valid: time=  0.4s loss=0.677, TAw acc= 74.8% |
| Epoch  93, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.950, TAw acc= 66.6% | Valid: time=  0.4s loss=0.690, TAw acc= 74.6% |
| Epoch  94, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 67.3% | Valid: time=  0.4s loss=0.679, TAw acc= 75.0% |
| Epoch  95, lr=2.9e-03 time=  2.9s/  1.9s | Train: loss=0.965, TAw acc= 69.3% | Valid: time=  0.4s loss=0.665, TAw acc= 73.2% |
| Epoch  96, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.948, TAw acc= 67.7% | Valid: time=  0.4s loss=0.675, TAw acc= 74.2% |
| Epoch  97, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.897, TAw acc= 69.3% | Valid: time=  0.4s loss=0.662, TAw acc= 74.2% |
| Epoch  98, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 67.1% | Valid: time=  0.4s loss=0.686, TAw acc= 73.4% |
| Epoch  99, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.928, TAw acc= 68.2% | Valid: time=  0.4s loss=0.680, TAw acc= 74.6% |
| Epoch 100, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.929, TAw acc= 67.4% | Valid: time=  0.4s loss=0.677, TAw acc= 75.0% |
== Rank Reduction [task:3] ==
best_loss=0.643,  best_acc=0.750
 r=256, loss=0.691, acc=0.742
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.675, acc=0.746
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.688, acc=0.736
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.682, acc=0.746
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.672, acc=0.758
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.668, acc=0.746
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.666, acc=0.754
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.665, acc=0.764
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.667, acc=0.756
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.665, acc=0.746
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.654, acc=0.750
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.642, acc=0.750
 loss_margin=0.006, acc_margin=0.004
best_r=608, loss=0.642, acc=0.750
== Header Training for Low Rank [task:3] ==
loss=0.642 acc=0.750
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.952, TAw acc= 67.0% | Valid: time=  0.4s loss=0.628, TAw acc= 77.0% | *
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.943, TAw acc= 67.4% | Valid: time=  0.4s loss=0.631, TAw acc= 76.4% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.931, TAw acc= 68.6% | Valid: time=  0.4s loss=0.635, TAw acc= 76.6% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.947, TAw acc= 67.5% | Valid: time=  0.4s loss=0.625, TAw acc= 77.4% | *
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.928, TAw acc= 68.6% | Valid: time=  0.4s loss=0.631, TAw acc= 76.6% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.939, TAw acc= 68.2% | Valid: time=  0.4s loss=0.627, TAw acc= 76.8% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 68.5% | Valid: time=  0.4s loss=0.632, TAw acc= 77.6% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.944, TAw acc= 68.4% | Valid: time=  0.4s loss=0.621, TAw acc= 77.6% | *
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 68.9% | Valid: time=  0.4s loss=0.623, TAw acc= 77.6% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.918, TAw acc= 67.8% | Valid: time=  0.4s loss=0.621, TAw acc= 77.0% | *
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 68.4% | Valid: time=  0.4s loss=0.627, TAw acc= 77.8% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 68.1% | Valid: time=  0.4s loss=0.633, TAw acc= 78.0% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.918, TAw acc= 68.8% | Valid: time=  0.4s loss=0.627, TAw acc= 77.4% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.906, TAw acc= 68.0% | Valid: time=  0.4s loss=0.624, TAw acc= 77.6% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.914, TAw acc= 68.2% | Valid: time=  0.4s loss=0.634, TAw acc= 75.8% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.919, TAw acc= 68.6% | Valid: time=  0.6s loss=0.624, TAw acc= 77.6% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.918, TAw acc= 68.4% | Valid: time=  0.4s loss=0.630, TAw acc= 77.2% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.904, TAw acc= 68.8% | Valid: time=  0.4s loss=0.630, TAw acc= 77.2% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.898, TAw acc= 68.7% | Valid: time=  0.4s loss=0.634, TAw acc= 76.6% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.885, TAw acc= 69.7% | Valid: time=  0.4s loss=0.623, TAw acc= 76.4% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.889, TAw acc= 69.6% | Valid: time=  0.4s loss=0.626, TAw acc= 76.6% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 69.6% | Valid: time=  0.4s loss=0.628, TAw acc= 77.2% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 69.7% | Valid: time=  0.4s loss=0.621, TAw acc= 77.0% | *
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 70.2% | Valid: time=  0.4s loss=0.631, TAw acc= 77.8% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 69.1% | Valid: time=  0.4s loss=0.635, TAw acc= 77.2% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.894, TAw acc= 69.1% | Valid: time=  0.4s loss=0.620, TAw acc= 76.2% | *
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 69.0% | Valid: time=  0.4s loss=0.624, TAw acc= 76.2% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.908, TAw acc= 68.3% | Valid: time=  0.4s loss=0.622, TAw acc= 76.8% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 69.9% | Valid: time=  0.4s loss=0.625, TAw acc= 76.4% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 69.6% | Valid: time=  0.4s loss=0.626, TAw acc= 77.4% |
| Epoch  31, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.896, TAw acc= 68.8% | Valid: time=  0.4s loss=0.630, TAw acc= 76.8% |
| Epoch  32, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 69.5% | Valid: time=  0.4s loss=0.625, TAw acc= 77.4% |
| Epoch  33, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.895, TAw acc= 69.7% | Valid: time=  0.5s loss=0.630, TAw acc= 77.0% |
| Epoch  34, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 69.2% | Valid: time=  0.4s loss=0.641, TAw acc= 76.6% |
| Epoch  35, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.887, TAw acc= 69.9% | Valid: time=  0.4s loss=0.623, TAw acc= 77.2% |
| Epoch  36, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.900, TAw acc= 69.1% | Valid: time=  0.4s loss=0.623, TAw acc= 77.0% |
| Epoch  37, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 70.1% | Valid: time=  0.4s loss=0.627, TAw acc= 77.2% |
| Epoch  38, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 69.8% | Valid: time=  0.4s loss=0.640, TAw acc= 76.6% |
| Epoch  39, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 70.3% | Valid: time=  0.4s loss=0.635, TAw acc= 76.8% |
| Epoch  40, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 69.0% | Valid: time=  0.4s loss=0.637, TAw acc= 76.4% |
| Epoch  41, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 70.4% | Valid: time=  0.5s loss=0.635, TAw acc= 77.2% |
| Epoch  42, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 70.4% | Valid: time=  0.4s loss=0.629, TAw acc= 77.2% |
| Epoch  43, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.840, TAw acc= 70.6% | Valid: time=  0.4s loss=0.635, TAw acc= 78.0% |
| Epoch  44, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 69.3% | Valid: time=  0.4s loss=0.645, TAw acc= 75.6% |
| Epoch  45, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 70.4% | Valid: time=  0.4s loss=0.629, TAw acc= 77.0% |
| Epoch  46, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 69.6% | Valid: time=  0.4s loss=0.626, TAw acc= 76.8% |
| Epoch  47, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.856, TAw acc= 70.5% | Valid: time=  0.4s loss=0.628, TAw acc= 77.8% |
| Epoch  48, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.887, TAw acc= 69.4% | Valid: time=  0.4s loss=0.628, TAw acc= 76.6% |
| Epoch  49, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 70.3% | Valid: time=  0.4s loss=0.627, TAw acc= 77.0% |
| Epoch  50, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 68.9% | Valid: time=  0.4s loss=0.630, TAw acc= 78.2% |
| Epoch  51, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.865, TAw acc= 69.8% | Valid: time=  0.4s loss=0.613, TAw acc= 77.4% | *
| Epoch  52, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 70.3% | Valid: time=  0.4s loss=0.624, TAw acc= 77.0% |
| Epoch  53, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 70.2% | Valid: time=  0.4s loss=0.632, TAw acc= 78.2% |
| Epoch  54, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 70.6% | Valid: time=  0.4s loss=0.630, TAw acc= 77.0% |
| Epoch  55, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 70.0% | Valid: time=  0.4s loss=0.628, TAw acc= 76.6% |
| Epoch  56, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.878, TAw acc= 69.6% | Valid: time=  0.4s loss=0.634, TAw acc= 76.8% |
| Epoch  57, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.860, TAw acc= 70.1% | Valid: time=  0.4s loss=0.632, TAw acc= 76.8% |
| Epoch  58, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 70.8% | Valid: time=  0.4s loss=0.628, TAw acc= 77.2% |
| Epoch  59, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.847, TAw acc= 70.4% | Valid: time=  0.4s loss=0.627, TAw acc= 76.8% |
| Epoch  60, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 70.6% | Valid: time=  0.4s loss=0.627, TAw acc= 77.4% |
| Epoch  61, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 70.0% | Valid: time=  0.4s loss=0.645, TAw acc= 76.2% |
| Epoch  62, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 70.2% | Valid: time=  0.4s loss=0.636, TAw acc= 76.6% |
| Epoch  63, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.827, TAw acc= 71.2% | Valid: time=  0.4s loss=0.635, TAw acc= 76.2% |
| Epoch  64, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.843, TAw acc= 71.1% | Valid: time=  0.4s loss=0.633, TAw acc= 78.0% |
| Epoch  65, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 70.8% | Valid: time=  0.4s loss=0.628, TAw acc= 76.6% |
| Epoch  66, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 70.7% | Valid: time=  0.4s loss=0.624, TAw acc= 76.8% |
| Epoch  67, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.847, TAw acc= 71.3% | Valid: time=  0.4s loss=0.635, TAw acc= 77.0% |
| Epoch  68, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.844, TAw acc= 71.2% | Valid: time=  0.4s loss=0.638, TAw acc= 76.2% |
| Epoch  69, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.836, TAw acc= 71.4% | Valid: time=  0.4s loss=0.640, TAw acc= 77.2% |
| Epoch  70, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.850, TAw acc= 70.4% | Valid: time=  0.4s loss=0.637, TAw acc= 76.6% |
| Epoch  71, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 70.8% | Valid: time=  0.4s loss=0.639, TAw acc= 77.4% |
| Epoch  72, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 70.4% | Valid: time=  0.4s loss=0.629, TAw acc= 76.8% |
| Epoch  73, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.836, TAw acc= 71.0% | Valid: time=  0.4s loss=0.634, TAw acc= 76.4% |
| Epoch  74, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.837, TAw acc= 71.6% | Valid: time=  0.4s loss=0.632, TAw acc= 76.2% |
| Epoch  75, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.835, TAw acc= 71.3% | Valid: time=  0.4s loss=0.641, TAw acc= 77.0% |
| Epoch  76, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.888, TAw acc= 68.8% | Valid: time=  0.4s loss=0.642, TAw acc= 76.4% |
| Epoch  77, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.824, TAw acc= 71.8% | Valid: time=  0.4s loss=0.634, TAw acc= 77.6% |
| Epoch  78, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.847, TAw acc= 70.5% | Valid: time=  0.4s loss=0.643, TAw acc= 76.4% |
| Epoch  79, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.858, TAw acc= 71.0% | Valid: time=  0.4s loss=0.637, TAw acc= 76.2% |
| Epoch  80, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.827, TAw acc= 72.0% | Valid: time=  0.4s loss=0.640, TAw acc= 76.8% |
| Epoch  81, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 70.4% | Valid: time=  0.4s loss=0.628, TAw acc= 76.4% | lr=2.9e-03
| Epoch  82, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.858, TAw acc= 70.4% | Valid: time=  0.4s loss=0.617, TAw acc= 77.2% |
| Epoch  83, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 70.3% | Valid: time=  0.4s loss=0.618, TAw acc= 77.2% |
| Epoch  84, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 69.6% | Valid: time=  0.4s loss=0.624, TAw acc= 77.4% |
| Epoch  85, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.838, TAw acc= 71.4% | Valid: time=  0.4s loss=0.619, TAw acc= 77.8% |
| Epoch  86, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 70.0% | Valid: time=  0.4s loss=0.623, TAw acc= 77.8% |
| Epoch  87, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 70.8% | Valid: time=  0.4s loss=0.624, TAw acc= 77.6% |
| Epoch  88, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 70.8% | Valid: time=  0.4s loss=0.621, TAw acc= 78.0% |
| Epoch  89, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.824, TAw acc= 71.8% | Valid: time=  0.4s loss=0.621, TAw acc= 77.0% |
| Epoch  90, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 69.0% | Valid: time=  0.4s loss=0.624, TAw acc= 77.0% |
| Epoch  91, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.868, TAw acc= 70.3% | Valid: time=  0.4s loss=0.621, TAw acc= 78.0% |
| Epoch  92, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.849, TAw acc= 70.0% | Valid: time=  0.4s loss=0.621, TAw acc= 77.2% |
| Epoch  93, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 70.2% | Valid: time=  0.4s loss=0.619, TAw acc= 77.6% |
| Epoch  94, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 69.8% | Valid: time=  0.4s loss=0.626, TAw acc= 77.8% |
| Epoch  95, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.850, TAw acc= 70.8% | Valid: time=  0.4s loss=0.630, TAw acc= 77.2% |
| Epoch  96, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 70.6% | Valid: time=  0.4s loss=0.625, TAw acc= 76.6% |
| Epoch  97, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 69.6% | Valid: time=  0.4s loss=0.628, TAw acc= 76.6% |
| Epoch  98, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.850, TAw acc= 70.2% | Valid: time=  0.4s loss=0.625, TAw acc= 77.0% |
| Epoch  99, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 70.3% | Valid: time=  0.4s loss=0.622, TAw acc= 77.2% |
| Epoch 100, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.856, TAw acc= 70.5% | Valid: time=  0.4s loss=0.625, TAw acc= 77.0% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc= 15.9%, forg= 61.4% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 52.3%, forg= 13.1% <<<
>>> Test on task  2 : loss=0.609 | TAw acc= 78.9%, forg=  0.8%| TAg acc= 27.8%, forg= 10.7% <<<
>>> Test on task  3 : loss=0.610 | TAw acc= 79.8%, forg=  0.0%| TAg acc= 40.7%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  4
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-4): 5 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.072, TAw acc= 64.3% | Valid: time=  0.4s loss=0.673, TAw acc= 78.4% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.013, TAw acc= 66.9% | Valid: time=  0.4s loss=0.514, TAw acc= 84.0% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.979, TAw acc= 68.0% | Valid: time=  0.4s loss=0.544, TAw acc= 82.0% |
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.977, TAw acc= 66.3% | Valid: time=  0.4s loss=0.531, TAw acc= 85.4% |
| Epoch   5, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.951, TAw acc= 68.8% | Valid: time=  0.4s loss=0.469, TAw acc= 85.4% | *
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.948, TAw acc= 68.7% | Valid: time=  0.4s loss=0.504, TAw acc= 84.8% |
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.930, TAw acc= 68.4% | Valid: time=  0.4s loss=0.489, TAw acc= 84.4% |
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.960, TAw acc= 68.1% | Valid: time=  0.4s loss=0.521, TAw acc= 83.8% |
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.941, TAw acc= 69.3% | Valid: time=  0.4s loss=0.495, TAw acc= 84.8% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.936, TAw acc= 68.6% | Valid: time=  0.4s loss=0.482, TAw acc= 85.0% |
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.918, TAw acc= 69.4% | Valid: time=  0.4s loss=0.512, TAw acc= 84.2% |
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.889, TAw acc= 70.7% | Valid: time=  0.4s loss=0.504, TAw acc= 84.4% |
| Epoch  13, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.913, TAw acc= 69.1% | Valid: time=  0.4s loss=0.507, TAw acc= 84.2% |
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.916, TAw acc= 68.4% | Valid: time=  0.4s loss=0.476, TAw acc= 83.2% |
| Epoch  15, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.868, TAw acc= 70.9% | Valid: time=  0.4s loss=0.489, TAw acc= 84.2% |
| Epoch  16, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.903, TAw acc= 70.3% | Valid: time=  0.4s loss=0.454, TAw acc= 85.2% | *
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.896, TAw acc= 70.0% | Valid: time=  0.4s loss=0.457, TAw acc= 86.0% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.908, TAw acc= 69.7% | Valid: time=  0.4s loss=0.484, TAw acc= 84.6% |
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.878, TAw acc= 70.4% | Valid: time=  0.4s loss=0.499, TAw acc= 83.8% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.876, TAw acc= 70.8% | Valid: time=  0.4s loss=0.442, TAw acc= 85.8% | *
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.862, TAw acc= 71.5% | Valid: time=  0.4s loss=0.451, TAw acc= 85.2% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.854, TAw acc= 71.8% | Valid: time=  0.4s loss=0.432, TAw acc= 87.6% | *
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.901, TAw acc= 71.0% | Valid: time=  0.4s loss=0.474, TAw acc= 84.4% |
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.865, TAw acc= 70.8% | Valid: time=  0.4s loss=0.472, TAw acc= 85.2% |
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.880, TAw acc= 70.5% | Valid: time=  0.4s loss=0.441, TAw acc= 86.2% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.873, TAw acc= 71.2% | Valid: time=  0.4s loss=0.428, TAw acc= 86.2% | *
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.869, TAw acc= 70.9% | Valid: time=  0.4s loss=0.417, TAw acc= 86.4% | *
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.857, TAw acc= 71.4% | Valid: time=  0.4s loss=0.461, TAw acc= 85.2% |
| Epoch  29, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.852, TAw acc= 71.3% | Valid: time=  0.4s loss=0.478, TAw acc= 84.4% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.859, TAw acc= 72.0% | Valid: time=  0.4s loss=0.448, TAw acc= 85.0% |
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.888, TAw acc= 70.6% | Valid: time=  0.4s loss=0.424, TAw acc= 85.6% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.894, TAw acc= 70.0% | Valid: time=  0.4s loss=0.448, TAw acc= 85.8% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.852, TAw acc= 72.6% | Valid: time=  0.4s loss=0.426, TAw acc= 86.4% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.848, TAw acc= 71.6% | Valid: time=  0.4s loss=0.459, TAw acc= 84.8% |
| Epoch  35, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.831, TAw acc= 71.0% | Valid: time=  0.4s loss=0.480, TAw acc= 85.2% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.859, TAw acc= 71.0% | Valid: time=  0.4s loss=0.436, TAw acc= 86.4% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.849, TAw acc= 71.2% | Valid: time=  0.4s loss=0.483, TAw acc= 85.6% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.847, TAw acc= 71.7% | Valid: time=  0.4s loss=0.462, TAw acc= 84.6% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.852, TAw acc= 71.9% | Valid: time=  0.4s loss=0.429, TAw acc= 85.2% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.851, TAw acc= 72.4% | Valid: time=  0.4s loss=0.472, TAw acc= 85.4% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.828, TAw acc= 72.4% | Valid: time=  0.4s loss=0.471, TAw acc= 85.0% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.862, TAw acc= 72.0% | Valid: time=  0.4s loss=0.457, TAw acc= 85.2% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.831, TAw acc= 72.2% | Valid: time=  0.4s loss=0.424, TAw acc= 86.0% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.837, TAw acc= 71.6% | Valid: time=  0.4s loss=0.458, TAw acc= 85.4% |
| Epoch  45, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.847, TAw acc= 72.2% | Valid: time=  0.4s loss=0.451, TAw acc= 85.2% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.841, TAw acc= 72.7% | Valid: time=  0.4s loss=0.481, TAw acc= 85.0% |
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.814, TAw acc= 73.0% | Valid: time=  0.4s loss=0.487, TAw acc= 85.4% |
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.849, TAw acc= 72.3% | Valid: time=  0.4s loss=0.443, TAw acc= 86.0% |
| Epoch  49, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.842, TAw acc= 72.7% | Valid: time=  0.4s loss=0.442, TAw acc= 85.4% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.872, TAw acc= 70.5% | Valid: time=  0.4s loss=0.505, TAw acc= 84.6% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.832, TAw acc= 72.2% | Valid: time=  0.4s loss=0.426, TAw acc= 85.4% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.805, TAw acc= 73.0% | Valid: time=  0.4s loss=0.451, TAw acc= 86.2% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.827, TAw acc= 71.9% | Valid: time=  0.4s loss=0.412, TAw acc= 86.8% | *
| Epoch  54, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.840, TAw acc= 72.6% | Valid: time=  0.4s loss=0.402, TAw acc= 85.8% | *
| Epoch  55, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.852, TAw acc= 71.9% | Valid: time=  0.4s loss=0.429, TAw acc= 85.4% |
| Epoch  56, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.830, TAw acc= 72.9% | Valid: time=  0.4s loss=0.431, TAw acc= 85.0% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.842, TAw acc= 72.2% | Valid: time=  0.4s loss=0.397, TAw acc= 87.6% | *
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.841, TAw acc= 72.4% | Valid: time=  0.4s loss=0.464, TAw acc= 85.8% |
| Epoch  59, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.835, TAw acc= 72.2% | Valid: time=  0.4s loss=0.493, TAw acc= 85.2% |
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.870, TAw acc= 71.0% | Valid: time=  0.4s loss=0.423, TAw acc= 85.4% |
| Epoch  61, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.828, TAw acc= 72.8% | Valid: time=  0.4s loss=0.474, TAw acc= 84.6% |
| Epoch  62, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.813, TAw acc= 73.6% | Valid: time=  0.4s loss=0.479, TAw acc= 84.2% |
| Epoch  63, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.863, TAw acc= 72.5% | Valid: time=  0.4s loss=0.457, TAw acc= 85.8% |
| Epoch  64, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.859, TAw acc= 72.2% | Valid: time=  0.4s loss=0.450, TAw acc= 85.4% |
| Epoch  65, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.803, TAw acc= 74.1% | Valid: time=  0.4s loss=0.467, TAw acc= 85.0% |
| Epoch  66, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.816, TAw acc= 73.2% | Valid: time=  0.4s loss=0.485, TAw acc= 84.8% |
| Epoch  67, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.814, TAw acc= 72.7% | Valid: time=  0.4s loss=0.472, TAw acc= 85.2% |
| Epoch  68, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.818, TAw acc= 72.2% | Valid: time=  0.4s loss=0.475, TAw acc= 85.6% |
| Epoch  69, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.826, TAw acc= 72.7% | Valid: time=  0.4s loss=0.457, TAw acc= 85.6% |
| Epoch  70, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.812, TAw acc= 73.5% | Valid: time=  0.4s loss=0.468, TAw acc= 84.8% |
| Epoch  71, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.778, TAw acc= 72.8% | Valid: time=  0.4s loss=0.498, TAw acc= 85.6% |
| Epoch  72, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.830, TAw acc= 72.3% | Valid: time=  0.4s loss=0.453, TAw acc= 85.8% |
| Epoch  73, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.811, TAw acc= 73.2% | Valid: time=  0.4s loss=0.439, TAw acc= 86.2% |
| Epoch  74, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.824, TAw acc= 71.7% | Valid: time=  0.4s loss=0.441, TAw acc= 86.4% |
| Epoch  75, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.789, TAw acc= 73.5% | Valid: time=  0.4s loss=0.426, TAw acc= 87.2% |
| Epoch  76, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.834, TAw acc= 73.4% | Valid: time=  0.4s loss=0.428, TAw acc= 86.8% |
| Epoch  77, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.803, TAw acc= 73.0% | Valid: time=  0.4s loss=0.432, TAw acc= 86.4% |
| Epoch  78, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.803, TAw acc= 73.1% | Valid: time=  0.4s loss=0.458, TAw acc= 85.0% |
| Epoch  79, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.803, TAw acc= 73.0% | Valid: time=  0.4s loss=0.457, TAw acc= 86.2% |
| Epoch  80, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.816, TAw acc= 72.7% | Valid: time=  0.4s loss=0.407, TAw acc= 85.8% |
| Epoch  81, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.785, TAw acc= 74.6% | Valid: time=  0.4s loss=0.438, TAw acc= 85.4% |
| Epoch  82, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.790, TAw acc= 74.8% | Valid: time=  0.4s loss=0.418, TAw acc= 85.8% |
| Epoch  83, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.834, TAw acc= 72.4% | Valid: time=  0.4s loss=0.409, TAw acc= 86.8% |
| Epoch  84, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.789, TAw acc= 73.6% | Valid: time=  0.4s loss=0.416, TAw acc= 87.2% |
| Epoch  85, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.811, TAw acc= 73.3% | Valid: time=  0.4s loss=0.441, TAw acc= 85.8% |
| Epoch  86, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.807, TAw acc= 72.8% | Valid: time=  0.4s loss=0.450, TAw acc= 85.6% |
| Epoch  87, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.804, TAw acc= 74.4% | Valid: time=  0.4s loss=0.444, TAw acc= 85.8% | lr=8.8e-03
| Epoch  88, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.815, TAw acc= 73.2% | Valid: time=  0.4s loss=0.434, TAw acc= 86.4% |
| Epoch  89, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.831, TAw acc= 72.8% | Valid: time=  0.4s loss=0.437, TAw acc= 85.6% |
| Epoch  90, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.811, TAw acc= 72.8% | Valid: time=  0.4s loss=0.436, TAw acc= 86.2% |
| Epoch  91, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.821, TAw acc= 72.9% | Valid: time=  0.4s loss=0.443, TAw acc= 85.8% |
| Epoch  92, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.824, TAw acc= 73.4% | Valid: time=  0.4s loss=0.420, TAw acc= 85.2% |
| Epoch  93, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.808, TAw acc= 72.7% | Valid: time=  0.4s loss=0.478, TAw acc= 85.2% |
| Epoch  94, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.815, TAw acc= 73.2% | Valid: time=  0.4s loss=0.468, TAw acc= 85.6% |
| Epoch  95, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.783, TAw acc= 73.5% | Valid: time=  0.4s loss=0.467, TAw acc= 85.2% |
| Epoch  96, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.811, TAw acc= 73.9% | Valid: time=  0.4s loss=0.466, TAw acc= 85.4% |
| Epoch  97, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.812, TAw acc= 73.0% | Valid: time=  0.4s loss=0.453, TAw acc= 85.4% |
| Epoch  98, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.825, TAw acc= 72.9% | Valid: time=  0.4s loss=0.447, TAw acc= 85.8% |
| Epoch  99, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.830, TAw acc= 72.2% | Valid: time=  0.4s loss=0.444, TAw acc= 85.4% |
| Epoch 100, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.819, TAw acc= 72.3% | Valid: time=  0.4s loss=0.435, TAw acc= 85.8% |
== Rank Reduction [task:4] ==
best_loss=0.397,  best_acc=0.876
 r=256, loss=0.471, acc=0.848
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.452, acc=0.858
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.437, acc=0.868
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.421, acc=0.872
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.416, acc=0.870
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.406, acc=0.870
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.401, acc=0.872
 loss_margin=0.006, acc_margin=0.004
best_r=448, loss=0.401, acc=0.872
== Header Training for Low Rank [task:4] ==
loss=0.401 acc=0.872
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.900, TAw acc= 72.2% | Valid: time=  0.4s loss=0.460, TAw acc= 85.6% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.900, TAw acc= 70.4% | Valid: time=  0.4s loss=0.471, TAw acc= 85.6% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.889, TAw acc= 71.3% | Valid: time=  0.4s loss=0.471, TAw acc= 85.4% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 71.8% | Valid: time=  0.4s loss=0.458, TAw acc= 85.6% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.878, TAw acc= 71.6% | Valid: time=  0.4s loss=0.448, TAw acc= 85.2% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 72.2% | Valid: time=  0.4s loss=0.452, TAw acc= 85.4% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.7% | Valid: time=  0.4s loss=0.452, TAw acc= 85.4% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 71.3% | Valid: time=  0.4s loss=0.449, TAw acc= 86.0% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.871, TAw acc= 71.5% | Valid: time=  0.4s loss=0.450, TAw acc= 86.0% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 71.6% | Valid: time=  0.4s loss=0.450, TAw acc= 85.4% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.860, TAw acc= 71.2% | Valid: time=  0.4s loss=0.457, TAw acc= 86.2% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 71.8% | Valid: time=  0.4s loss=0.446, TAw acc= 86.0% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.855, TAw acc= 71.7% | Valid: time=  0.4s loss=0.448, TAw acc= 85.2% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 70.9% | Valid: time=  0.4s loss=0.448, TAw acc= 85.2% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 72.1% | Valid: time=  0.4s loss=0.446, TAw acc= 86.2% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.889, TAw acc= 71.3% | Valid: time=  0.4s loss=0.453, TAw acc= 85.6% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.849, TAw acc= 72.3% | Valid: time=  0.4s loss=0.445, TAw acc= 86.2% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.849, TAw acc= 72.1% | Valid: time=  0.4s loss=0.441, TAw acc= 85.6% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 72.6% | Valid: time=  0.4s loss=0.447, TAw acc= 85.4% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 71.9% | Valid: time=  0.4s loss=0.435, TAw acc= 85.4% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 72.6% | Valid: time=  0.4s loss=0.441, TAw acc= 85.8% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.839, TAw acc= 72.6% | Valid: time=  0.4s loss=0.439, TAw acc= 85.8% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 72.9% | Valid: time=  0.4s loss=0.434, TAw acc= 85.2% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.836, TAw acc= 73.3% | Valid: time=  0.4s loss=0.432, TAw acc= 85.4% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.826, TAw acc= 72.4% | Valid: time=  0.4s loss=0.432, TAw acc= 85.2% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.825, TAw acc= 73.5% | Valid: time=  0.4s loss=0.437, TAw acc= 85.0% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 71.9% | Valid: time=  0.4s loss=0.440, TAw acc= 84.8% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.843, TAw acc= 72.6% | Valid: time=  0.4s loss=0.435, TAw acc= 85.4% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.833, TAw acc= 72.5% | Valid: time=  0.4s loss=0.430, TAw acc= 85.4% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.807, TAw acc= 73.3% | Valid: time=  0.4s loss=0.441, TAw acc= 85.6% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.932, TAw acc= 70.1% | Valid: time=  0.4s loss=0.422, TAw acc= 86.4% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 71.1% | Valid: time=  0.4s loss=0.445, TAw acc= 85.8% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.887, TAw acc= 71.9% | Valid: time=  0.4s loss=0.459, TAw acc= 85.6% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.888, TAw acc= 71.8% | Valid: time=  0.4s loss=0.463, TAw acc= 85.2% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.912, TAw acc= 70.9% | Valid: time=  0.4s loss=0.465, TAw acc= 85.0% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 71.7% | Valid: time=  0.4s loss=0.464, TAw acc= 85.0% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 72.0% | Valid: time=  0.4s loss=0.460, TAw acc= 85.0% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 71.5% | Valid: time=  0.4s loss=0.458, TAw acc= 85.4% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 70.9% | Valid: time=  0.4s loss=0.458, TAw acc= 85.4% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 72.6% | Valid: time=  0.4s loss=0.455, TAw acc= 85.6% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.888, TAw acc= 72.2% | Valid: time=  0.4s loss=0.456, TAw acc= 85.4% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 72.2% | Valid: time=  0.4s loss=0.460, TAw acc= 85.0% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.6% | Valid: time=  0.4s loss=0.455, TAw acc= 85.4% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.871, TAw acc= 72.6% | Valid: time=  0.4s loss=0.458, TAw acc= 85.0% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 71.2% | Valid: time=  0.4s loss=0.453, TAw acc= 85.2% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 72.5% | Valid: time=  0.4s loss=0.454, TAw acc= 85.8% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 71.9% | Valid: time=  0.4s loss=0.449, TAw acc= 85.4% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 72.4% | Valid: time=  0.4s loss=0.448, TAw acc= 85.8% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 71.6% | Valid: time=  0.4s loss=0.447, TAw acc= 85.6% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.885, TAw acc= 72.1% | Valid: time=  0.4s loss=0.449, TAw acc= 85.6% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 71.8% | Valid: time=  0.4s loss=0.446, TAw acc= 86.4% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 71.4% | Valid: time=  0.4s loss=0.447, TAw acc= 86.0% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 71.4% | Valid: time=  0.4s loss=0.442, TAw acc= 85.8% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 70.9% | Valid: time=  0.4s loss=0.447, TAw acc= 85.8% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 72.3% | Valid: time=  0.4s loss=0.444, TAw acc= 86.2% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 73.0% | Valid: time=  0.4s loss=0.445, TAw acc= 85.8% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 71.6% | Valid: time=  0.4s loss=0.447, TAw acc= 85.8% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 72.1% | Valid: time=  0.4s loss=0.442, TAw acc= 86.0% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 72.4% | Valid: time=  0.4s loss=0.447, TAw acc= 86.0% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 71.6% | Valid: time=  0.4s loss=0.443, TAw acc= 86.0% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.942, TAw acc= 69.0% | Valid: time=  0.4s loss=0.407, TAw acc= 87.2% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.927, TAw acc= 70.5% | Valid: time=  0.4s loss=0.416, TAw acc= 86.2% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.926, TAw acc= 70.2% | Valid: time=  0.4s loss=0.424, TAw acc= 86.4% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.924, TAw acc= 70.2% | Valid: time=  0.4s loss=0.433, TAw acc= 86.2% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.912, TAw acc= 71.0% | Valid: time=  0.4s loss=0.439, TAw acc= 85.8% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.907, TAw acc= 71.0% | Valid: time=  0.4s loss=0.446, TAw acc= 85.8% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.923, TAw acc= 70.4% | Valid: time=  0.4s loss=0.450, TAw acc= 85.8% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.910, TAw acc= 71.1% | Valid: time=  0.4s loss=0.452, TAw acc= 85.8% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.905, TAw acc= 71.1% | Valid: time=  0.4s loss=0.454, TAw acc= 85.8% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.902, TAw acc= 71.3% | Valid: time=  0.4s loss=0.456, TAw acc= 85.8% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.909, TAw acc= 70.7% | Valid: time=  0.4s loss=0.457, TAw acc= 85.8% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.908, TAw acc= 70.6% | Valid: time=  0.4s loss=0.459, TAw acc= 85.4% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.915, TAw acc= 70.6% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.888, TAw acc= 71.2% | Valid: time=  0.4s loss=0.459, TAw acc= 85.2% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.888, TAw acc= 71.4% | Valid: time=  0.4s loss=0.458, TAw acc= 85.4% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.897, TAw acc= 71.5% | Valid: time=  0.4s loss=0.458, TAw acc= 85.4% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 70.7% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.907, TAw acc= 71.0% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.898, TAw acc= 71.0% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 71.6% | Valid: time=  0.4s loss=0.461, TAw acc= 85.2% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.897, TAw acc= 70.8% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.896, TAw acc= 71.2% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.906, TAw acc= 70.3% | Valid: time=  0.4s loss=0.457, TAw acc= 85.2% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 72.0% | Valid: time=  0.4s loss=0.456, TAw acc= 85.2% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 70.7% | Valid: time=  0.4s loss=0.457, TAw acc= 85.2% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.899, TAw acc= 71.6% | Valid: time=  0.4s loss=0.457, TAw acc= 85.2% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.899, TAw acc= 72.0% | Valid: time=  0.4s loss=0.457, TAw acc= 85.2% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 71.3% | Valid: time=  0.4s loss=0.458, TAw acc= 85.2% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 71.1% | Valid: time=  0.4s loss=0.457, TAw acc= 85.4% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.900, TAw acc= 70.9% | Valid: time=  0.4s loss=0.455, TAw acc= 85.2% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.978, TAw acc= 67.8% | Valid: time=  0.4s loss=0.402, TAw acc= 87.0% |
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.965, TAw acc= 68.5% | Valid: time=  0.4s loss=0.404, TAw acc= 87.2% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.964, TAw acc= 68.6% | Valid: time=  0.4s loss=0.407, TAw acc= 87.2% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.943, TAw acc= 68.6% | Valid: time=  0.4s loss=0.410, TAw acc= 86.6% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 68.3% | Valid: time=  0.4s loss=0.412, TAw acc= 86.4% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.935, TAw acc= 69.8% | Valid: time=  0.4s loss=0.416, TAw acc= 86.2% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.938, TAw acc= 69.3% | Valid: time=  0.4s loss=0.419, TAw acc= 86.4% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.938, TAw acc= 69.7% | Valid: time=  0.4s loss=0.423, TAw acc= 86.4% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.928, TAw acc= 69.8% | Valid: time=  0.4s loss=0.426, TAw acc= 86.4% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.923, TAw acc= 70.2% | Valid: time=  0.4s loss=0.429, TAw acc= 86.2% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc= 10.1%, forg= 67.2% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 48.2%, forg= 17.2% <<<
>>> Test on task  2 : loss=0.618 | TAw acc= 78.7%, forg=  1.0%| TAg acc= 23.8%, forg= 14.7% <<<
>>> Test on task  3 : loss=0.624 | TAw acc= 79.5%, forg=  0.3%| TAg acc= 35.0%, forg=  5.7% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 51.6%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  5
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-5): 6 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.225, TAw acc= 55.3% | Valid: time=  0.4s loss=1.052, TAw acc= 60.4% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.157, TAw acc= 57.9% | Valid: time=  0.4s loss=1.058, TAw acc= 62.2% |
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.078, TAw acc= 60.7% | Valid: time=  0.4s loss=0.917, TAw acc= 65.8% | *
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.112, TAw acc= 60.0% | Valid: time=  0.4s loss=0.895, TAw acc= 66.8% | *
| Epoch   5, lr=2.6e-02 time=  2.9s/  2.0s | Train: loss=1.085, TAw acc= 62.3% | Valid: time=  0.4s loss=0.980, TAw acc= 63.4% |
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.085, TAw acc= 61.8% | Valid: time=  0.4s loss=0.869, TAw acc= 67.8% | *
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.065, TAw acc= 61.2% | Valid: time=  0.4s loss=0.900, TAw acc= 65.8% |
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.043, TAw acc= 62.9% | Valid: time=  0.4s loss=0.935, TAw acc= 65.8% |
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.071, TAw acc= 61.0% | Valid: time=  0.4s loss=0.913, TAw acc= 66.0% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.040, TAw acc= 62.7% | Valid: time=  0.4s loss=0.868, TAw acc= 68.2% | *
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.068, TAw acc= 61.4% | Valid: time=  0.4s loss=0.973, TAw acc= 66.0% |
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.033, TAw acc= 64.0% | Valid: time=  0.4s loss=0.853, TAw acc= 68.0% | *
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.034, TAw acc= 61.4% | Valid: time=  0.4s loss=0.971, TAw acc= 63.6% |
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.063, TAw acc= 61.7% | Valid: time=  0.4s loss=0.945, TAw acc= 66.0% |
| Epoch  15, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.051, TAw acc= 62.1% | Valid: time=  0.4s loss=0.922, TAw acc= 68.4% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.026, TAw acc= 63.6% | Valid: time=  0.4s loss=0.862, TAw acc= 67.4% |
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.021, TAw acc= 62.9% | Valid: time=  0.4s loss=0.945, TAw acc= 69.0% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.029, TAw acc= 63.3% | Valid: time=  0.4s loss=0.872, TAw acc= 70.2% |
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.016, TAw acc= 63.2% | Valid: time=  0.4s loss=0.962, TAw acc= 67.0% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 63.4% | Valid: time=  0.4s loss=0.855, TAw acc= 70.8% |
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 63.8% | Valid: time=  0.4s loss=0.889, TAw acc= 69.6% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 63.6% | Valid: time=  0.4s loss=0.862, TAw acc= 68.4% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.030, TAw acc= 63.4% | Valid: time=  0.4s loss=0.841, TAw acc= 68.2% | *
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.009, TAw acc= 64.1% | Valid: time=  0.4s loss=0.830, TAw acc= 70.0% | *
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.011, TAw acc= 64.1% | Valid: time=  0.4s loss=0.847, TAw acc= 69.2% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.000, TAw acc= 64.3% | Valid: time=  0.4s loss=0.873, TAw acc= 66.6% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 64.8% | Valid: time=  0.4s loss=0.866, TAw acc= 69.6% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.025, TAw acc= 63.5% | Valid: time=  0.4s loss=0.870, TAw acc= 67.0% |
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.011, TAw acc= 64.4% | Valid: time=  0.4s loss=0.888, TAw acc= 68.2% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 64.9% | Valid: time=  0.4s loss=0.841, TAw acc= 68.6% |
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.002, TAw acc= 65.6% | Valid: time=  0.4s loss=0.837, TAw acc= 70.2% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.015, TAw acc= 63.9% | Valid: time=  0.4s loss=0.882, TAw acc= 69.0% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.032, TAw acc= 64.1% | Valid: time=  0.4s loss=0.831, TAw acc= 69.4% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 64.6% | Valid: time=  0.4s loss=0.844, TAw acc= 69.0% |
| Epoch  35, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.999, TAw acc= 65.0% | Valid: time=  0.4s loss=0.830, TAw acc= 69.8% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 65.0% | Valid: time=  0.4s loss=0.855, TAw acc= 69.2% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.025, TAw acc= 63.9% | Valid: time=  0.4s loss=0.859, TAw acc= 68.2% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.985, TAw acc= 63.7% | Valid: time=  0.4s loss=0.849, TAw acc= 71.6% |
| Epoch  39, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.007, TAw acc= 63.9% | Valid: time=  0.4s loss=0.868, TAw acc= 69.0% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.014, TAw acc= 62.9% | Valid: time=  0.4s loss=0.895, TAw acc= 68.0% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 64.2% | Valid: time=  0.4s loss=0.841, TAw acc= 68.8% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.968, TAw acc= 65.5% | Valid: time=  0.4s loss=0.866, TAw acc= 68.0% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 66.4% | Valid: time=  0.4s loss=0.826, TAw acc= 69.6% | *
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.979, TAw acc= 66.6% | Valid: time=  0.4s loss=0.828, TAw acc= 70.0% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.984, TAw acc= 65.3% | Valid: time=  0.4s loss=0.885, TAw acc= 68.2% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.005, TAw acc= 63.3% | Valid: time=  0.4s loss=0.867, TAw acc= 68.4% |
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.013, TAw acc= 63.6% | Valid: time=  0.4s loss=0.869, TAw acc= 68.6% |
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 66.3% | Valid: time=  0.4s loss=0.811, TAw acc= 69.8% | *
| Epoch  49, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.965, TAw acc= 65.8% | Valid: time=  0.4s loss=0.849, TAw acc= 68.4% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.000, TAw acc= 64.7% | Valid: time=  0.4s loss=0.807, TAw acc= 70.0% | *
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.002, TAw acc= 65.0% | Valid: time=  0.4s loss=0.823, TAw acc= 69.6% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.005, TAw acc= 64.7% | Valid: time=  0.4s loss=0.876, TAw acc= 68.0% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.004, TAw acc= 65.3% | Valid: time=  0.4s loss=0.831, TAw acc= 69.2% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 64.0% | Valid: time=  0.4s loss=0.819, TAw acc= 70.6% |
| Epoch  55, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 64.5% | Valid: time=  0.4s loss=0.836, TAw acc= 68.8% |
| Epoch  56, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 65.0% | Valid: time=  0.4s loss=0.830, TAw acc= 69.8% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.963, TAw acc= 65.3% | Valid: time=  0.4s loss=0.852, TAw acc= 69.8% |
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 65.1% | Valid: time=  0.4s loss=0.833, TAw acc= 68.6% |
| Epoch  59, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 65.0% | Valid: time=  0.4s loss=0.828, TAw acc= 68.6% |
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.974, TAw acc= 64.8% | Valid: time=  0.4s loss=0.852, TAw acc= 69.6% |
| Epoch  61, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.980, TAw acc= 64.6% | Valid: time=  0.4s loss=0.886, TAw acc= 68.6% |
| Epoch  62, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.969, TAw acc= 65.4% | Valid: time=  0.4s loss=0.826, TAw acc= 69.8% |
| Epoch  63, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.987, TAw acc= 65.0% | Valid: time=  0.4s loss=0.862, TAw acc= 67.6% |
| Epoch  64, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.935, TAw acc= 66.7% | Valid: time=  0.4s loss=0.873, TAw acc= 70.0% |
| Epoch  65, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 65.0% | Valid: time=  0.4s loss=0.866, TAw acc= 67.8% |
| Epoch  66, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.959, TAw acc= 65.8% | Valid: time=  0.4s loss=0.833, TAw acc= 70.2% |
| Epoch  67, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 65.3% | Valid: time=  0.4s loss=0.877, TAw acc= 68.8% |
| Epoch  68, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.981, TAw acc= 64.5% | Valid: time=  0.4s loss=0.813, TAw acc= 69.8% |
| Epoch  69, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.984, TAw acc= 65.1% | Valid: time=  0.4s loss=0.886, TAw acc= 67.2% |
| Epoch  70, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.990, TAw acc= 66.2% | Valid: time=  0.4s loss=0.817, TAw acc= 69.0% |
| Epoch  71, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.944, TAw acc= 67.3% | Valid: time=  0.4s loss=0.857, TAw acc= 68.4% |
| Epoch  72, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.982, TAw acc= 64.8% | Valid: time=  0.4s loss=0.799, TAw acc= 72.2% | *
| Epoch  73, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.964, TAw acc= 66.0% | Valid: time=  0.4s loss=0.830, TAw acc= 68.2% |
| Epoch  74, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.995, TAw acc= 64.2% | Valid: time=  0.4s loss=0.787, TAw acc= 70.4% | *
| Epoch  75, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 65.7% | Valid: time=  0.4s loss=0.833, TAw acc= 70.6% |
| Epoch  76, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.967, TAw acc= 65.4% | Valid: time=  0.4s loss=0.862, TAw acc= 67.8% |
| Epoch  77, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.967, TAw acc= 66.9% | Valid: time=  0.4s loss=0.809, TAw acc= 69.6% |
| Epoch  78, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.971, TAw acc= 67.6% | Valid: time=  0.4s loss=0.818, TAw acc= 69.6% |
| Epoch  79, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.016, TAw acc= 64.1% | Valid: time=  0.4s loss=0.830, TAw acc= 68.0% |
| Epoch  80, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.971, TAw acc= 66.2% | Valid: time=  0.4s loss=0.816, TAw acc= 69.6% |
| Epoch  81, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.956, TAw acc= 65.2% | Valid: time=  0.4s loss=0.817, TAw acc= 69.4% |
| Epoch  82, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.962, TAw acc= 65.4% | Valid: time=  0.4s loss=0.814, TAw acc= 70.0% |
| Epoch  83, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.016, TAw acc= 63.9% | Valid: time=  0.4s loss=0.806, TAw acc= 69.2% |
| Epoch  84, lr=2.6e-02 time=  3.8s/  1.9s | Train: loss=0.955, TAw acc= 66.6% | Valid: time=  0.4s loss=0.815, TAw acc= 71.0% |
| Epoch  85, lr=2.6e-02 time=  4.7s/  1.9s | Train: loss=0.970, TAw acc= 66.1% | Valid: time=  0.4s loss=0.804, TAw acc= 72.0% |
| Epoch  86, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.966, TAw acc= 65.5% | Valid: time=  0.4s loss=0.857, TAw acc= 68.8% |
| Epoch  87, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.927, TAw acc= 67.0% | Valid: time=  0.4s loss=0.836, TAw acc= 68.2% |
| Epoch  88, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.933, TAw acc= 66.4% | Valid: time=  0.4s loss=0.815, TAw acc= 69.8% |
| Epoch  89, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 63.8% | Valid: time=  0.4s loss=0.816, TAw acc= 69.6% |
| Epoch  90, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.938, TAw acc= 67.0% | Valid: time=  0.4s loss=0.838, TAw acc= 70.8% |
| Epoch  91, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.975, TAw acc= 65.8% | Valid: time=  0.4s loss=0.834, TAw acc= 70.0% |
| Epoch  92, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.940, TAw acc= 67.2% | Valid: time=  0.4s loss=0.792, TAw acc= 70.4% |
| Epoch  93, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.982, TAw acc= 65.6% | Valid: time=  0.4s loss=0.889, TAw acc= 69.0% |
| Epoch  94, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 66.5% | Valid: time=  0.4s loss=0.807, TAw acc= 71.2% |
| Epoch  95, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.938, TAw acc= 65.8% | Valid: time=  0.4s loss=0.926, TAw acc= 66.2% |
| Epoch  96, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.958, TAw acc= 66.3% | Valid: time=  0.4s loss=0.792, TAw acc= 71.2% |
| Epoch  97, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.954, TAw acc= 66.4% | Valid: time=  0.4s loss=0.822, TAw acc= 69.8% |
| Epoch  98, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.969, TAw acc= 66.4% | Valid: time=  0.4s loss=0.825, TAw acc= 69.8% |
| Epoch  99, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.947, TAw acc= 66.7% | Valid: time=  0.4s loss=0.867, TAw acc= 67.2% |
| Epoch 100, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.937, TAw acc= 66.5% | Valid: time=  0.4s loss=0.804, TAw acc= 68.4% |
== Rank Reduction [task:5] ==
best_loss=0.787,  best_acc=0.704
 r=256, loss=1.002, acc=0.610
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.960, acc=0.642
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.961, acc=0.642
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.942, acc=0.648
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.908, acc=0.664
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.888, acc=0.676
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.874, acc=0.682
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.857, acc=0.682
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.850, acc=0.674
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.830, acc=0.686
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.812, acc=0.702
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.793, acc=0.704
 loss_margin=0.006, acc_margin=0.004
 r=640, loss=0.784, acc=0.704
 loss_margin=0.006, acc_margin=0.004
best_r=640, loss=0.784, acc=0.704
== Header Training for Low Rank [task:5] ==
loss=0.784 acc=0.704
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 65.2% | Valid: time=  0.4s loss=0.842, TAw acc= 69.0% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.976, TAw acc= 65.4% | Valid: time=  0.4s loss=0.840, TAw acc= 68.6% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.989, TAw acc= 65.3% | Valid: time=  0.4s loss=0.838, TAw acc= 70.4% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.965, TAw acc= 66.0% | Valid: time=  0.4s loss=0.839, TAw acc= 69.4% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 66.0% | Valid: time=  0.4s loss=0.831, TAw acc= 70.2% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 66.4% | Valid: time=  0.5s loss=0.831, TAw acc= 70.0% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.937, TAw acc= 67.3% | Valid: time=  0.4s loss=0.848, TAw acc= 69.4% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 65.0% | Valid: time=  0.4s loss=0.845, TAw acc= 69.2% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.954, TAw acc= 65.8% | Valid: time=  0.4s loss=0.841, TAw acc= 69.0% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.963, TAw acc= 66.6% | Valid: time=  0.4s loss=0.844, TAw acc= 69.8% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.950, TAw acc= 67.0% | Valid: time=  0.4s loss=0.842, TAw acc= 70.4% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.968, TAw acc= 66.0% | Valid: time=  0.4s loss=0.846, TAw acc= 69.4% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.963, TAw acc= 66.1% | Valid: time=  0.5s loss=0.862, TAw acc= 68.6% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.951, TAw acc= 66.4% | Valid: time=  0.4s loss=0.857, TAw acc= 68.8% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.958, TAw acc= 66.5% | Valid: time=  0.4s loss=0.843, TAw acc= 68.6% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.959, TAw acc= 66.5% | Valid: time=  0.4s loss=0.858, TAw acc= 69.0% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 66.1% | Valid: time=  0.4s loss=0.845, TAw acc= 69.4% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.929, TAw acc= 67.3% | Valid: time=  0.4s loss=0.840, TAw acc= 70.0% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.941, TAw acc= 67.1% | Valid: time=  0.4s loss=0.846, TAw acc= 69.8% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.960, TAw acc= 66.0% | Valid: time=  0.4s loss=0.849, TAw acc= 70.0% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.932, TAw acc= 67.3% | Valid: time=  0.4s loss=0.863, TAw acc= 68.2% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.963, TAw acc= 66.3% | Valid: time=  0.4s loss=0.855, TAw acc= 68.8% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.947, TAw acc= 66.0% | Valid: time=  0.4s loss=0.855, TAw acc= 69.2% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.928, TAw acc= 67.3% | Valid: time=  0.4s loss=0.851, TAw acc= 68.2% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.952, TAw acc= 66.2% | Valid: time=  0.4s loss=0.857, TAw acc= 68.4% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 65.6% | Valid: time=  0.4s loss=0.858, TAw acc= 67.8% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.936, TAw acc= 67.6% | Valid: time=  0.4s loss=0.851, TAw acc= 68.2% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.937, TAw acc= 66.9% | Valid: time=  0.4s loss=0.850, TAw acc= 68.6% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.916, TAw acc= 68.0% | Valid: time=  0.4s loss=0.857, TAw acc= 68.4% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 67.0% | Valid: time=  0.4s loss=0.849, TAw acc= 69.4% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.968, TAw acc= 66.2% | Valid: time=  0.4s loss=0.800, TAw acc= 71.0% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.1% | Valid: time=  0.4s loss=0.820, TAw acc= 70.4% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.987, TAw acc= 66.3% | Valid: time=  0.4s loss=0.830, TAw acc= 70.4% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 65.2% | Valid: time=  0.4s loss=0.833, TAw acc= 69.8% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 66.4% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 65.6% | Valid: time=  0.4s loss=0.832, TAw acc= 69.2% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.978, TAw acc= 66.5% | Valid: time=  0.4s loss=0.835, TAw acc= 68.8% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 66.9% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 66.4% | Valid: time=  0.4s loss=0.835, TAw acc= 69.6% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.976, TAw acc= 65.8% | Valid: time=  0.4s loss=0.834, TAw acc= 69.4% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 66.2% | Valid: time=  0.4s loss=0.832, TAw acc= 69.6% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.978, TAw acc= 66.4% | Valid: time=  0.4s loss=0.834, TAw acc= 70.0% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 66.0% | Valid: time=  0.4s loss=0.837, TAw acc= 69.6% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 66.6% | Valid: time=  0.4s loss=0.836, TAw acc= 69.4% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.968, TAw acc= 66.1% | Valid: time=  0.4s loss=0.839, TAw acc= 69.8% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 66.8% | Valid: time=  0.4s loss=0.839, TAw acc= 70.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 67.9% | Valid: time=  0.4s loss=0.836, TAw acc= 69.6% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 66.2% | Valid: time=  0.4s loss=0.841, TAw acc= 69.8% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 66.4% | Valid: time=  0.4s loss=0.837, TAw acc= 69.6% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.989, TAw acc= 65.3% | Valid: time=  0.4s loss=0.839, TAw acc= 69.6% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 66.1% | Valid: time=  0.4s loss=0.838, TAw acc= 70.0% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.959, TAw acc= 66.4% | Valid: time=  0.4s loss=0.842, TAw acc= 69.8% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.968, TAw acc= 66.1% | Valid: time=  0.4s loss=0.843, TAw acc= 69.6% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.956, TAw acc= 66.8% | Valid: time=  0.4s loss=0.841, TAw acc= 69.8% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.954, TAw acc= 66.8% | Valid: time=  0.4s loss=0.842, TAw acc= 69.4% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.952, TAw acc= 67.0% | Valid: time=  0.4s loss=0.843, TAw acc= 69.6% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.952, TAw acc= 67.0% | Valid: time=  0.4s loss=0.844, TAw acc= 69.4% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.953, TAw acc= 66.0% | Valid: time=  0.4s loss=0.841, TAw acc= 69.2% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.957, TAw acc= 66.5% | Valid: time=  0.4s loss=0.843, TAw acc= 69.4% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 66.6% | Valid: time=  0.4s loss=0.843, TAw acc= 69.6% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.996, TAw acc= 65.0% | Valid: time=  0.4s loss=0.780, TAw acc= 70.6% | *
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.010, TAw acc= 64.6% | Valid: time=  0.4s loss=0.788, TAw acc= 71.0% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.996, TAw acc= 65.2% | Valid: time=  0.4s loss=0.798, TAw acc= 71.6% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 65.7% | Valid: time=  0.4s loss=0.806, TAw acc= 70.6% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 65.8% | Valid: time=  0.4s loss=0.814, TAw acc= 70.4% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.973, TAw acc= 66.4% | Valid: time=  0.4s loss=0.821, TAw acc= 70.2% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 65.6% | Valid: time=  0.5s loss=0.824, TAw acc= 70.2% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 66.3% | Valid: time=  0.4s loss=0.827, TAw acc= 70.0% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 66.9% | Valid: time=  0.4s loss=0.831, TAw acc= 70.2% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.980, TAw acc= 66.2% | Valid: time=  0.4s loss=0.831, TAw acc= 70.0% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.010, TAw acc= 64.6% | Valid: time=  0.4s loss=0.830, TAw acc= 70.4% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 67.1% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 66.0% | Valid: time=  0.4s loss=0.834, TAw acc= 70.4% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 65.0% | Valid: time=  0.4s loss=0.835, TAw acc= 69.6% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 66.2% | Valid: time=  0.4s loss=0.834, TAw acc= 69.8% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.963, TAw acc= 66.5% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.974, TAw acc= 66.2% | Valid: time=  0.4s loss=0.835, TAw acc= 69.6% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.976, TAw acc= 65.6% | Valid: time=  0.4s loss=0.837, TAw acc= 69.8% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 66.3% | Valid: time=  0.4s loss=0.837, TAw acc= 69.4% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 66.6% | Valid: time=  0.4s loss=0.837, TAw acc= 69.2% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 66.4% | Valid: time=  0.4s loss=0.836, TAw acc= 69.4% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.981, TAw acc= 65.7% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 66.7% | Valid: time=  0.4s loss=0.834, TAw acc= 69.4% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.981, TAw acc= 65.9% | Valid: time=  0.4s loss=0.832, TAw acc= 69.4% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 65.9% | Valid: time=  0.4s loss=0.832, TAw acc= 69.4% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.2% | Valid: time=  0.4s loss=0.836, TAw acc= 69.4% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.980, TAw acc= 66.4% | Valid: time=  0.4s loss=0.834, TAw acc= 69.6% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.978, TAw acc= 65.7% | Valid: time=  0.4s loss=0.836, TAw acc= 69.4% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.951, TAw acc= 67.8% | Valid: time=  0.4s loss=0.836, TAw acc= 69.4% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 66.4% | Valid: time=  0.4s loss=0.837, TAw acc= 69.4% |
| Epoch  91, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.2% | Valid: time=  0.4s loss=0.838, TAw acc= 69.6% | lr=3.2e-04
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.008, TAw acc= 64.9% | Valid: time=  0.4s loss=0.781, TAw acc= 71.0% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.006, TAw acc= 65.0% | Valid: time=  0.4s loss=0.784, TAw acc= 70.8% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 65.9% | Valid: time=  0.4s loss=0.787, TAw acc= 70.8% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.001, TAw acc= 66.4% | Valid: time=  0.4s loss=0.790, TAw acc= 70.8% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 66.2% | Valid: time=  0.4s loss=0.793, TAw acc= 71.2% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 66.4% | Valid: time=  0.4s loss=0.796, TAw acc= 71.2% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 65.0% | Valid: time=  0.4s loss=0.799, TAw acc= 71.4% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 66.4% | Valid: time=  0.4s loss=0.802, TAw acc= 71.0% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 66.3% | Valid: time=  0.4s loss=0.805, TAw acc= 71.2% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc=  7.1%, forg= 70.2% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 45.8%, forg= 19.6% <<<
>>> Test on task  2 : loss=0.618 | TAw acc= 78.9%, forg=  0.8%| TAg acc= 17.3%, forg= 21.2% <<<
>>> Test on task  3 : loss=0.625 | TAw acc= 79.0%, forg=  0.8%| TAg acc= 29.1%, forg= 11.6% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 44.6%, forg=  7.0% <<<
>>> Test on task  5 : loss=0.792 | TAw acc= 69.9%, forg=  0.0%| TAg acc= 41.2%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  6
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-6): 7 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.134, TAw acc= 63.6% | Valid: time=  0.4s loss=0.771, TAw acc= 74.4% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.092, TAw acc= 64.5% | Valid: time=  0.4s loss=0.700, TAw acc= 75.4% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.046, TAw acc= 66.0% | Valid: time=  0.4s loss=0.694, TAw acc= 77.0% | *
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.061, TAw acc= 64.7% | Valid: time=  0.4s loss=0.705, TAw acc= 76.4% |
| Epoch   5, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.012, TAw acc= 65.5% | Valid: time=  0.4s loss=0.731, TAw acc= 76.8% |
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 65.9% | Valid: time=  0.4s loss=0.695, TAw acc= 77.0% |
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.014, TAw acc= 66.0% | Valid: time=  0.4s loss=0.640, TAw acc= 78.0% | *
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.997, TAw acc= 65.9% | Valid: time=  0.4s loss=0.665, TAw acc= 78.2% |
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.960, TAw acc= 68.4% | Valid: time=  0.4s loss=0.673, TAw acc= 77.6% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 66.8% | Valid: time=  0.5s loss=0.668, TAw acc= 78.4% |
| Epoch  11, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.978, TAw acc= 67.2% | Valid: time=  0.4s loss=0.702, TAw acc= 77.2% |
| Epoch  12, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.966, TAw acc= 67.4% | Valid: time=  0.4s loss=0.717, TAw acc= 75.4% |
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 66.8% | Valid: time=  0.4s loss=0.661, TAw acc= 76.8% |
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 66.4% | Valid: time=  0.4s loss=0.632, TAw acc= 79.2% | *
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.990, TAw acc= 66.2% | Valid: time=  0.4s loss=0.646, TAw acc= 77.8% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.973, TAw acc= 67.8% | Valid: time=  0.4s loss=0.608, TAw acc= 79.6% | *
| Epoch  17, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.964, TAw acc= 68.1% | Valid: time=  0.4s loss=0.682, TAw acc= 77.6% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 68.6% | Valid: time=  0.4s loss=0.645, TAw acc= 77.8% |
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 67.8% | Valid: time=  0.4s loss=0.733, TAw acc= 75.4% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.953, TAw acc= 68.5% | Valid: time=  0.4s loss=0.638, TAw acc= 78.4% |
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 67.2% | Valid: time=  0.4s loss=0.644, TAw acc= 76.6% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.941, TAw acc= 68.4% | Valid: time=  0.4s loss=0.683, TAw acc= 77.0% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.961, TAw acc= 67.3% | Valid: time=  0.4s loss=0.607, TAw acc= 78.0% | *
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 67.2% | Valid: time=  0.4s loss=0.595, TAw acc= 79.8% | *
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.938, TAw acc= 68.0% | Valid: time=  0.4s loss=0.641, TAw acc= 78.2% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.939, TAw acc= 68.4% | Valid: time=  0.4s loss=0.640, TAw acc= 78.0% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.947, TAw acc= 68.3% | Valid: time=  0.4s loss=0.598, TAw acc= 79.2% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 68.5% | Valid: time=  0.4s loss=0.591, TAw acc= 80.4% | *
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.925, TAw acc= 68.4% | Valid: time=  0.4s loss=0.652, TAw acc= 78.6% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.936, TAw acc= 68.8% | Valid: time=  0.4s loss=0.616, TAw acc= 79.6% |
| Epoch  31, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.942, TAw acc= 68.2% | Valid: time=  0.4s loss=0.644, TAw acc= 78.6% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.914, TAw acc= 70.4% | Valid: time=  0.4s loss=0.599, TAw acc= 79.8% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.946, TAw acc= 68.0% | Valid: time=  0.4s loss=0.649, TAw acc= 78.4% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.905, TAw acc= 69.2% | Valid: time=  0.4s loss=0.611, TAw acc= 78.4% |
| Epoch  35, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.921, TAw acc= 69.2% | Valid: time=  0.4s loss=0.607, TAw acc= 80.0% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.899, TAw acc= 70.0% | Valid: time=  0.4s loss=0.640, TAw acc= 79.2% |
| Epoch  37, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.923, TAw acc= 68.8% | Valid: time=  0.4s loss=0.602, TAw acc= 79.0% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.921, TAw acc= 69.3% | Valid: time=  0.5s loss=0.628, TAw acc= 79.6% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.880, TAw acc= 70.9% | Valid: time=  0.4s loss=0.655, TAw acc= 78.8% |
| Epoch  40, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.887, TAw acc= 69.8% | Valid: time=  0.4s loss=0.666, TAw acc= 78.0% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.928, TAw acc= 69.0% | Valid: time=  0.4s loss=0.616, TAw acc= 79.2% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.886, TAw acc= 70.7% | Valid: time=  0.4s loss=0.667, TAw acc= 77.2% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.944, TAw acc= 68.5% | Valid: time=  0.4s loss=0.609, TAw acc= 79.6% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.923, TAw acc= 69.1% | Valid: time=  0.4s loss=0.625, TAw acc= 79.0% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.925, TAw acc= 68.5% | Valid: time=  0.4s loss=0.592, TAw acc= 79.8% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.922, TAw acc= 69.4% | Valid: time=  0.4s loss=0.608, TAw acc= 78.2% |
| Epoch  47, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.884, TAw acc= 69.8% | Valid: time=  0.4s loss=0.585, TAw acc= 80.4% | *
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.913, TAw acc= 69.2% | Valid: time=  0.4s loss=0.619, TAw acc= 78.8% |
| Epoch  49, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.922, TAw acc= 68.8% | Valid: time=  0.4s loss=0.612, TAw acc= 77.4% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.925, TAw acc= 68.6% | Valid: time=  0.4s loss=0.633, TAw acc= 79.0% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.880, TAw acc= 70.5% | Valid: time=  0.4s loss=0.633, TAw acc= 79.0% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.915, TAw acc= 69.8% | Valid: time=  0.4s loss=0.621, TAw acc= 78.8% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.894, TAw acc= 70.4% | Valid: time=  0.4s loss=0.625, TAw acc= 78.2% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.899, TAw acc= 69.2% | Valid: time=  0.4s loss=0.620, TAw acc= 79.2% |
| Epoch  55, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.884, TAw acc= 70.2% | Valid: time=  0.4s loss=0.611, TAw acc= 80.6% |
| Epoch  56, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.904, TAw acc= 69.6% | Valid: time=  0.4s loss=0.646, TAw acc= 78.0% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.943, TAw acc= 68.0% | Valid: time=  0.5s loss=0.626, TAw acc= 78.6% |
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.926, TAw acc= 69.3% | Valid: time=  0.4s loss=0.590, TAw acc= 79.6% |
| Epoch  59, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.906, TAw acc= 69.7% | Valid: time=  0.4s loss=0.594, TAw acc= 80.8% |
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 69.9% | Valid: time=  0.4s loss=0.611, TAw acc= 79.4% |
| Epoch  61, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.905, TAw acc= 70.1% | Valid: time=  0.4s loss=0.647, TAw acc= 78.6% |
| Epoch  62, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.902, TAw acc= 70.0% | Valid: time=  0.4s loss=0.620, TAw acc= 78.2% |
| Epoch  63, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.912, TAw acc= 69.5% | Valid: time=  0.5s loss=0.601, TAw acc= 79.8% |
| Epoch  64, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.892, TAw acc= 70.3% | Valid: time=  0.4s loss=0.582, TAw acc= 80.0% | *
| Epoch  65, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.891, TAw acc= 70.1% | Valid: time=  0.4s loss=0.647, TAw acc= 80.2% |
| Epoch  66, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.902, TAw acc= 69.3% | Valid: time=  0.4s loss=0.577, TAw acc= 79.6% | *
| Epoch  67, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.886, TAw acc= 69.8% | Valid: time=  0.4s loss=0.593, TAw acc= 80.2% |
| Epoch  68, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.929, TAw acc= 68.9% | Valid: time=  0.4s loss=0.576, TAw acc= 79.6% | *
| Epoch  69, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.895, TAw acc= 69.8% | Valid: time=  0.4s loss=0.615, TAw acc= 79.6% |
| Epoch  70, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.877, TAw acc= 70.5% | Valid: time=  0.4s loss=0.611, TAw acc= 78.4% |
| Epoch  71, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.894, TAw acc= 70.1% | Valid: time=  0.4s loss=0.606, TAw acc= 79.6% |
| Epoch  72, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.882, TAw acc= 70.8% | Valid: time=  0.4s loss=0.627, TAw acc= 80.2% |
| Epoch  73, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.884, TAw acc= 70.2% | Valid: time=  0.4s loss=0.654, TAw acc= 78.4% |
| Epoch  74, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.888, TAw acc= 71.2% | Valid: time=  0.4s loss=0.598, TAw acc= 80.0% |
| Epoch  75, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.883, TAw acc= 70.6% | Valid: time=  0.4s loss=0.659, TAw acc= 78.6% |
| Epoch  76, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.891, TAw acc= 69.4% | Valid: time=  0.4s loss=0.615, TAw acc= 80.0% |
| Epoch  77, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.906, TAw acc= 70.1% | Valid: time=  0.4s loss=0.607, TAw acc= 81.4% |
| Epoch  78, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.916, TAw acc= 69.3% | Valid: time=  0.4s loss=0.601, TAw acc= 80.4% |
| Epoch  79, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.869, TAw acc= 70.4% | Valid: time=  0.4s loss=0.611, TAw acc= 79.0% |
| Epoch  80, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.905, TAw acc= 69.3% | Valid: time=  0.4s loss=0.591, TAw acc= 80.0% |
| Epoch  81, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.905, TAw acc= 69.3% | Valid: time=  0.4s loss=0.605, TAw acc= 80.0% |
| Epoch  82, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.888, TAw acc= 69.4% | Valid: time=  0.4s loss=0.625, TAw acc= 80.4% |
| Epoch  83, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 70.1% | Valid: time=  0.4s loss=0.582, TAw acc= 81.2% |
| Epoch  84, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.895, TAw acc= 70.0% | Valid: time=  0.4s loss=0.572, TAw acc= 81.6% | *
| Epoch  85, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.861, TAw acc= 71.1% | Valid: time=  0.4s loss=0.638, TAw acc= 80.0% |
| Epoch  86, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.881, TAw acc= 69.6% | Valid: time=  0.4s loss=0.602, TAw acc= 81.2% |
| Epoch  87, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.865, TAw acc= 71.1% | Valid: time=  0.4s loss=0.638, TAw acc= 79.0% |
| Epoch  88, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.892, TAw acc= 69.2% | Valid: time=  0.4s loss=0.655, TAw acc= 80.4% |
| Epoch  89, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.922, TAw acc= 68.6% | Valid: time=  0.4s loss=0.574, TAw acc= 81.2% |
| Epoch  90, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.874, TAw acc= 70.9% | Valid: time=  0.4s loss=0.609, TAw acc= 80.6% |
| Epoch  91, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.890, TAw acc= 70.1% | Valid: time=  0.4s loss=0.572, TAw acc= 81.4% | *
| Epoch  92, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.879, TAw acc= 70.4% | Valid: time=  0.4s loss=0.599, TAw acc= 81.4% |
| Epoch  93, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.889, TAw acc= 70.3% | Valid: time=  0.4s loss=0.594, TAw acc= 81.0% |
| Epoch  94, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.881, TAw acc= 70.7% | Valid: time=  0.4s loss=0.585, TAw acc= 81.0% |
| Epoch  95, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 69.6% | Valid: time=  0.4s loss=0.584, TAw acc= 80.6% |
| Epoch  96, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.899, TAw acc= 70.1% | Valid: time=  0.4s loss=0.580, TAw acc= 81.0% |
| Epoch  97, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.890, TAw acc= 69.7% | Valid: time=  0.4s loss=0.611, TAw acc= 80.6% |
| Epoch  98, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.872, TAw acc= 71.3% | Valid: time=  0.4s loss=0.569, TAw acc= 81.0% | *
| Epoch  99, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.862, TAw acc= 71.3% | Valid: time=  0.4s loss=0.622, TAw acc= 80.2% |
| Epoch 100, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.859, TAw acc= 71.0% | Valid: time=  0.4s loss=0.658, TAw acc= 79.6% |
== Rank Reduction [task:6] ==
best_loss=0.569,  best_acc=0.810
 r=256, loss=0.872, acc=0.714
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.837, acc=0.720
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.783, acc=0.748
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.747, acc=0.750
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.723, acc=0.760
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.705, acc=0.756
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.694, acc=0.764
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.686, acc=0.768
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.677, acc=0.768
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.650, acc=0.778
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.607, acc=0.800
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.593, acc=0.798
 loss_margin=0.006, acc_margin=0.004
 r=640, loss=0.582, acc=0.798
 loss_margin=0.006, acc_margin=0.004
 r=672, loss=0.568, acc=0.808
 loss_margin=0.006, acc_margin=0.004
best_r=672, loss=0.568, acc=0.808
== Header Training for Low Rank [task:6] ==
loss=0.568 acc=0.808
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 72.3% | Valid: time=  0.4s loss=0.649, TAw acc= 77.8% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 71.9% | Valid: time=  0.4s loss=0.653, TAw acc= 78.0% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.871, TAw acc= 71.4% | Valid: time=  0.4s loss=0.642, TAw acc= 78.2% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 71.3% | Valid: time=  0.4s loss=0.647, TAw acc= 77.8% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 70.6% | Valid: time=  0.4s loss=0.648, TAw acc= 79.2% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 71.8% | Valid: time=  0.4s loss=0.648, TAw acc= 78.6% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 70.9% | Valid: time=  0.4s loss=0.648, TAw acc= 78.8% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.856, TAw acc= 72.2% | Valid: time=  0.4s loss=0.637, TAw acc= 78.6% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.5% | Valid: time=  0.4s loss=0.662, TAw acc= 77.6% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.850, TAw acc= 72.5% | Valid: time=  0.4s loss=0.657, TAw acc= 78.0% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 71.6% | Valid: time=  0.4s loss=0.650, TAw acc= 78.2% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.850, TAw acc= 72.0% | Valid: time=  0.4s loss=0.660, TAw acc= 78.4% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.856, TAw acc= 71.2% | Valid: time=  0.4s loss=0.655, TAw acc= 78.2% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 72.8% | Valid: time=  0.4s loss=0.662, TAw acc= 77.8% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 71.8% | Valid: time=  0.4s loss=0.654, TAw acc= 78.6% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 72.0% | Valid: time=  0.4s loss=0.660, TAw acc= 78.4% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 71.1% | Valid: time=  0.4s loss=0.657, TAw acc= 78.4% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.835, TAw acc= 72.8% | Valid: time=  0.4s loss=0.652, TAw acc= 78.6% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.836, TAw acc= 72.1% | Valid: time=  0.4s loss=0.649, TAw acc= 78.6% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 72.5% | Valid: time=  0.4s loss=0.663, TAw acc= 78.4% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 72.3% | Valid: time=  0.4s loss=0.657, TAw acc= 78.8% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 71.6% | Valid: time=  0.4s loss=0.658, TAw acc= 78.6% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.829, TAw acc= 73.1% | Valid: time=  0.4s loss=0.650, TAw acc= 78.6% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 71.6% | Valid: time=  0.4s loss=0.642, TAw acc= 78.2% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.848, TAw acc= 71.8% | Valid: time=  0.4s loss=0.659, TAw acc= 78.8% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.832, TAw acc= 72.3% | Valid: time=  0.4s loss=0.663, TAw acc= 78.4% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.855, TAw acc= 71.0% | Valid: time=  0.4s loss=0.656, TAw acc= 78.8% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.816, TAw acc= 72.8% | Valid: time=  0.4s loss=0.664, TAw acc= 78.6% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.840, TAw acc= 71.6% | Valid: time=  0.4s loss=0.652, TAw acc= 78.4% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.832, TAw acc= 72.4% | Valid: time=  0.4s loss=0.654, TAw acc= 78.0% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 70.7% | Valid: time=  0.4s loss=0.602, TAw acc= 80.6% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.898, TAw acc= 70.1% | Valid: time=  0.4s loss=0.631, TAw acc= 79.0% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 70.9% | Valid: time=  0.4s loss=0.645, TAw acc= 78.4% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 71.5% | Valid: time=  0.4s loss=0.650, TAw acc= 78.4% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 71.7% | Valid: time=  0.4s loss=0.646, TAw acc= 78.2% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.857, TAw acc= 72.2% | Valid: time=  0.4s loss=0.649, TAw acc= 78.4% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 71.3% | Valid: time=  0.4s loss=0.652, TAw acc= 78.2% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 71.1% | Valid: time=  0.5s loss=0.651, TAw acc= 78.0% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 71.9% | Valid: time=  0.4s loss=0.653, TAw acc= 78.2% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.860, TAw acc= 72.0% | Valid: time=  0.4s loss=0.653, TAw acc= 78.2% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.864, TAw acc= 72.5% | Valid: time=  0.4s loss=0.659, TAw acc= 78.0% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 71.6% | Valid: time=  0.4s loss=0.660, TAw acc= 77.8% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 72.2% | Valid: time=  0.4s loss=0.655, TAw acc= 78.2% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 71.0% | Valid: time=  0.4s loss=0.654, TAw acc= 78.0% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.855, TAw acc= 72.4% | Valid: time=  0.4s loss=0.653, TAw acc= 78.0% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 71.8% | Valid: time=  0.4s loss=0.658, TAw acc= 78.2% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.853, TAw acc= 72.4% | Valid: time=  0.4s loss=0.654, TAw acc= 78.4% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 72.2% | Valid: time=  0.5s loss=0.658, TAw acc= 78.2% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.5% | Valid: time=  0.4s loss=0.658, TAw acc= 78.2% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 72.1% | Valid: time=  0.4s loss=0.652, TAw acc= 78.0% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 71.5% | Valid: time=  0.4s loss=0.655, TAw acc= 78.2% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 70.5% | Valid: time=  0.4s loss=0.653, TAw acc= 78.6% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.843, TAw acc= 72.1% | Valid: time=  0.4s loss=0.652, TAw acc= 78.0% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.854, TAw acc= 71.6% | Valid: time=  0.4s loss=0.657, TAw acc= 78.0% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 70.8% | Valid: time=  0.4s loss=0.656, TAw acc= 78.0% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 70.8% | Valid: time=  0.4s loss=0.660, TAw acc= 78.0% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.870, TAw acc= 71.5% | Valid: time=  0.4s loss=0.661, TAw acc= 77.8% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.885, TAw acc= 70.4% | Valid: time=  0.4s loss=0.655, TAw acc= 77.8% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.843, TAw acc= 72.7% | Valid: time=  0.4s loss=0.659, TAw acc= 77.8% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 71.2% | Valid: time=  0.4s loss=0.658, TAw acc= 78.0% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.893, TAw acc= 70.4% | Valid: time=  0.4s loss=0.581, TAw acc= 80.6% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.910, TAw acc= 70.3% | Valid: time=  0.4s loss=0.593, TAw acc= 80.2% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 71.4% | Valid: time=  0.4s loss=0.605, TAw acc= 80.2% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.875, TAw acc= 70.2% | Valid: time=  0.4s loss=0.615, TAw acc= 79.4% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 71.5% | Valid: time=  0.4s loss=0.624, TAw acc= 79.0% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 71.0% | Valid: time=  0.4s loss=0.629, TAw acc= 79.0% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 70.9% | Valid: time=  0.4s loss=0.634, TAw acc= 78.6% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 71.7% | Valid: time=  0.4s loss=0.640, TAw acc= 78.2% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 71.1% | Valid: time=  0.4s loss=0.641, TAw acc= 78.2% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.852, TAw acc= 73.1% | Valid: time=  0.4s loss=0.644, TAw acc= 78.2% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 71.9% | Valid: time=  0.4s loss=0.646, TAw acc= 78.4% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.878, TAw acc= 70.9% | Valid: time=  0.4s loss=0.645, TAw acc= 78.6% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 71.1% | Valid: time=  0.4s loss=0.646, TAw acc= 78.6% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.866, TAw acc= 71.5% | Valid: time=  0.4s loss=0.646, TAw acc= 78.6% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.861, TAw acc= 71.7% | Valid: time=  0.4s loss=0.646, TAw acc= 78.6% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.874, TAw acc= 71.8% | Valid: time=  0.4s loss=0.648, TAw acc= 78.6% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.867, TAw acc= 71.0% | Valid: time=  0.4s loss=0.649, TAw acc= 78.6% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 70.6% | Valid: time=  0.4s loss=0.650, TAw acc= 78.6% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.858, TAw acc= 72.0% | Valid: time=  0.4s loss=0.652, TAw acc= 78.4% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.857, TAw acc= 72.7% | Valid: time=  0.4s loss=0.652, TAw acc= 78.6% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 71.8% | Valid: time=  0.4s loss=0.652, TAw acc= 78.2% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.868, TAw acc= 72.4% | Valid: time=  0.4s loss=0.652, TAw acc= 78.2% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.851, TAw acc= 72.3% | Valid: time=  0.4s loss=0.651, TAw acc= 78.2% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.858, TAw acc= 71.3% | Valid: time=  0.4s loss=0.653, TAw acc= 78.0% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.862, TAw acc= 72.2% | Valid: time=  0.4s loss=0.655, TAw acc= 78.0% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.890, TAw acc= 70.3% | Valid: time=  0.4s loss=0.653, TAw acc= 78.2% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.2% | Valid: time=  0.4s loss=0.650, TAw acc= 78.2% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 71.1% | Valid: time=  0.4s loss=0.652, TAw acc= 78.2% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 71.1% | Valid: time=  0.4s loss=0.652, TAw acc= 78.2% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.847, TAw acc= 72.0% | Valid: time=  0.4s loss=0.653, TAw acc= 78.2% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.907, TAw acc= 69.5% | Valid: time=  0.4s loss=0.572, TAw acc= 81.2% |
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.910, TAw acc= 69.0% | Valid: time=  0.4s loss=0.576, TAw acc= 80.8% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.905, TAw acc= 70.7% | Valid: time=  0.4s loss=0.581, TAw acc= 80.6% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.915, TAw acc= 69.3% | Valid: time=  0.4s loss=0.585, TAw acc= 80.6% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.879, TAw acc= 71.2% | Valid: time=  0.4s loss=0.590, TAw acc= 80.4% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 70.0% | Valid: time=  0.4s loss=0.595, TAw acc= 80.0% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 70.6% | Valid: time=  0.4s loss=0.599, TAw acc= 80.2% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 70.9% | Valid: time=  0.4s loss=0.602, TAw acc= 80.4% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.891, TAw acc= 71.1% | Valid: time=  0.4s loss=0.606, TAw acc= 80.0% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 71.1% | Valid: time=  0.4s loss=0.609, TAw acc= 80.0% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc=  5.6%, forg= 71.7% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 41.5%, forg= 23.9% <<<
>>> Test on task  2 : loss=0.623 | TAw acc= 78.7%, forg=  1.0%| TAg acc= 12.4%, forg= 26.1% <<<
>>> Test on task  3 : loss=0.615 | TAw acc= 80.0%, forg= -0.2%| TAg acc= 21.8%, forg= 18.9% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 42.0%, forg=  9.6% <<<
>>> Test on task  5 : loss=0.798 | TAw acc= 69.6%, forg=  0.3%| TAg acc= 32.9%, forg=  8.3% <<<
>>> Test on task  6 : loss=0.559 | TAw acc= 80.1%, forg=  0.0%| TAg acc= 53.6%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  7
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-7): 8 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.108, TAw acc= 61.5% | Valid: time=  0.4s loss=0.806, TAw acc= 70.0% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.071, TAw acc= 63.5% | Valid: time=  0.4s loss=0.759, TAw acc= 72.2% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.038, TAw acc= 63.7% | Valid: time=  0.4s loss=0.810, TAw acc= 72.2% |
| Epoch   4, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.028, TAw acc= 64.9% | Valid: time=  0.4s loss=0.744, TAw acc= 71.8% | *
| Epoch   5, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.992, TAw acc= 66.6% | Valid: time=  0.4s loss=0.729, TAw acc= 71.6% | *
| Epoch   6, lr=2.6e-02 time=  3.2s/  1.9s | Train: loss=0.973, TAw acc= 66.9% | Valid: time=  0.4s loss=0.714, TAw acc= 74.8% | *
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.982, TAw acc= 66.5% | Valid: time=  0.5s loss=0.734, TAw acc= 74.2% |
| Epoch   8, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.009, TAw acc= 66.4% | Valid: time=  0.4s loss=0.698, TAw acc= 74.4% | *
| Epoch   9, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.965, TAw acc= 67.3% | Valid: time=  0.4s loss=0.720, TAw acc= 74.8% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.967, TAw acc= 66.1% | Valid: time=  0.4s loss=0.736, TAw acc= 72.8% |
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.966, TAw acc= 67.0% | Valid: time=  0.4s loss=0.720, TAw acc= 74.6% |
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.939, TAw acc= 68.4% | Valid: time=  0.4s loss=0.703, TAw acc= 75.2% |
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 67.8% | Valid: time=  0.4s loss=0.697, TAw acc= 74.8% | *
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.945, TAw acc= 67.8% | Valid: time=  0.4s loss=0.699, TAw acc= 75.4% |
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.935, TAw acc= 68.9% | Valid: time=  0.4s loss=0.712, TAw acc= 75.4% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.932, TAw acc= 67.7% | Valid: time=  0.4s loss=0.716, TAw acc= 74.6% |
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.957, TAw acc= 67.4% | Valid: time=  0.4s loss=0.700, TAw acc= 76.2% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.953, TAw acc= 67.4% | Valid: time=  0.4s loss=0.696, TAw acc= 74.6% | *
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.917, TAw acc= 68.2% | Valid: time=  0.4s loss=0.701, TAw acc= 75.2% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.964, TAw acc= 67.1% | Valid: time=  0.4s loss=0.694, TAw acc= 75.0% | *
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.907, TAw acc= 68.8% | Valid: time=  0.4s loss=0.724, TAw acc= 75.4% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.950, TAw acc= 68.0% | Valid: time=  0.4s loss=0.707, TAw acc= 74.6% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.919, TAw acc= 68.6% | Valid: time=  0.4s loss=0.708, TAw acc= 76.0% |
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.956, TAw acc= 67.3% | Valid: time=  0.4s loss=0.708, TAw acc= 75.6% |
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.932, TAw acc= 67.9% | Valid: time=  0.4s loss=0.701, TAw acc= 75.4% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.912, TAw acc= 68.5% | Valid: time=  0.4s loss=0.745, TAw acc= 74.0% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 69.0% | Valid: time=  0.4s loss=0.748, TAw acc= 74.6% |
| Epoch  28, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.919, TAw acc= 68.4% | Valid: time=  0.4s loss=0.770, TAw acc= 74.6% |
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.954, TAw acc= 66.9% | Valid: time=  0.4s loss=0.738, TAw acc= 73.2% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.904, TAw acc= 68.3% | Valid: time=  0.4s loss=0.693, TAw acc= 77.6% | *
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.965, TAw acc= 67.2% | Valid: time=  0.4s loss=0.697, TAw acc= 76.0% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.928, TAw acc= 69.0% | Valid: time=  0.4s loss=0.707, TAw acc= 74.6% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.946, TAw acc= 67.7% | Valid: time=  0.4s loss=0.701, TAw acc= 75.4% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.906, TAw acc= 68.1% | Valid: time=  0.4s loss=0.766, TAw acc= 74.2% |
| Epoch  35, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.932, TAw acc= 68.5% | Valid: time=  0.4s loss=0.711, TAw acc= 74.4% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.923, TAw acc= 68.9% | Valid: time=  0.4s loss=0.651, TAw acc= 77.0% | *
| Epoch  37, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.923, TAw acc= 68.0% | Valid: time=  0.4s loss=0.683, TAw acc= 76.4% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.906, TAw acc= 69.4% | Valid: time=  0.4s loss=0.688, TAw acc= 76.0% |
| Epoch  39, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.933, TAw acc= 67.3% | Valid: time=  0.4s loss=0.741, TAw acc= 73.6% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.931, TAw acc= 68.4% | Valid: time=  0.4s loss=0.657, TAw acc= 76.6% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.914, TAw acc= 68.6% | Valid: time=  0.4s loss=0.707, TAw acc= 74.6% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.899, TAw acc= 70.2% | Valid: time=  0.4s loss=0.670, TAw acc= 76.6% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 68.7% | Valid: time=  0.4s loss=0.709, TAw acc= 75.0% |
| Epoch  44, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.907, TAw acc= 68.8% | Valid: time=  0.4s loss=0.667, TAw acc= 77.8% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.912, TAw acc= 67.8% | Valid: time=  0.4s loss=0.704, TAw acc= 74.8% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.895, TAw acc= 69.4% | Valid: time=  0.4s loss=0.690, TAw acc= 75.4% |
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.921, TAw acc= 69.5% | Valid: time=  0.4s loss=0.669, TAw acc= 76.6% |
| Epoch  48, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.901, TAw acc= 69.0% | Valid: time=  0.4s loss=0.716, TAw acc= 75.0% |
| Epoch  49, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.911, TAw acc= 69.5% | Valid: time=  0.4s loss=0.729, TAw acc= 74.6% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.886, TAw acc= 69.1% | Valid: time=  0.4s loss=0.670, TAw acc= 76.0% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.918, TAw acc= 68.7% | Valid: time=  0.4s loss=0.653, TAw acc= 77.2% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 69.1% | Valid: time=  0.4s loss=0.701, TAw acc= 75.8% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.884, TAw acc= 69.8% | Valid: time=  0.4s loss=0.694, TAw acc= 77.2% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.939, TAw acc= 68.9% | Valid: time=  0.4s loss=0.652, TAw acc= 77.0% |
| Epoch  55, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 69.3% | Valid: time=  0.4s loss=0.710, TAw acc= 77.0% |
| Epoch  56, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.882, TAw acc= 68.8% | Valid: time=  0.4s loss=0.683, TAw acc= 78.2% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.885, TAw acc= 68.9% | Valid: time=  0.4s loss=0.711, TAw acc= 77.0% |
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.884, TAw acc= 69.1% | Valid: time=  0.4s loss=0.716, TAw acc= 74.0% |
| Epoch  59, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.895, TAw acc= 68.9% | Valid: time=  0.4s loss=0.698, TAw acc= 77.0% |
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.876, TAw acc= 69.6% | Valid: time=  0.4s loss=0.730, TAw acc= 75.4% |
| Epoch  61, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.904, TAw acc= 69.3% | Valid: time=  0.4s loss=0.687, TAw acc= 77.6% |
| Epoch  62, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.866, TAw acc= 68.9% | Valid: time=  0.4s loss=0.718, TAw acc= 75.8% |
| Epoch  63, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.892, TAw acc= 70.0% | Valid: time=  0.4s loss=0.677, TAw acc= 76.4% |
| Epoch  64, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.859, TAw acc= 69.8% | Valid: time=  0.4s loss=0.687, TAw acc= 76.4% |
| Epoch  65, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.873, TAw acc= 69.9% | Valid: time=  0.4s loss=0.708, TAw acc= 77.0% |
| Epoch  66, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.870, TAw acc= 69.9% | Valid: time=  0.4s loss=0.673, TAw acc= 78.8% | lr=8.8e-03
| Epoch  67, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.911, TAw acc= 69.0% | Valid: time=  0.4s loss=0.703, TAw acc= 76.2% |
| Epoch  68, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.926, TAw acc= 69.3% | Valid: time=  0.5s loss=0.653, TAw acc= 76.4% |
| Epoch  69, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.896, TAw acc= 69.7% | Valid: time=  0.4s loss=0.691, TAw acc= 76.0% |
| Epoch  70, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.900, TAw acc= 69.0% | Valid: time=  0.4s loss=0.685, TAw acc= 76.2% |
| Epoch  71, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.918, TAw acc= 68.9% | Valid: time=  0.4s loss=0.707, TAw acc= 76.0% |
| Epoch  72, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.888, TAw acc= 69.0% | Valid: time=  0.4s loss=0.696, TAw acc= 76.4% |
| Epoch  73, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.891, TAw acc= 69.8% | Valid: time=  0.4s loss=0.690, TAw acc= 75.2% |
| Epoch  74, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.929, TAw acc= 68.5% | Valid: time=  0.4s loss=0.693, TAw acc= 75.6% |
| Epoch  75, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.889, TAw acc= 69.5% | Valid: time=  0.4s loss=0.722, TAw acc= 77.0% |
| Epoch  76, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.898, TAw acc= 68.7% | Valid: time=  0.4s loss=0.671, TAw acc= 77.6% |
| Epoch  77, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.878, TAw acc= 70.0% | Valid: time=  0.4s loss=0.696, TAw acc= 77.0% |
| Epoch  78, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.896, TAw acc= 69.7% | Valid: time=  0.4s loss=0.700, TAw acc= 77.4% |
| Epoch  79, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.903, TAw acc= 69.2% | Valid: time=  0.4s loss=0.704, TAw acc= 75.6% |
| Epoch  80, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.887, TAw acc= 69.7% | Valid: time=  0.4s loss=0.673, TAw acc= 76.2% |
| Epoch  81, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.890, TAw acc= 68.7% | Valid: time=  0.4s loss=0.671, TAw acc= 78.0% |
| Epoch  82, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.878, TAw acc= 69.5% | Valid: time=  0.4s loss=0.723, TAw acc= 75.0% |
| Epoch  83, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.880, TAw acc= 70.2% | Valid: time=  0.4s loss=0.666, TAw acc= 76.4% |
| Epoch  84, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.866, TAw acc= 70.3% | Valid: time=  0.4s loss=0.697, TAw acc= 74.8% |
| Epoch  85, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.909, TAw acc= 68.4% | Valid: time=  0.4s loss=0.691, TAw acc= 76.2% |
| Epoch  86, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.920, TAw acc= 69.1% | Valid: time=  0.4s loss=0.690, TAw acc= 76.6% |
| Epoch  87, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.854, TAw acc= 70.5% | Valid: time=  0.4s loss=0.685, TAw acc= 75.4% |
| Epoch  88, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.877, TAw acc= 69.8% | Valid: time=  0.4s loss=0.686, TAw acc= 78.2% |
| Epoch  89, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.885, TAw acc= 69.8% | Valid: time=  0.4s loss=0.687, TAw acc= 77.2% |
| Epoch  90, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.871, TAw acc= 70.1% | Valid: time=  0.4s loss=0.711, TAw acc= 77.0% |
| Epoch  91, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.904, TAw acc= 69.7% | Valid: time=  0.4s loss=0.686, TAw acc= 77.0% |
| Epoch  92, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.883, TAw acc= 69.1% | Valid: time=  0.4s loss=0.698, TAw acc= 75.2% |
| Epoch  93, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.901, TAw acc= 69.0% | Valid: time=  0.4s loss=0.679, TAw acc= 76.4% |
| Epoch  94, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.883, TAw acc= 69.8% | Valid: time=  0.4s loss=0.662, TAw acc= 77.0% |
| Epoch  95, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.888, TAw acc= 69.6% | Valid: time=  0.4s loss=0.663, TAw acc= 76.4% |
| Epoch  96, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.896, TAw acc= 69.3% | Valid: time=  0.4s loss=0.691, TAw acc= 74.6% | lr=2.9e-03
| Epoch  97, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.899, TAw acc= 69.3% | Valid: time=  0.4s loss=0.695, TAw acc= 76.2% |
| Epoch  98, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.897, TAw acc= 68.4% | Valid: time=  0.4s loss=0.697, TAw acc= 76.4% |
| Epoch  99, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.912, TAw acc= 69.5% | Valid: time=  0.4s loss=0.673, TAw acc= 76.8% |
| Epoch 100, lr=2.9e-03 time=  2.8s/  1.9s | Train: loss=0.903, TAw acc= 68.5% | Valid: time=  0.4s loss=0.702, TAw acc= 76.4% |
== Rank Reduction [task:7] ==
best_loss=0.651,  best_acc=0.770
 r=256, loss=0.890, acc=0.698
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.877, acc=0.706
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.861, acc=0.706
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.838, acc=0.722
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.807, acc=0.728
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.789, acc=0.728
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.774, acc=0.734
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.774, acc=0.742
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.775, acc=0.754
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.741, acc=0.754
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.702, acc=0.758
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.683, acc=0.764
 loss_margin=0.006, acc_margin=0.004
 r=640, loss=0.666, acc=0.768
 loss_margin=0.006, acc_margin=0.004
 r=672, loss=0.660, acc=0.768
 loss_margin=0.006, acc_margin=0.004
 r=704, loss=0.656, acc=0.772
 loss_margin=0.006, acc_margin=0.004
best_r=704, loss=0.656, acc=0.772
== Header Training for Low Rank [task:7] ==
loss=0.656 acc=0.772
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.926, TAw acc= 69.1% | Valid: time=  0.4s loss=0.679, TAw acc= 76.6% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.923, TAw acc= 68.8% | Valid: time=  0.4s loss=0.685, TAw acc= 76.6% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.905, TAw acc= 69.5% | Valid: time=  0.4s loss=0.683, TAw acc= 76.8% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.903, TAw acc= 69.9% | Valid: time=  0.4s loss=0.682, TAw acc= 76.6% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.902, TAw acc= 70.0% | Valid: time=  0.4s loss=0.681, TAw acc= 76.0% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.878, TAw acc= 70.4% | Valid: time=  0.4s loss=0.694, TAw acc= 76.6% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 69.8% | Valid: time=  0.4s loss=0.688, TAw acc= 76.0% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.892, TAw acc= 70.7% | Valid: time=  0.4s loss=0.695, TAw acc= 77.0% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.901, TAw acc= 69.6% | Valid: time=  0.4s loss=0.681, TAw acc= 76.0% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.898, TAw acc= 70.0% | Valid: time=  0.4s loss=0.692, TAw acc= 76.6% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 69.6% | Valid: time=  0.4s loss=0.690, TAw acc= 77.0% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.880, TAw acc= 70.4% | Valid: time=  0.4s loss=0.703, TAw acc= 76.0% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 71.1% | Valid: time=  0.4s loss=0.697, TAw acc= 75.8% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 69.7% | Valid: time=  0.4s loss=0.701, TAw acc= 77.4% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.881, TAw acc= 70.2% | Valid: time=  0.4s loss=0.700, TAw acc= 76.6% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.887, TAw acc= 70.7% | Valid: time=  0.4s loss=0.711, TAw acc= 76.8% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 69.9% | Valid: time=  0.4s loss=0.704, TAw acc= 76.0% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 70.9% | Valid: time=  0.4s loss=0.706, TAw acc= 76.8% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.877, TAw acc= 70.2% | Valid: time=  0.4s loss=0.702, TAw acc= 75.8% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.883, TAw acc= 70.2% | Valid: time=  0.4s loss=0.714, TAw acc= 75.8% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.872, TAw acc= 70.2% | Valid: time=  0.4s loss=0.705, TAw acc= 76.4% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 69.6% | Valid: time=  0.4s loss=0.695, TAw acc= 76.6% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 70.0% | Valid: time=  0.4s loss=0.703, TAw acc= 76.2% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.871, TAw acc= 69.9% | Valid: time=  0.4s loss=0.692, TAw acc= 76.8% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.894, TAw acc= 70.3% | Valid: time=  0.4s loss=0.687, TAw acc= 76.2% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.884, TAw acc= 69.7% | Valid: time=  0.4s loss=0.699, TAw acc= 77.0% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.859, TAw acc= 70.7% | Valid: time=  0.4s loss=0.696, TAw acc= 76.8% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.842, TAw acc= 71.7% | Valid: time=  0.4s loss=0.706, TAw acc= 76.0% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.845, TAw acc= 70.9% | Valid: time=  0.4s loss=0.698, TAw acc= 76.2% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.873, TAw acc= 69.9% | Valid: time=  0.4s loss=0.704, TAw acc= 76.0% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 69.6% | Valid: time=  0.4s loss=0.672, TAw acc= 77.0% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.912, TAw acc= 69.3% | Valid: time=  0.4s loss=0.681, TAw acc= 76.6% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 69.3% | Valid: time=  0.4s loss=0.684, TAw acc= 76.8% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.925, TAw acc= 69.0% | Valid: time=  0.4s loss=0.682, TAw acc= 76.6% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.917, TAw acc= 69.7% | Valid: time=  0.4s loss=0.686, TAw acc= 77.2% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.929, TAw acc= 69.1% | Valid: time=  0.4s loss=0.682, TAw acc= 76.2% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.922, TAw acc= 69.1% | Valid: time=  0.4s loss=0.684, TAw acc= 76.6% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.925, TAw acc= 69.0% | Valid: time=  0.4s loss=0.686, TAw acc= 76.4% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.915, TAw acc= 70.3% | Valid: time=  0.4s loss=0.683, TAw acc= 76.2% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.923, TAw acc= 69.4% | Valid: time=  0.4s loss=0.685, TAw acc= 76.2% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 69.6% | Valid: time=  0.4s loss=0.687, TAw acc= 76.4% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.918, TAw acc= 68.8% | Valid: time=  0.4s loss=0.690, TAw acc= 76.6% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.907, TAw acc= 69.5% | Valid: time=  0.4s loss=0.690, TAw acc= 76.4% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.913, TAw acc= 69.5% | Valid: time=  0.4s loss=0.688, TAw acc= 76.2% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.912, TAw acc= 69.4% | Valid: time=  0.4s loss=0.690, TAw acc= 76.6% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.906, TAw acc= 69.7% | Valid: time=  0.4s loss=0.688, TAw acc= 76.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.896, TAw acc= 70.1% | Valid: time=  0.4s loss=0.688, TAw acc= 76.2% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.878, TAw acc= 70.7% | Valid: time=  0.4s loss=0.689, TAw acc= 76.6% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.899, TAw acc= 70.3% | Valid: time=  0.4s loss=0.687, TAw acc= 77.0% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.893, TAw acc= 69.9% | Valid: time=  0.4s loss=0.690, TAw acc= 76.8% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.908, TAw acc= 70.0% | Valid: time=  0.4s loss=0.691, TAw acc= 77.0% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.904, TAw acc= 69.9% | Valid: time=  0.4s loss=0.689, TAw acc= 76.8% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.886, TAw acc= 70.6% | Valid: time=  0.4s loss=0.691, TAw acc= 77.0% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.891, TAw acc= 70.2% | Valid: time=  0.4s loss=0.690, TAw acc= 76.4% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.905, TAw acc= 69.6% | Valid: time=  0.4s loss=0.692, TAw acc= 76.8% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.893, TAw acc= 70.4% | Valid: time=  0.4s loss=0.692, TAw acc= 76.4% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.869, TAw acc= 71.1% | Valid: time=  0.4s loss=0.690, TAw acc= 76.4% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.876, TAw acc= 70.7% | Valid: time=  0.4s loss=0.694, TAw acc= 76.4% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.882, TAw acc= 70.0% | Valid: time=  0.4s loss=0.693, TAw acc= 76.8% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.895, TAw acc= 69.8% | Valid: time=  0.5s loss=0.691, TAw acc= 76.8% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.933, TAw acc= 68.5% | Valid: time=  0.4s loss=0.660, TAw acc= 77.8% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.938, TAw acc= 68.5% | Valid: time=  0.4s loss=0.668, TAw acc= 76.6% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.925, TAw acc= 69.5% | Valid: time=  0.4s loss=0.672, TAw acc= 77.0% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.939, TAw acc= 69.0% | Valid: time=  0.4s loss=0.674, TAw acc= 76.8% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.926, TAw acc= 69.1% | Valid: time=  0.4s loss=0.675, TAw acc= 76.8% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.920, TAw acc= 70.3% | Valid: time=  0.4s loss=0.679, TAw acc= 76.8% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.932, TAw acc= 69.0% | Valid: time=  0.4s loss=0.681, TAw acc= 76.6% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.926, TAw acc= 68.9% | Valid: time=  0.4s loss=0.683, TAw acc= 76.6% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.906, TAw acc= 70.4% | Valid: time=  0.4s loss=0.684, TAw acc= 76.6% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 69.3% | Valid: time=  0.4s loss=0.683, TAw acc= 76.6% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.913, TAw acc= 69.8% | Valid: time=  0.4s loss=0.684, TAw acc= 76.6% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 69.4% | Valid: time=  0.4s loss=0.684, TAw acc= 76.6% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.934, TAw acc= 69.0% | Valid: time=  0.4s loss=0.686, TAw acc= 76.6% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.924, TAw acc= 69.7% | Valid: time=  0.4s loss=0.686, TAw acc= 76.4% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.919, TAw acc= 69.1% | Valid: time=  0.4s loss=0.686, TAw acc= 76.2% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.903, TAw acc= 70.4% | Valid: time=  0.4s loss=0.685, TAw acc= 76.2% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 69.2% | Valid: time=  0.4s loss=0.685, TAw acc= 76.4% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.919, TAw acc= 69.7% | Valid: time=  0.4s loss=0.686, TAw acc= 76.2% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.915, TAw acc= 69.4% | Valid: time=  0.4s loss=0.684, TAw acc= 76.0% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.915, TAw acc= 68.5% | Valid: time=  0.4s loss=0.685, TAw acc= 76.4% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.932, TAw acc= 69.0% | Valid: time=  0.4s loss=0.685, TAw acc= 76.4% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.918, TAw acc= 69.0% | Valid: time=  0.4s loss=0.686, TAw acc= 76.0% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.903, TAw acc= 69.9% | Valid: time=  0.4s loss=0.686, TAw acc= 76.2% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.907, TAw acc= 69.8% | Valid: time=  0.4s loss=0.685, TAw acc= 76.2% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.897, TAw acc= 70.4% | Valid: time=  0.4s loss=0.686, TAw acc= 76.2% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.904, TAw acc= 70.0% | Valid: time=  0.4s loss=0.687, TAw acc= 76.2% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.910, TAw acc= 69.5% | Valid: time=  0.4s loss=0.686, TAw acc= 75.8% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.911, TAw acc= 70.4% | Valid: time=  0.4s loss=0.685, TAw acc= 76.4% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.916, TAw acc= 68.9% | Valid: time=  0.4s loss=0.686, TAw acc= 76.2% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.912, TAw acc= 69.8% | Valid: time=  0.4s loss=0.686, TAw acc= 76.4% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.930, TAw acc= 68.6% | Valid: time=  0.4s loss=0.658, TAw acc= 77.2% |
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.943, TAw acc= 68.7% | Valid: time=  0.4s loss=0.660, TAw acc= 77.2% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.931, TAw acc= 69.3% | Valid: time=  0.4s loss=0.662, TAw acc= 77.8% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.943, TAw acc= 68.6% | Valid: time=  0.4s loss=0.663, TAw acc= 77.4% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.949, TAw acc= 68.8% | Valid: time=  0.4s loss=0.666, TAw acc= 77.2% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.942, TAw acc= 68.5% | Valid: time=  0.4s loss=0.667, TAw acc= 76.8% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 69.4% | Valid: time=  0.4s loss=0.669, TAw acc= 77.0% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.921, TAw acc= 69.0% | Valid: time=  0.4s loss=0.670, TAw acc= 77.0% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.935, TAw acc= 68.7% | Valid: time=  0.4s loss=0.672, TAw acc= 76.8% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.932, TAw acc= 68.5% | Valid: time=  0.4s loss=0.673, TAw acc= 76.8% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc=  4.1%, forg= 73.2% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 38.6%, forg= 26.8% <<<
>>> Test on task  2 : loss=0.613 | TAw acc= 78.8%, forg=  0.9%| TAg acc= 11.4%, forg= 27.1% <<<
>>> Test on task  3 : loss=0.613 | TAw acc= 80.2%, forg= -0.2%| TAg acc= 20.3%, forg= 20.4% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 39.8%, forg= 11.8% <<<
>>> Test on task  5 : loss=0.786 | TAw acc= 70.4%, forg= -0.5%| TAg acc= 31.3%, forg=  9.9% <<<
>>> Test on task  6 : loss=0.558 | TAw acc= 81.2%, forg= -1.1%| TAg acc= 51.2%, forg=  2.4% <<<
>>> Test on task  7 : loss=0.631 | TAw acc= 77.8%, forg=  0.0%| TAg acc= 23.2%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  8
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-8): 9 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.262, TAw acc= 56.2% | Valid: time=  0.4s loss=0.854, TAw acc= 71.0% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.183, TAw acc= 58.7% | Valid: time=  0.4s loss=0.815, TAw acc= 71.0% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.148, TAw acc= 60.8% | Valid: time=  0.4s loss=0.817, TAw acc= 72.0% |
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.113, TAw acc= 62.8% | Valid: time=  0.4s loss=0.816, TAw acc= 72.4% |
| Epoch   5, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.124, TAw acc= 62.3% | Valid: time=  0.4s loss=0.842, TAw acc= 72.2% |
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.118, TAw acc= 61.7% | Valid: time=  0.4s loss=0.829, TAw acc= 73.0% |
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.059, TAw acc= 64.8% | Valid: time=  0.4s loss=0.826, TAw acc= 71.4% |
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.126, TAw acc= 62.1% | Valid: time=  0.4s loss=0.808, TAw acc= 70.6% | *
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.078, TAw acc= 63.5% | Valid: time=  0.4s loss=0.823, TAw acc= 71.2% |
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.099, TAw acc= 63.3% | Valid: time=  0.4s loss=0.784, TAw acc= 73.4% | *
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.075, TAw acc= 62.9% | Valid: time=  0.4s loss=0.884, TAw acc= 71.6% |
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.098, TAw acc= 63.0% | Valid: time=  0.4s loss=0.768, TAw acc= 73.2% | *
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.126, TAw acc= 62.6% | Valid: time=  0.4s loss=0.766, TAw acc= 73.8% | *
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.064, TAw acc= 64.0% | Valid: time=  0.4s loss=0.779, TAw acc= 73.2% |
| Epoch  15, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.060, TAw acc= 64.7% | Valid: time=  0.4s loss=0.802, TAw acc= 73.0% |
| Epoch  16, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.044, TAw acc= 64.7% | Valid: time=  0.4s loss=0.768, TAw acc= 74.2% |
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.051, TAw acc= 63.8% | Valid: time=  0.4s loss=0.809, TAw acc= 73.6% |
| Epoch  18, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.028, TAw acc= 65.2% | Valid: time=  0.4s loss=0.776, TAw acc= 74.0% |
| Epoch  19, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.042, TAw acc= 65.2% | Valid: time=  0.4s loss=0.774, TAw acc= 73.8% |
| Epoch  20, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.054, TAw acc= 65.6% | Valid: time=  0.4s loss=0.756, TAw acc= 73.2% | *
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.069, TAw acc= 64.2% | Valid: time=  0.4s loss=0.838, TAw acc= 73.2% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.045, TAw acc= 63.8% | Valid: time=  0.4s loss=0.820, TAw acc= 72.0% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.060, TAw acc= 64.2% | Valid: time=  0.4s loss=0.892, TAw acc= 71.4% |
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.045, TAw acc= 64.7% | Valid: time=  0.4s loss=0.850, TAw acc= 72.0% |
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.026, TAw acc= 65.3% | Valid: time=  0.4s loss=0.806, TAw acc= 72.4% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.052, TAw acc= 64.0% | Valid: time=  0.4s loss=0.779, TAw acc= 74.0% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.036, TAw acc= 64.3% | Valid: time=  0.4s loss=0.886, TAw acc= 71.4% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.033, TAw acc= 65.4% | Valid: time=  0.4s loss=0.816, TAw acc= 73.0% |
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.032, TAw acc= 65.1% | Valid: time=  0.4s loss=0.788, TAw acc= 72.6% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.023, TAw acc= 65.6% | Valid: time=  0.4s loss=0.793, TAw acc= 71.8% |
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.015, TAw acc= 64.8% | Valid: time=  0.4s loss=0.808, TAw acc= 72.4% |
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.022, TAw acc= 65.4% | Valid: time=  0.4s loss=0.776, TAw acc= 72.8% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.000, TAw acc= 66.8% | Valid: time=  0.4s loss=0.776, TAw acc= 74.2% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.015, TAw acc= 65.3% | Valid: time=  0.4s loss=0.803, TAw acc= 74.0% |
| Epoch  35, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.027, TAw acc= 64.7% | Valid: time=  0.4s loss=0.781, TAw acc= 74.4% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.011, TAw acc= 65.5% | Valid: time=  0.4s loss=0.784, TAw acc= 74.4% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.045, TAw acc= 65.3% | Valid: time=  0.4s loss=0.783, TAw acc= 73.6% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.031, TAw acc= 63.8% | Valid: time=  0.4s loss=0.829, TAw acc= 72.8% |
| Epoch  39, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.033, TAw acc= 64.9% | Valid: time=  0.4s loss=0.763, TAw acc= 73.8% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.010, TAw acc= 66.1% | Valid: time=  0.4s loss=0.789, TAw acc= 73.8% |
| Epoch  41, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.049, TAw acc= 65.0% | Valid: time=  0.4s loss=0.771, TAw acc= 74.4% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.034, TAw acc= 65.6% | Valid: time=  0.4s loss=0.774, TAw acc= 74.0% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.022, TAw acc= 65.4% | Valid: time=  0.4s loss=0.777, TAw acc= 74.0% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.019, TAw acc= 65.5% | Valid: time=  0.4s loss=0.794, TAw acc= 73.0% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 66.4% | Valid: time=  0.4s loss=0.816, TAw acc= 73.8% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.011, TAw acc= 65.6% | Valid: time=  0.4s loss=0.756, TAw acc= 74.0% | *
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.008, TAw acc= 65.0% | Valid: time=  0.4s loss=0.843, TAw acc= 73.4% |
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.997, TAw acc= 67.0% | Valid: time=  0.4s loss=0.786, TAw acc= 74.0% |
| Epoch  49, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.022, TAw acc= 66.1% | Valid: time=  0.4s loss=0.755, TAw acc= 74.2% | *
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.007, TAw acc= 65.9% | Valid: time=  0.4s loss=0.870, TAw acc= 72.0% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.012, TAw acc= 66.1% | Valid: time=  0.4s loss=0.767, TAw acc= 75.6% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.019, TAw acc= 65.0% | Valid: time=  0.4s loss=0.794, TAw acc= 74.0% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 66.2% | Valid: time=  0.4s loss=0.839, TAw acc= 75.0% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.970, TAw acc= 67.5% | Valid: time=  0.4s loss=0.837, TAw acc= 74.0% |
| Epoch  55, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.032, TAw acc= 64.6% | Valid: time=  0.4s loss=0.786, TAw acc= 75.8% |
| Epoch  56, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 65.5% | Valid: time=  0.4s loss=0.774, TAw acc= 74.2% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 66.9% | Valid: time=  0.4s loss=0.825, TAw acc= 73.0% |
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.993, TAw acc= 65.5% | Valid: time=  0.4s loss=0.747, TAw acc= 77.0% | *
| Epoch  59, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 65.8% | Valid: time=  0.4s loss=0.724, TAw acc= 76.4% | *
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.019, TAw acc= 64.8% | Valid: time=  0.4s loss=0.813, TAw acc= 73.4% |
| Epoch  61, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 68.1% | Valid: time=  0.4s loss=0.773, TAw acc= 74.0% |
| Epoch  62, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.968, TAw acc= 67.6% | Valid: time=  0.4s loss=0.774, TAw acc= 75.8% |
| Epoch  63, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.001, TAw acc= 66.0% | Valid: time=  0.4s loss=0.755, TAw acc= 75.4% |
| Epoch  64, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.985, TAw acc= 66.8% | Valid: time=  0.4s loss=0.774, TAw acc= 74.6% |
| Epoch  65, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.008, TAw acc= 66.1% | Valid: time=  0.4s loss=0.781, TAw acc= 75.0% |
| Epoch  66, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 65.9% | Valid: time=  0.4s loss=0.742, TAw acc= 77.2% |
| Epoch  67, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.973, TAw acc= 66.8% | Valid: time=  0.4s loss=0.748, TAw acc= 75.8% |
| Epoch  68, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.996, TAw acc= 66.1% | Valid: time=  0.4s loss=0.758, TAw acc= 74.8% |
| Epoch  69, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.014, TAw acc= 65.4% | Valid: time=  0.4s loss=0.769, TAw acc= 75.2% |
| Epoch  70, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.004, TAw acc= 65.3% | Valid: time=  0.4s loss=0.794, TAw acc= 74.8% |
| Epoch  71, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.023, TAw acc= 65.7% | Valid: time=  0.4s loss=0.751, TAw acc= 75.6% |
| Epoch  72, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.953, TAw acc= 68.5% | Valid: time=  0.4s loss=0.792, TAw acc= 75.2% |
| Epoch  73, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.002, TAw acc= 65.4% | Valid: time=  0.4s loss=0.822, TAw acc= 74.4% |
| Epoch  74, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.029, TAw acc= 64.3% | Valid: time=  0.4s loss=0.812, TAw acc= 73.8% |
| Epoch  75, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 66.0% | Valid: time=  0.4s loss=0.779, TAw acc= 75.6% |
| Epoch  76, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.963, TAw acc= 66.7% | Valid: time=  0.4s loss=0.802, TAw acc= 73.8% |
| Epoch  77, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.982, TAw acc= 66.7% | Valid: time=  0.4s loss=0.796, TAw acc= 74.6% |
| Epoch  78, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.024, TAw acc= 66.2% | Valid: time=  0.4s loss=0.770, TAw acc= 75.4% |
| Epoch  79, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.017, TAw acc= 65.4% | Valid: time=  0.4s loss=0.765, TAw acc= 75.6% |
| Epoch  80, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 66.2% | Valid: time=  0.4s loss=0.777, TAw acc= 75.2% |
| Epoch  81, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.968, TAw acc= 67.8% | Valid: time=  0.4s loss=0.753, TAw acc= 74.8% |
| Epoch  82, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.001, TAw acc= 66.8% | Valid: time=  0.5s loss=0.753, TAw acc= 75.4% |
| Epoch  83, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.988, TAw acc= 66.6% | Valid: time=  0.4s loss=0.733, TAw acc= 76.4% |
| Epoch  84, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.985, TAw acc= 65.9% | Valid: time=  0.4s loss=0.765, TAw acc= 76.2% |
| Epoch  85, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.005, TAw acc= 65.4% | Valid: time=  0.4s loss=0.776, TAw acc= 75.6% |
| Epoch  86, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 66.5% | Valid: time=  0.4s loss=0.725, TAw acc= 77.4% |
| Epoch  87, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.963, TAw acc= 66.8% | Valid: time=  0.4s loss=0.762, TAw acc= 76.2% |
| Epoch  88, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 66.2% | Valid: time=  0.4s loss=0.841, TAw acc= 73.4% |
| Epoch  89, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 65.0% | Valid: time=  0.4s loss=0.782, TAw acc= 73.8% | lr=8.8e-03
| Epoch  90, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.997, TAw acc= 66.1% | Valid: time=  0.4s loss=0.787, TAw acc= 75.8% |
| Epoch  91, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 66.2% | Valid: time=  0.4s loss=0.781, TAw acc= 75.8% |
| Epoch  92, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.002, TAw acc= 65.9% | Valid: time=  0.4s loss=0.809, TAw acc= 74.6% |
| Epoch  93, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.002, TAw acc= 66.3% | Valid: time=  0.4s loss=0.784, TAw acc= 74.8% |
| Epoch  94, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 65.8% | Valid: time=  0.4s loss=0.792, TAw acc= 74.8% |
| Epoch  95, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.000, TAw acc= 66.6% | Valid: time=  0.4s loss=0.740, TAw acc= 75.8% |
| Epoch  96, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.028, TAw acc= 65.1% | Valid: time=  0.4s loss=0.804, TAw acc= 74.4% |
| Epoch  97, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.985, TAw acc= 67.3% | Valid: time=  0.4s loss=0.764, TAw acc= 75.2% |
| Epoch  98, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.006, TAw acc= 65.8% | Valid: time=  0.4s loss=0.838, TAw acc= 72.8% |
| Epoch  99, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.993, TAw acc= 66.5% | Valid: time=  0.4s loss=0.819, TAw acc= 75.0% |
| Epoch 100, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.990, TAw acc= 66.3% | Valid: time=  0.4s loss=0.792, TAw acc= 75.6% |
== Rank Reduction [task:8] ==
best_loss=0.724,  best_acc=0.764
 r=256, loss=0.845, acc=0.710
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.832, acc=0.722
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.828, acc=0.714
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.804, acc=0.732
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.796, acc=0.732
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.786, acc=0.726
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.771, acc=0.738
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.767, acc=0.744
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.768, acc=0.746
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.766, acc=0.748
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.754, acc=0.754
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.745, acc=0.766
 loss_margin=0.006, acc_margin=0.004
 r=640, loss=0.741, acc=0.772
 loss_margin=0.006, acc_margin=0.004
 r=672, loss=0.733, acc=0.772
 loss_margin=0.006, acc_margin=0.004
 r=704, loss=0.734, acc=0.770
 loss_margin=0.006, acc_margin=0.004
 r=736, loss=0.724, acc=0.774
 loss_margin=0.006, acc_margin=0.004
best_r=736, loss=0.724, acc=0.774
== Header Training for Low Rank [task:8] ==
loss=0.724 acc=0.774
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.991, TAw acc= 67.3% | Valid: time=  0.4s loss=0.756, TAw acc= 75.6% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.979, TAw acc= 67.7% | Valid: time=  0.4s loss=0.776, TAw acc= 74.2% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 67.5% | Valid: time=  0.4s loss=0.769, TAw acc= 75.2% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 67.1% | Valid: time=  0.4s loss=0.761, TAw acc= 75.4% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.6% | Valid: time=  0.4s loss=0.763, TAw acc= 74.8% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 67.4% | Valid: time=  0.4s loss=0.760, TAw acc= 75.8% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.961, TAw acc= 68.2% | Valid: time=  0.4s loss=0.767, TAw acc= 76.6% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 67.7% | Valid: time=  0.4s loss=0.767, TAw acc= 75.4% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.987, TAw acc= 67.0% | Valid: time=  0.4s loss=0.774, TAw acc= 75.6% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.958, TAw acc= 68.2% | Valid: time=  0.4s loss=0.770, TAw acc= 75.4% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.960, TAw acc= 68.9% | Valid: time=  0.4s loss=0.777, TAw acc= 74.8% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 68.1% | Valid: time=  0.4s loss=0.776, TAw acc= 75.2% |
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 68.4% | Valid: time=  0.4s loss=0.768, TAw acc= 75.0% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 67.2% | Valid: time=  0.4s loss=0.769, TAw acc= 74.2% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.7% | Valid: time=  0.4s loss=0.778, TAw acc= 75.0% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 67.8% | Valid: time=  0.4s loss=0.769, TAw acc= 74.4% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.953, TAw acc= 68.4% | Valid: time=  0.4s loss=0.783, TAw acc= 75.0% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.959, TAw acc= 67.9% | Valid: time=  0.4s loss=0.786, TAw acc= 75.2% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.954, TAw acc= 68.5% | Valid: time=  0.4s loss=0.790, TAw acc= 74.8% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.948, TAw acc= 67.9% | Valid: time=  0.4s loss=0.773, TAw acc= 75.8% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.946, TAw acc= 67.8% | Valid: time=  0.4s loss=0.779, TAw acc= 76.0% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 67.8% | Valid: time=  0.4s loss=0.774, TAw acc= 75.6% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.953, TAw acc= 68.3% | Valid: time=  0.4s loss=0.779, TAw acc= 76.2% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 66.8% | Valid: time=  0.4s loss=0.781, TAw acc= 75.6% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.960, TAw acc= 68.5% | Valid: time=  0.4s loss=0.776, TAw acc= 75.4% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.930, TAw acc= 69.3% | Valid: time=  0.4s loss=0.779, TAw acc= 75.0% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.4% | Valid: time=  0.4s loss=0.766, TAw acc= 75.4% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.953, TAw acc= 67.7% | Valid: time=  0.4s loss=0.778, TAw acc= 75.0% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.958, TAw acc= 67.9% | Valid: time=  0.4s loss=0.775, TAw acc= 75.6% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.942, TAw acc= 67.8% | Valid: time=  0.4s loss=0.772, TAw acc= 75.2% | lr=2.9e-03
| Epoch  31, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.003, TAw acc= 66.4% | Valid: time=  0.4s loss=0.737, TAw acc= 76.4% |
| Epoch  32, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.969, TAw acc= 68.6% | Valid: time=  0.4s loss=0.752, TAw acc= 75.8% |
| Epoch  33, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.990, TAw acc= 67.4% | Valid: time=  0.4s loss=0.758, TAw acc= 75.8% |
| Epoch  34, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.975, TAw acc= 68.0% | Valid: time=  0.4s loss=0.765, TAw acc= 74.8% |
| Epoch  35, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.975, TAw acc= 68.2% | Valid: time=  0.4s loss=0.770, TAw acc= 74.4% |
| Epoch  36, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 68.0% | Valid: time=  0.4s loss=0.769, TAw acc= 74.4% |
| Epoch  37, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 67.4% | Valid: time=  0.4s loss=0.766, TAw acc= 74.6% |
| Epoch  38, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.982, TAw acc= 68.4% | Valid: time=  0.4s loss=0.761, TAw acc= 74.6% |
| Epoch  39, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.007, TAw acc= 66.0% | Valid: time=  0.4s loss=0.761, TAw acc= 75.0% |
| Epoch  40, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.964, TAw acc= 68.5% | Valid: time=  0.4s loss=0.758, TAw acc= 75.4% |
| Epoch  41, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 68.0% | Valid: time=  0.4s loss=0.761, TAw acc= 76.0% |
| Epoch  42, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.006, TAw acc= 66.8% | Valid: time=  0.4s loss=0.763, TAw acc= 76.0% |
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.981, TAw acc= 67.9% | Valid: time=  0.4s loss=0.759, TAw acc= 76.0% |
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.979, TAw acc= 67.4% | Valid: time=  0.4s loss=0.764, TAw acc= 75.8% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.009, TAw acc= 66.7% | Valid: time=  0.4s loss=0.767, TAw acc= 75.0% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.978, TAw acc= 67.8% | Valid: time=  0.4s loss=0.763, TAw acc= 75.2% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.973, TAw acc= 68.5% | Valid: time=  0.4s loss=0.760, TAw acc= 76.4% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 67.2% | Valid: time=  0.4s loss=0.759, TAw acc= 75.8% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.979, TAw acc= 67.6% | Valid: time=  0.4s loss=0.761, TAw acc= 75.6% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 66.8% | Valid: time=  0.4s loss=0.765, TAw acc= 75.6% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.977, TAw acc= 67.4% | Valid: time=  0.4s loss=0.767, TAw acc= 76.0% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.3% | Valid: time=  0.4s loss=0.770, TAw acc= 75.6% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.8% | Valid: time=  0.4s loss=0.764, TAw acc= 76.0% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 66.8% | Valid: time=  0.4s loss=0.767, TAw acc= 75.4% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.5% | Valid: time=  0.4s loss=0.765, TAw acc= 75.6% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 66.3% | Valid: time=  0.4s loss=0.766, TAw acc= 75.6% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.969, TAw acc= 68.0% | Valid: time=  0.4s loss=0.768, TAw acc= 75.6% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.965, TAw acc= 67.6% | Valid: time=  0.4s loss=0.769, TAw acc= 75.6% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.961, TAw acc= 67.5% | Valid: time=  0.4s loss=0.767, TAw acc= 75.6% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 67.7% | Valid: time=  0.4s loss=0.769, TAw acc= 75.6% | lr=9.7e-04
| Epoch  61, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.036, TAw acc= 64.8% | Valid: time=  0.4s loss=0.725, TAw acc= 77.2% |
| Epoch  62, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.024, TAw acc= 66.1% | Valid: time=  0.4s loss=0.731, TAw acc= 76.2% |
| Epoch  63, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.005, TAw acc= 67.2% | Valid: time=  0.4s loss=0.737, TAw acc= 76.4% |
| Epoch  64, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.997, TAw acc= 66.7% | Valid: time=  0.4s loss=0.742, TAw acc= 76.0% |
| Epoch  65, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.002, TAw acc= 67.1% | Valid: time=  0.4s loss=0.746, TAw acc= 75.8% |
| Epoch  66, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.008, TAw acc= 66.9% | Valid: time=  0.4s loss=0.748, TAw acc= 75.8% |
| Epoch  67, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.996, TAw acc= 67.6% | Valid: time=  0.4s loss=0.754, TAw acc= 75.6% |
| Epoch  68, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.005, TAw acc= 67.4% | Valid: time=  0.4s loss=0.756, TAw acc= 75.6% |
| Epoch  69, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.002, TAw acc= 67.9% | Valid: time=  0.4s loss=0.756, TAw acc= 76.0% |
| Epoch  70, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.998, TAw acc= 67.6% | Valid: time=  0.4s loss=0.758, TAw acc= 76.0% |
| Epoch  71, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.989, TAw acc= 67.8% | Valid: time=  0.4s loss=0.759, TAw acc= 75.6% |
| Epoch  72, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 67.8% | Valid: time=  0.4s loss=0.760, TAw acc= 75.4% |
| Epoch  73, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 67.4% | Valid: time=  0.4s loss=0.761, TAw acc= 75.4% |
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.990, TAw acc= 67.4% | Valid: time=  0.4s loss=0.763, TAw acc= 75.2% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 67.6% | Valid: time=  0.4s loss=0.764, TAw acc= 75.4% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.008, TAw acc= 67.0% | Valid: time=  0.4s loss=0.763, TAw acc= 75.0% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.008, TAw acc= 67.4% | Valid: time=  0.4s loss=0.764, TAw acc= 75.0% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.967, TAw acc= 67.9% | Valid: time=  0.4s loss=0.764, TAw acc= 74.8% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 68.0% | Valid: time=  0.4s loss=0.763, TAw acc= 75.0% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 68.4% | Valid: time=  0.4s loss=0.763, TAw acc= 74.8% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.015, TAw acc= 66.7% | Valid: time=  0.4s loss=0.764, TAw acc= 74.6% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.979, TAw acc= 67.5% | Valid: time=  0.4s loss=0.763, TAw acc= 74.8% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.000, TAw acc= 66.6% | Valid: time=  0.4s loss=0.762, TAw acc= 74.8% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.003, TAw acc= 67.0% | Valid: time=  0.4s loss=0.764, TAw acc= 75.2% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.000, TAw acc= 66.7% | Valid: time=  0.4s loss=0.765, TAw acc= 74.6% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 67.8% | Valid: time=  0.4s loss=0.766, TAw acc= 74.8% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 67.3% | Valid: time=  0.4s loss=0.766, TAw acc= 75.4% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 67.2% | Valid: time=  0.4s loss=0.764, TAw acc= 75.6% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 67.2% | Valid: time=  0.4s loss=0.764, TAw acc= 75.6% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.987, TAw acc= 67.5% | Valid: time=  0.4s loss=0.763, TAw acc= 75.8% | lr=3.2e-04
| Epoch  91, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.022, TAw acc= 65.7% | Valid: time=  0.4s loss=0.724, TAw acc= 77.2% | *
| Epoch  92, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.027, TAw acc= 65.1% | Valid: time=  0.4s loss=0.725, TAw acc= 77.0% |
| Epoch  93, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.009, TAw acc= 65.4% | Valid: time=  0.4s loss=0.726, TAw acc= 76.8% |
| Epoch  94, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.030, TAw acc= 65.3% | Valid: time=  0.4s loss=0.728, TAw acc= 76.4% |
| Epoch  95, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.031, TAw acc= 65.7% | Valid: time=  0.4s loss=0.730, TAw acc= 76.4% |
| Epoch  96, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.980, TAw acc= 67.2% | Valid: time=  0.4s loss=0.733, TAw acc= 76.6% |
| Epoch  97, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.008, TAw acc= 66.7% | Valid: time=  0.4s loss=0.735, TAw acc= 76.2% |
| Epoch  98, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.001, TAw acc= 66.2% | Valid: time=  0.4s loss=0.737, TAw acc= 76.2% |
| Epoch  99, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=1.002, TAw acc= 66.7% | Valid: time=  0.4s loss=0.739, TAw acc= 76.4% |
| Epoch 100, lr=3.2e-04 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 67.6% | Valid: time=  0.4s loss=0.740, TAw acc= 76.2% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc=  3.0%, forg= 74.3% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 37.3%, forg= 28.1% <<<
>>> Test on task  2 : loss=0.606 | TAw acc= 79.3%, forg=  0.4%| TAg acc= 10.2%, forg= 28.3% <<<
>>> Test on task  3 : loss=0.611 | TAw acc= 80.7%, forg= -0.5%| TAg acc= 18.8%, forg= 21.9% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 37.3%, forg= 14.3% <<<
>>> Test on task  5 : loss=0.797 | TAw acc= 70.2%, forg=  0.2%| TAg acc= 30.7%, forg= 10.5% <<<
>>> Test on task  6 : loss=0.582 | TAw acc= 80.2%, forg=  1.0%| TAg acc= 44.7%, forg=  8.9% <<<
>>> Test on task  7 : loss=0.645 | TAw acc= 77.5%, forg=  0.3%| TAg acc= 20.3%, forg=  2.9% <<<
>>> Test on task  8 : loss=0.682 | TAw acc= 77.0%, forg=  0.0%| TAg acc= 38.7%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
Task  9
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32SOW(
    in_channels=3, in_H=32, in_W=32, training=False, fix_features=True, fix_classifier=False
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): SOW_V3(in_features=1024, out_features=1024, num_tasks=10, dtype=torch.float64, device=cuda:1)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-9): 10 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.0263039750973134
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.236, TAw acc= 57.8% | Valid: time=  0.4s loss=1.074, TAw acc= 62.0% | *
| Epoch   2, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.155, TAw acc= 60.6% | Valid: time=  0.4s loss=0.905, TAw acc= 69.4% | *
| Epoch   3, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.132, TAw acc= 62.5% | Valid: time=  0.4s loss=0.917, TAw acc= 68.0% |
| Epoch   4, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.127, TAw acc= 61.0% | Valid: time=  0.4s loss=0.903, TAw acc= 69.4% | *
| Epoch   5, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.118, TAw acc= 62.1% | Valid: time=  0.4s loss=0.898, TAw acc= 69.4% | *
| Epoch   6, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.081, TAw acc= 62.9% | Valid: time=  0.4s loss=0.900, TAw acc= 68.0% |
| Epoch   7, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.091, TAw acc= 62.6% | Valid: time=  0.4s loss=0.890, TAw acc= 69.2% | *
| Epoch   8, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.080, TAw acc= 62.9% | Valid: time=  0.4s loss=0.886, TAw acc= 70.6% | *
| Epoch   9, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.074, TAw acc= 63.8% | Valid: time=  0.4s loss=0.845, TAw acc= 68.6% | *
| Epoch  10, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.106, TAw acc= 62.4% | Valid: time=  0.4s loss=0.840, TAw acc= 68.6% | *
| Epoch  11, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.097, TAw acc= 63.2% | Valid: time=  0.4s loss=0.795, TAw acc= 71.6% | *
| Epoch  12, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.061, TAw acc= 63.6% | Valid: time=  0.4s loss=0.898, TAw acc= 68.0% |
| Epoch  13, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.035, TAw acc= 64.7% | Valid: time=  0.4s loss=0.867, TAw acc= 69.4% |
| Epoch  14, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.060, TAw acc= 63.7% | Valid: time=  0.4s loss=0.832, TAw acc= 69.8% |
| Epoch  15, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.073, TAw acc= 64.1% | Valid: time=  0.4s loss=0.830, TAw acc= 71.2% |
| Epoch  16, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.028, TAw acc= 64.8% | Valid: time=  0.4s loss=0.866, TAw acc= 69.2% |
| Epoch  17, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.043, TAw acc= 64.1% | Valid: time=  0.4s loss=0.814, TAw acc= 71.6% |
| Epoch  18, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.033, TAw acc= 65.0% | Valid: time=  0.4s loss=0.829, TAw acc= 72.2% |
| Epoch  19, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.041, TAw acc= 64.1% | Valid: time=  0.4s loss=0.800, TAw acc= 71.2% |
| Epoch  20, lr=2.6e-02 time=  3.0s/  1.9s | Train: loss=1.057, TAw acc= 64.2% | Valid: time=  0.4s loss=0.824, TAw acc= 71.0% |
| Epoch  21, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.051, TAw acc= 63.2% | Valid: time=  0.4s loss=0.810, TAw acc= 70.8% |
| Epoch  22, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.053, TAw acc= 64.0% | Valid: time=  0.4s loss=0.859, TAw acc= 70.0% |
| Epoch  23, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.029, TAw acc= 64.8% | Valid: time=  0.4s loss=0.857, TAw acc= 71.0% |
| Epoch  24, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.013, TAw acc= 65.9% | Valid: time=  0.4s loss=0.800, TAw acc= 71.0% |
| Epoch  25, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.068, TAw acc= 65.0% | Valid: time=  0.4s loss=0.806, TAw acc= 69.0% |
| Epoch  26, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.007, TAw acc= 64.9% | Valid: time=  0.4s loss=0.836, TAw acc= 70.4% |
| Epoch  27, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.022, TAw acc= 65.1% | Valid: time=  0.4s loss=0.891, TAw acc= 69.6% |
| Epoch  28, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.029, TAw acc= 64.3% | Valid: time=  0.4s loss=0.886, TAw acc= 68.2% |
| Epoch  29, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.021, TAw acc= 65.6% | Valid: time=  0.4s loss=0.802, TAw acc= 70.0% |
| Epoch  30, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.042, TAw acc= 64.3% | Valid: time=  0.4s loss=0.880, TAw acc= 69.6% |
| Epoch  31, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.028, TAw acc= 66.0% | Valid: time=  0.4s loss=0.775, TAw acc= 71.4% | *
| Epoch  32, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.013, TAw acc= 66.0% | Valid: time=  0.4s loss=0.793, TAw acc= 70.2% |
| Epoch  33, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.008, TAw acc= 65.5% | Valid: time=  0.4s loss=0.829, TAw acc= 70.2% |
| Epoch  34, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.004, TAw acc= 65.6% | Valid: time=  0.4s loss=0.806, TAw acc= 71.0% |
| Epoch  35, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.015, TAw acc= 65.0% | Valid: time=  0.4s loss=0.811, TAw acc= 70.2% |
| Epoch  36, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.036, TAw acc= 65.4% | Valid: time=  0.4s loss=0.817, TAw acc= 69.6% |
| Epoch  37, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.015, TAw acc= 65.5% | Valid: time=  0.4s loss=0.866, TAw acc= 69.2% |
| Epoch  38, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.009, TAw acc= 64.9% | Valid: time=  0.4s loss=0.818, TAw acc= 70.4% |
| Epoch  39, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.006, TAw acc= 65.6% | Valid: time=  0.4s loss=0.889, TAw acc= 70.0% |
| Epoch  40, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.027, TAw acc= 65.0% | Valid: time=  0.4s loss=0.845, TAw acc= 69.6% |
| Epoch  41, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=0.982, TAw acc= 66.9% | Valid: time=  0.4s loss=0.815, TAw acc= 70.4% |
| Epoch  42, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.017, TAw acc= 65.4% | Valid: time=  0.4s loss=0.844, TAw acc= 69.8% |
| Epoch  43, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.983, TAw acc= 67.9% | Valid: time=  0.4s loss=0.809, TAw acc= 69.4% |
| Epoch  44, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.012, TAw acc= 65.6% | Valid: time=  0.4s loss=0.789, TAw acc= 70.2% |
| Epoch  45, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.990, TAw acc= 65.8% | Valid: time=  0.4s loss=0.787, TAw acc= 72.8% |
| Epoch  46, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 65.9% | Valid: time=  0.4s loss=0.880, TAw acc= 68.0% |
| Epoch  47, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.009, TAw acc= 66.2% | Valid: time=  0.4s loss=0.805, TAw acc= 70.0% |
| Epoch  48, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.031, TAw acc= 64.7% | Valid: time=  0.4s loss=0.807, TAw acc= 69.8% |
| Epoch  49, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.023, TAw acc= 65.7% | Valid: time=  0.4s loss=0.814, TAw acc= 70.2% |
| Epoch  50, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.994, TAw acc= 65.4% | Valid: time=  0.4s loss=0.872, TAw acc= 69.6% |
| Epoch  51, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.010, TAw acc= 65.4% | Valid: time=  0.4s loss=0.813, TAw acc= 70.2% |
| Epoch  52, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.981, TAw acc= 66.4% | Valid: time=  0.4s loss=0.804, TAw acc= 70.6% |
| Epoch  53, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.980, TAw acc= 66.6% | Valid: time=  0.4s loss=0.842, TAw acc= 70.8% |
| Epoch  54, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.977, TAw acc= 66.5% | Valid: time=  0.4s loss=0.835, TAw acc= 70.2% |
| Epoch  55, lr=2.6e-02 time=  2.9s/  1.9s | Train: loss=1.010, TAw acc= 65.9% | Valid: time=  0.4s loss=0.817, TAw acc= 70.8% |
| Epoch  56, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 65.7% | Valid: time=  0.4s loss=0.800, TAw acc= 71.4% |
| Epoch  57, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.010, TAw acc= 65.6% | Valid: time=  0.4s loss=0.813, TAw acc= 70.8% |
| Epoch  58, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 66.6% | Valid: time=  0.4s loss=0.826, TAw acc= 71.0% |
| Epoch  59, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=1.003, TAw acc= 66.4% | Valid: time=  0.4s loss=0.793, TAw acc= 70.8% |
| Epoch  60, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.990, TAw acc= 67.0% | Valid: time=  0.4s loss=0.777, TAw acc= 72.0% |
| Epoch  61, lr=2.6e-02 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 66.0% | Valid: time=  0.4s loss=0.855, TAw acc= 70.8% | lr=8.8e-03
| Epoch  62, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.004, TAw acc= 65.7% | Valid: time=  0.4s loss=0.833, TAw acc= 70.0% |
| Epoch  63, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.997, TAw acc= 66.3% | Valid: time=  0.4s loss=0.818, TAw acc= 69.4% |
| Epoch  64, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.014, TAw acc= 66.0% | Valid: time=  0.4s loss=0.822, TAw acc= 70.6% |
| Epoch  65, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.027, TAw acc= 65.0% | Valid: time=  0.4s loss=0.822, TAw acc= 70.6% |
| Epoch  66, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.996, TAw acc= 66.1% | Valid: time=  0.4s loss=0.861, TAw acc= 69.6% |
| Epoch  67, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.016, TAw acc= 65.3% | Valid: time=  0.4s loss=0.809, TAw acc= 70.4% |
| Epoch  68, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.032, TAw acc= 65.2% | Valid: time=  0.4s loss=0.811, TAw acc= 70.2% |
| Epoch  69, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.995, TAw acc= 66.5% | Valid: time=  0.4s loss=0.802, TAw acc= 69.8% |
| Epoch  70, lr=8.8e-03 time=  6.3s/  1.9s | Train: loss=1.008, TAw acc= 65.4% | Valid: time=  0.4s loss=0.875, TAw acc= 68.0% |
| Epoch  71, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.979, TAw acc= 66.6% | Valid: time=  0.4s loss=0.805, TAw acc= 71.8% |
| Epoch  72, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.997, TAw acc= 66.7% | Valid: time=  0.4s loss=0.823, TAw acc= 70.4% |
| Epoch  73, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.983, TAw acc= 66.5% | Valid: time=  0.4s loss=0.812, TAw acc= 69.6% |
| Epoch  74, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.985, TAw acc= 66.8% | Valid: time=  0.4s loss=0.789, TAw acc= 70.6% |
| Epoch  75, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=1.001, TAw acc= 66.7% | Valid: time=  0.4s loss=0.811, TAw acc= 70.4% |
| Epoch  76, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 66.1% | Valid: time=  0.4s loss=0.847, TAw acc= 69.6% |
| Epoch  77, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.028, TAw acc= 65.6% | Valid: time=  0.4s loss=0.772, TAw acc= 70.6% | *
| Epoch  78, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.972, TAw acc= 67.1% | Valid: time=  0.4s loss=0.807, TAw acc= 70.4% |
| Epoch  79, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.980, TAw acc= 66.1% | Valid: time=  0.4s loss=0.787, TAw acc= 71.6% |
| Epoch  80, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.981, TAw acc= 66.5% | Valid: time=  0.4s loss=0.824, TAw acc= 70.4% |
| Epoch  81, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.989, TAw acc= 67.0% | Valid: time=  0.4s loss=0.784, TAw acc= 70.0% |
| Epoch  82, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.987, TAw acc= 66.3% | Valid: time=  0.4s loss=0.838, TAw acc= 69.8% |
| Epoch  83, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.999, TAw acc= 65.3% | Valid: time=  0.4s loss=0.828, TAw acc= 69.8% |
| Epoch  84, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.991, TAw acc= 66.2% | Valid: time=  0.4s loss=0.793, TAw acc= 71.4% |
| Epoch  85, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.996, TAw acc= 66.9% | Valid: time=  0.4s loss=0.812, TAw acc= 70.2% |
| Epoch  86, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.975, TAw acc= 66.0% | Valid: time=  0.4s loss=0.822, TAw acc= 70.6% |
| Epoch  87, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 66.6% | Valid: time=  0.4s loss=0.818, TAw acc= 70.2% |
| Epoch  88, lr=8.8e-03 time=  2.9s/  1.9s | Train: loss=0.977, TAw acc= 66.8% | Valid: time=  0.4s loss=0.816, TAw acc= 71.2% |
| Epoch  89, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.982, TAw acc= 65.9% | Valid: time=  0.4s loss=0.864, TAw acc= 68.8% |
| Epoch  90, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.005, TAw acc= 66.3% | Valid: time=  0.4s loss=0.807, TAw acc= 69.0% |
| Epoch  91, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.005, TAw acc= 66.4% | Valid: time=  0.4s loss=0.809, TAw acc= 69.4% |
| Epoch  92, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.973, TAw acc= 67.4% | Valid: time=  0.4s loss=0.844, TAw acc= 70.2% |
| Epoch  93, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 66.3% | Valid: time=  0.4s loss=0.878, TAw acc= 70.6% |
| Epoch  94, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.992, TAw acc= 66.5% | Valid: time=  0.4s loss=0.805, TAw acc= 69.0% |
| Epoch  95, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=1.010, TAw acc= 65.4% | Valid: time=  0.4s loss=0.854, TAw acc= 69.0% |
| Epoch  96, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.980, TAw acc= 66.6% | Valid: time=  0.4s loss=0.829, TAw acc= 71.0% |
| Epoch  97, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.976, TAw acc= 66.4% | Valid: time=  0.4s loss=0.821, TAw acc= 70.6% |
| Epoch  98, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.980, TAw acc= 66.3% | Valid: time=  0.4s loss=0.807, TAw acc= 70.8% |
| Epoch  99, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.988, TAw acc= 66.5% | Valid: time=  0.4s loss=0.827, TAw acc= 71.4% |
| Epoch 100, lr=8.8e-03 time=  2.8s/  1.9s | Train: loss=0.998, TAw acc= 66.4% | Valid: time=  0.4s loss=0.855, TAw acc= 69.8% |
== Rank Reduction [task:9] ==
best_loss=0.772,  best_acc=0.706
 r=256, loss=0.880, acc=0.706
 loss_margin=0.006, acc_margin=0.004
 r=288, loss=0.864, acc=0.698
 loss_margin=0.006, acc_margin=0.004
 r=320, loss=0.858, acc=0.700
 loss_margin=0.006, acc_margin=0.004
 r=352, loss=0.863, acc=0.706
 loss_margin=0.006, acc_margin=0.004
 r=384, loss=0.851, acc=0.706
 loss_margin=0.006, acc_margin=0.004
 r=416, loss=0.835, acc=0.714
 loss_margin=0.006, acc_margin=0.004
 r=448, loss=0.824, acc=0.716
 loss_margin=0.006, acc_margin=0.004
 r=480, loss=0.816, acc=0.720
 loss_margin=0.006, acc_margin=0.004
 r=512, loss=0.810, acc=0.720
 loss_margin=0.006, acc_margin=0.004
 r=544, loss=0.809, acc=0.722
 loss_margin=0.006, acc_margin=0.004
 r=576, loss=0.796, acc=0.734
 loss_margin=0.006, acc_margin=0.004
 r=608, loss=0.777, acc=0.724
 loss_margin=0.006, acc_margin=0.004
best_r=608, loss=0.777, acc=0.724
== Header Training for Low Rank [task:9] ==
loss=0.777 acc=0.724
Fix_Classifier: Done (training=False, fix_classifier=True)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.008767991699104466
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0

Parameter Group 1
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
| Epoch   1, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.072, TAw acc= 65.5% | Valid: time=  0.4s loss=0.799, TAw acc= 72.4% |
| Epoch   2, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.051, TAw acc= 65.6% | Valid: time=  0.4s loss=0.799, TAw acc= 71.4% |
| Epoch   3, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.031, TAw acc= 66.0% | Valid: time=  0.4s loss=0.783, TAw acc= 72.0% |
| Epoch   4, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.044, TAw acc= 64.8% | Valid: time=  0.4s loss=0.790, TAw acc= 72.8% |
| Epoch   5, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.027, TAw acc= 65.2% | Valid: time=  0.4s loss=0.778, TAw acc= 72.8% |
| Epoch   6, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.027, TAw acc= 66.0% | Valid: time=  0.4s loss=0.783, TAw acc= 72.8% |
| Epoch   7, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.013, TAw acc= 65.8% | Valid: time=  0.4s loss=0.781, TAw acc= 72.8% |
| Epoch   8, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.029, TAw acc= 65.6% | Valid: time=  0.4s loss=0.793, TAw acc= 72.0% |
| Epoch   9, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.018, TAw acc= 64.8% | Valid: time=  0.4s loss=0.789, TAw acc= 72.4% |
| Epoch  10, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.017, TAw acc= 65.4% | Valid: time=  0.4s loss=0.786, TAw acc= 72.4% |
| Epoch  11, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.017, TAw acc= 65.6% | Valid: time=  0.4s loss=0.781, TAw acc= 72.6% |
| Epoch  12, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.2% | Valid: time=  0.4s loss=0.777, TAw acc= 73.0% | *
| Epoch  13, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.5% | Valid: time=  0.4s loss=0.779, TAw acc= 73.2% |
| Epoch  14, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.004, TAw acc= 65.8% | Valid: time=  0.4s loss=0.783, TAw acc= 72.6% |
| Epoch  15, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.003, TAw acc= 65.0% | Valid: time=  0.4s loss=0.780, TAw acc= 72.6% |
| Epoch  16, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.997, TAw acc= 66.4% | Valid: time=  0.4s loss=0.786, TAw acc= 73.0% |
| Epoch  17, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.987, TAw acc= 66.8% | Valid: time=  0.4s loss=0.793, TAw acc= 72.2% |
| Epoch  18, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 66.5% | Valid: time=  0.4s loss=0.780, TAw acc= 72.8% |
| Epoch  19, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=1.004, TAw acc= 65.1% | Valid: time=  0.4s loss=0.791, TAw acc= 72.2% |
| Epoch  20, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.991, TAw acc= 66.6% | Valid: time=  0.4s loss=0.785, TAw acc= 72.2% |
| Epoch  21, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 66.4% | Valid: time=  0.4s loss=0.797, TAw acc= 71.6% |
| Epoch  22, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.979, TAw acc= 67.4% | Valid: time=  0.4s loss=0.779, TAw acc= 72.6% |
| Epoch  23, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.981, TAw acc= 67.2% | Valid: time=  0.4s loss=0.778, TAw acc= 72.4% |
| Epoch  24, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.995, TAw acc= 66.5% | Valid: time=  0.4s loss=0.792, TAw acc= 72.0% |
| Epoch  25, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 66.4% | Valid: time=  0.4s loss=0.785, TAw acc= 72.4% |
| Epoch  26, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 67.2% | Valid: time=  0.4s loss=0.786, TAw acc= 72.6% |
| Epoch  27, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 66.7% | Valid: time=  0.4s loss=0.787, TAw acc= 72.0% |
| Epoch  28, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.975, TAw acc= 67.6% | Valid: time=  0.4s loss=0.791, TAw acc= 72.0% |
| Epoch  29, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.942, TAw acc= 67.9% | Valid: time=  0.4s loss=0.781, TAw acc= 72.4% |
| Epoch  30, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 67.8% | Valid: time=  0.4s loss=0.794, TAw acc= 72.4% |
| Epoch  31, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.959, TAw acc= 67.8% | Valid: time=  0.4s loss=0.782, TAw acc= 73.2% |
| Epoch  32, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.974, TAw acc= 67.9% | Valid: time=  0.4s loss=0.795, TAw acc= 72.6% |
| Epoch  33, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.960, TAw acc= 67.3% | Valid: time=  0.4s loss=0.802, TAw acc= 71.8% |
| Epoch  34, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.962, TAw acc= 67.2% | Valid: time=  0.4s loss=0.805, TAw acc= 71.8% |
| Epoch  35, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.970, TAw acc= 67.7% | Valid: time=  0.4s loss=0.810, TAw acc= 71.4% |
| Epoch  36, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 66.3% | Valid: time=  0.4s loss=0.795, TAw acc= 71.8% |
| Epoch  37, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.950, TAw acc= 67.3% | Valid: time=  0.4s loss=0.796, TAw acc= 72.0% |
| Epoch  38, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.973, TAw acc= 67.6% | Valid: time=  0.4s loss=0.802, TAw acc= 71.4% |
| Epoch  39, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 66.5% | Valid: time=  0.4s loss=0.782, TAw acc= 73.0% |
| Epoch  40, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.947, TAw acc= 68.3% | Valid: time=  0.4s loss=0.795, TAw acc= 72.2% |
| Epoch  41, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.966, TAw acc= 67.2% | Valid: time=  0.4s loss=0.785, TAw acc= 72.8% |
| Epoch  42, lr=8.8e-03 time=  1.7s/  1.9s | Train: loss=0.961, TAw acc= 67.7% | Valid: time=  0.4s loss=0.789, TAw acc= 73.0% | lr=2.9e-03
| Epoch  43, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 66.2% | Valid: time=  0.4s loss=0.774, TAw acc= 73.2% | *
| Epoch  44, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.010, TAw acc= 66.3% | Valid: time=  0.4s loss=0.780, TAw acc= 72.8% |
| Epoch  45, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.004, TAw acc= 65.7% | Valid: time=  0.4s loss=0.778, TAw acc= 73.0% |
| Epoch  46, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 65.7% | Valid: time=  0.4s loss=0.779, TAw acc= 73.0% |
| Epoch  47, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.982, TAw acc= 66.8% | Valid: time=  0.4s loss=0.778, TAw acc= 72.6% |
| Epoch  48, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.3% | Valid: time=  0.4s loss=0.783, TAw acc= 72.8% |
| Epoch  49, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.005, TAw acc= 65.8% | Valid: time=  0.4s loss=0.780, TAw acc= 72.8% |
| Epoch  50, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.1% | Valid: time=  0.4s loss=0.779, TAw acc= 72.8% |
| Epoch  51, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 67.2% | Valid: time=  0.4s loss=0.783, TAw acc= 73.0% |
| Epoch  52, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=1.007, TAw acc= 66.2% | Valid: time=  0.4s loss=0.785, TAw acc= 72.4% |
| Epoch  53, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.7% | Valid: time=  0.4s loss=0.782, TAw acc= 72.6% |
| Epoch  54, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.998, TAw acc= 65.8% | Valid: time=  0.4s loss=0.779, TAw acc= 73.0% |
| Epoch  55, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.4% | Valid: time=  0.4s loss=0.778, TAw acc= 72.8% |
| Epoch  56, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.1% | Valid: time=  0.4s loss=0.777, TAw acc= 72.8% |
| Epoch  57, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.976, TAw acc= 67.6% | Valid: time=  0.4s loss=0.782, TAw acc= 72.8% |
| Epoch  58, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 66.7% | Valid: time=  0.4s loss=0.781, TAw acc= 72.6% |
| Epoch  59, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.7% | Valid: time=  0.4s loss=0.782, TAw acc= 72.8% |
| Epoch  60, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 67.0% | Valid: time=  0.4s loss=0.781, TAw acc= 73.2% |
| Epoch  61, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.0% | Valid: time=  0.4s loss=0.779, TAw acc= 73.0% |
| Epoch  62, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.985, TAw acc= 67.1% | Valid: time=  0.4s loss=0.782, TAw acc= 73.0% |
| Epoch  63, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.980, TAw acc= 67.1% | Valid: time=  0.4s loss=0.780, TAw acc= 73.2% |
| Epoch  64, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 66.4% | Valid: time=  0.4s loss=0.782, TAw acc= 73.4% |
| Epoch  65, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 65.9% | Valid: time=  0.4s loss=0.782, TAw acc= 73.4% |
| Epoch  66, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.987, TAw acc= 67.2% | Valid: time=  0.4s loss=0.782, TAw acc= 73.2% |
| Epoch  67, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 66.3% | Valid: time=  0.4s loss=0.784, TAw acc= 73.2% |
| Epoch  68, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.982, TAw acc= 67.0% | Valid: time=  0.4s loss=0.781, TAw acc= 73.2% |
| Epoch  69, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.972, TAw acc= 67.2% | Valid: time=  0.4s loss=0.782, TAw acc= 73.2% |
| Epoch  70, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.984, TAw acc= 66.3% | Valid: time=  0.4s loss=0.785, TAw acc= 73.0% |
| Epoch  71, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.965, TAw acc= 67.4% | Valid: time=  0.4s loss=0.786, TAw acc= 73.0% |
| Epoch  72, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.990, TAw acc= 66.5% | Valid: time=  0.4s loss=0.785, TAw acc= 72.8% |
| Epoch  73, lr=2.9e-03 time=  1.7s/  1.9s | Train: loss=0.971, TAw acc= 67.6% | Valid: time=  0.4s loss=0.784, TAw acc= 72.6% | lr=9.7e-04
| Epoch  74, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.991, TAw acc= 66.6% | Valid: time=  0.4s loss=0.776, TAw acc= 73.0% |
| Epoch  75, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.991, TAw acc= 66.8% | Valid: time=  0.4s loss=0.776, TAw acc= 73.0% |
| Epoch  76, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.001, TAw acc= 66.0% | Valid: time=  0.4s loss=0.779, TAw acc= 73.0% |
| Epoch  77, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.997, TAw acc= 67.2% | Valid: time=  0.4s loss=0.780, TAw acc= 72.8% |
| Epoch  78, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.006, TAw acc= 65.8% | Valid: time=  0.4s loss=0.780, TAw acc= 73.0% |
| Epoch  79, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.998, TAw acc= 67.0% | Valid: time=  0.4s loss=0.779, TAw acc= 73.0% |
| Epoch  80, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.025, TAw acc= 65.7% | Valid: time=  0.4s loss=0.778, TAw acc= 73.0% |
| Epoch  81, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.019, TAw acc= 65.5% | Valid: time=  0.4s loss=0.777, TAw acc= 73.2% |
| Epoch  82, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 67.0% | Valid: time=  0.4s loss=0.778, TAw acc= 73.2% |
| Epoch  83, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.995, TAw acc= 66.3% | Valid: time=  0.4s loss=0.779, TAw acc= 73.2% |
| Epoch  84, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 66.8% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
| Epoch  85, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.2% | Valid: time=  0.4s loss=0.780, TAw acc= 73.0% |
| Epoch  86, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.995, TAw acc= 66.0% | Valid: time=  0.4s loss=0.782, TAw acc= 73.0% |
| Epoch  87, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.989, TAw acc= 67.6% | Valid: time=  0.4s loss=0.783, TAw acc= 73.0% |
| Epoch  88, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.986, TAw acc= 67.0% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
| Epoch  89, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.982, TAw acc= 67.2% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
| Epoch  90, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 67.5% | Valid: time=  0.4s loss=0.782, TAw acc= 73.0% |
| Epoch  91, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.000, TAw acc= 66.8% | Valid: time=  0.4s loss=0.781, TAw acc= 73.2% |
| Epoch  92, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.994, TAw acc= 66.4% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
| Epoch  93, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.983, TAw acc= 67.3% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
| Epoch  94, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.993, TAw acc= 66.0% | Valid: time=  0.4s loss=0.783, TAw acc= 72.8% |
| Epoch  95, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.988, TAw acc= 67.3% | Valid: time=  0.4s loss=0.784, TAw acc= 72.8% |
| Epoch  96, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.992, TAw acc= 66.0% | Valid: time=  0.4s loss=0.783, TAw acc= 73.0% |
| Epoch  97, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=1.001, TAw acc= 66.2% | Valid: time=  0.4s loss=0.781, TAw acc= 72.8% |
| Epoch  98, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.981, TAw acc= 66.6% | Valid: time=  0.4s loss=0.781, TAw acc= 72.8% |
| Epoch  99, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.999, TAw acc= 66.4% | Valid: time=  0.4s loss=0.779, TAw acc= 72.6% |
| Epoch 100, lr=9.7e-04 time=  1.7s/  1.9s | Train: loss=0.991, TAw acc= 66.6% | Valid: time=  0.4s loss=0.781, TAw acc= 73.0% |
Free_Classifier: Done (training=True, fix_classifier=False)
Header Training: Finised.
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 72.9%, forg=  4.4%| TAg acc=  2.1%, forg= 75.2% <<<
>>> Test on task  1 : loss=0.957 | TAw acc= 69.0%, forg=  0.2%| TAg acc= 36.8%, forg= 28.6% <<<
>>> Test on task  2 : loss=0.605 | TAw acc= 79.3%, forg=  0.4%| TAg acc=  9.1%, forg= 29.4% <<<
>>> Test on task  3 : loss=0.616 | TAw acc= 79.7%, forg=  1.0%| TAg acc= 18.3%, forg= 22.4% <<<
>>> Test on task  4 : loss=0.516 | TAw acc= 83.6%, forg=  0.0%| TAg acc= 35.0%, forg= 16.6% <<<
>>> Test on task  5 : loss=0.791 | TAw acc= 69.8%, forg=  0.6%| TAg acc= 28.8%, forg= 12.4% <<<
>>> Test on task  6 : loss=0.577 | TAw acc= 80.7%, forg=  0.5%| TAg acc= 42.6%, forg= 11.0% <<<
>>> Test on task  7 : loss=0.643 | TAw acc= 77.2%, forg=  0.6%| TAg acc= 20.2%, forg=  3.0% <<<
>>> Test on task  8 : loss=0.685 | TAw acc= 76.5%, forg=  0.5%| TAg acc= 37.1%, forg=  1.6% <<<
>>> Test on task  9 : loss=0.852 | TAw acc= 71.5%, forg=  0.0%| TAg acc= 33.7%, forg=  0.0% <<<
Save at ../RESULT_AAAI2025/CR10/0/cifar100_sow
************************************************************************************************************
TAw Acc
	 77.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 77.3% 
	 72.0%  69.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 70.6% 
	 72.9%  69.0%  79.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 73.9% 
	 72.9%  69.0%  78.9%  79.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 75.2% 
	 72.9%  69.0%  78.7%  79.5%  83.6%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 76.7% 
	 72.9%  69.0%  78.9%  79.0%  83.6%  69.9%   0.0%   0.0%   0.0%   0.0% 	Avg.: 75.6% 
	 72.9%  69.0%  78.7%  80.0%  83.6%  69.6%  80.1%   0.0%   0.0%   0.0% 	Avg.: 76.3% 
	 72.9%  69.0%  78.8%  80.2%  83.6%  70.4%  81.2%  77.8%   0.0%   0.0% 	Avg.: 76.7% 
	 72.9%  69.0%  79.3%  80.7%  83.6%  70.2%  80.2%  77.5%  77.0%   0.0% 	Avg.: 76.7% 
	 72.9%  69.0%  79.3%  79.7%  83.6%  69.8%  80.7%  77.2%  76.5%  71.5% 	Avg.: 76.0% 
************************************************************************************************************
TAg Acc
	 77.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 77.3% 
	 32.0%  65.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 48.7% 
	 24.1%  60.6%  38.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 41.1% 
	 15.9%  52.3%  27.8%  40.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 34.2% 
	 10.1%  48.2%  23.8%  35.0%  51.6%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 33.7% 
	  7.1%  45.8%  17.3%  29.1%  44.6%  41.2%   0.0%   0.0%   0.0%   0.0% 	Avg.: 30.8% 
	  5.6%  41.5%  12.4%  21.8%  42.0%  32.9%  53.6%   0.0%   0.0%   0.0% 	Avg.: 30.0% 
	  4.1%  38.6%  11.4%  20.3%  39.8%  31.3%  51.2%  23.2%   0.0%   0.0% 	Avg.: 27.5% 
	  3.0%  37.3%  10.2%  18.8%  37.3%  30.7%  44.7%  20.3%  38.7%   0.0% 	Avg.: 26.8% 
	  2.1%  36.8%   9.1%  18.3%  35.0%  28.8%  42.6%  20.2%  37.1%  33.7% 	Avg.: 26.4% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	  5.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  5.3% 
	  4.4%   0.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  2.3% 
	  4.4%   0.2%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.8% 
	  4.4%   0.2%   1.0%   0.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.5% 
	  4.4%   0.2%   0.8%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.2% 
	  4.4%   0.2%   1.0%  -0.2%   0.0%   0.3%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.0% 
	  4.4%   0.2%   0.9%  -0.2%   0.0%  -0.5%  -1.1%   0.0%   0.0%   0.0% 	Avg.:  0.5% 
	  4.4%   0.2%   0.4%  -0.5%   0.0%   0.2%   1.0%   0.3%   0.0%   0.0% 	Avg.:  0.8% 
	  4.4%   0.2%   0.4%   1.0%   0.0%   0.6%   0.5%   0.6%   0.5%   0.0% 	Avg.:  0.9% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	 45.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 45.3% 
	 53.2%   4.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 29.0% 
	 61.4%  13.1%  10.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 28.4% 
	 67.2%  17.2%  14.7%   5.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 26.2% 
	 70.2%  19.6%  21.2%  11.6%   7.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 25.9% 
	 71.7%  23.9%  26.1%  18.9%   9.6%   8.3%   0.0%   0.0%   0.0%   0.0% 	Avg.: 26.4% 
	 73.2%  26.8%  27.1%  20.4%  11.8%   9.9%   2.4%   0.0%   0.0%   0.0% 	Avg.: 24.5% 
	 74.3%  28.1%  28.3%  21.9%  14.3%  10.5%   8.9%   2.9%   0.0%   0.0% 	Avg.: 23.6% 
	 75.2%  28.6%  29.4%  22.4%  16.6%  12.4%  11.0%   3.0%   1.6%   0.0% 	Avg.: 22.2% 
************************************************************************************************************
>> Task 0, SOW-0: Rank = 320 (736)
>> Task 1, SOW-0: Rank = 384 (736)
>> Task 2, SOW-0: Rank = 640 (736)
>> Task 3, SOW-0: Rank = 608 (736)
>> Task 4, SOW-0: Rank = 448 (736)
>> Task 5, SOW-0: Rank = 640 (736)
>> Task 6, SOW-0: Rank = 672 (736)
>> Task 7, SOW-0: Rank = 704 (736)
>> Task 8, SOW-0: Rank = 736 (736)
>> Task 9, SOW-0: Rank = 608 (736)
************************************************************************************************************
[Elapsed time = 2.6 h]
Done!
