============================================================================================================
Arguments =
	approach: finetuning
	batch_size: 64
	clipping: 1.0
	datasets: ['cifar100']
	eval_on_train: True
	exp_name: None
	fix_bn: True
	gpu: 0
	gridsearch_tasks: -1
	keep_existing_head: False
	last_layer_analysis: False
	log: ['disk']
	lr: 0.0263039750973134
	lr_factor: 3.0
	lr_first: None
	lr_min: 1e-05
	lr_patience: 30
	momentum: 0.9
	multi_softmax: True
	nc_first_task: None
	nepochs: 200
	network: resnet50_32
	no_cudnn_deterministic: False
	num_tasks: 1
	num_workers: 4
	pin_memory: True
	pretrained: False
	results_path: ../RESULT_AAAI2026/CR1/0
	save_models: True
	seed: 0
	stop_at_task: 0
	validation: 0.1
	warmup_lr_factor: 1.0
	warmup_nepochs: 0
	weight_decay: 0.0
============================================================================================================
	device: cuda:0
============================================================================================================
Network arguments =
	dropout: 0.417598542370663
	fix_features: True
	load_features: True
	pretrained_path: ../Conv-Model/ResNet50-TinyImageNet.pt
============================================================================================================
ResNet50_32.__init__: features is loadded (../Conv-Model/ResNet50-TinyImageNet.pt)
Fix_Features: Done
Approach arguments =
	all_outputs: False
============================================================================================================
Exemplars dataset arguments =
	exemplar_selection: random
	num_exemplars: 0
	num_exemplars_per_class: 0
============================================================================================================
class_indices: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
[(0, 100)]
************************************************************************************************************
Task  0
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1024, out_features=100, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  6.6s/  7.7s | Train: loss=3.215, TAw acc= 22.6% | Valid: time=  1.1s loss=2.678, TAw acc= 29.7% | *
| Epoch   2, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=3.045, TAw acc= 25.8% | Valid: time=  1.1s loss=2.560, TAw acc= 33.8% | *
| Epoch   3, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.955, TAw acc= 27.2% | Valid: time=  1.1s loss=2.468, TAw acc= 36.7% | *
| Epoch   4, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.903, TAw acc= 28.4% | Valid: time=  1.1s loss=2.405, TAw acc= 38.3% | *
| Epoch   5, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.862, TAw acc= 29.6% | Valid: time=  1.1s loss=2.414, TAw acc= 38.4% |
| Epoch   6, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.832, TAw acc= 29.8% | Valid: time=  1.1s loss=2.322, TAw acc= 39.8% | *
| Epoch   7, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.800, TAw acc= 30.8% | Valid: time=  1.1s loss=2.340, TAw acc= 39.8% |
| Epoch   8, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.780, TAw acc= 31.1% | Valid: time=  1.1s loss=2.291, TAw acc= 40.8% | *
| Epoch   9, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.756, TAw acc= 31.4% | Valid: time=  1.1s loss=2.287, TAw acc= 41.0% | *
| Epoch  10, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.737, TAw acc= 32.4% | Valid: time=  1.1s loss=2.262, TAw acc= 41.8% | *
| Epoch  11, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.725, TAw acc= 32.3% | Valid: time=  1.1s loss=2.224, TAw acc= 42.0% | *
| Epoch  12, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.699, TAw acc= 32.7% | Valid: time=  1.1s loss=2.244, TAw acc= 42.1% |
| Epoch  13, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.675, TAw acc= 33.3% | Valid: time=  1.1s loss=2.214, TAw acc= 43.0% | *
| Epoch  14, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.675, TAw acc= 33.0% | Valid: time=  1.1s loss=2.211, TAw acc= 42.8% | *
| Epoch  15, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.656, TAw acc= 33.7% | Valid: time=  1.3s loss=2.227, TAw acc= 43.1% |
| Epoch  16, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.654, TAw acc= 33.4% | Valid: time=  1.1s loss=2.165, TAw acc= 43.6% | *
| Epoch  17, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.645, TAw acc= 34.1% | Valid: time=  1.1s loss=2.176, TAw acc= 44.1% |
| Epoch  18, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.642, TAw acc= 34.0% | Valid: time=  1.1s loss=2.209, TAw acc= 42.4% |
| Epoch  19, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.631, TAw acc= 34.4% | Valid: time=  1.1s loss=2.158, TAw acc= 44.5% | *
| Epoch  20, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.603, TAw acc= 34.9% | Valid: time=  1.1s loss=2.188, TAw acc= 44.0% |
| Epoch  21, lr=2.6e-02 time=  5.9s/  7.7s | Train: loss=2.620, TAw acc= 34.6% | Valid: time=  1.2s loss=2.187, TAw acc= 43.5% |
| Epoch  22, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.602, TAw acc= 34.5% | Valid: time=  1.1s loss=2.162, TAw acc= 44.0% |
| Epoch  23, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.596, TAw acc= 34.9% | Valid: time=  1.1s loss=2.166, TAw acc= 44.1% |
| Epoch  24, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.590, TAw acc= 35.1% | Valid: time=  1.2s loss=2.178, TAw acc= 43.9% |
| Epoch  25, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.580, TAw acc= 35.5% | Valid: time=  1.1s loss=2.209, TAw acc= 43.7% |
| Epoch  26, lr=2.6e-02 time=  5.9s/  7.8s | Train: loss=2.562, TAw acc= 35.8% | Valid: time=  1.1s loss=2.180, TAw acc= 44.0% |
| Epoch  27, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.559, TAw acc= 36.1% | Valid: time=  1.1s loss=2.243, TAw acc= 43.2% |
| Epoch  28, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.561, TAw acc= 35.9% | Valid: time=  1.1s loss=2.204, TAw acc= 43.5% |
| Epoch  29, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.555, TAw acc= 35.9% | Valid: time=  1.1s loss=2.157, TAw acc= 44.3% | *
| Epoch  30, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.544, TAw acc= 36.4% | Valid: time=  1.1s loss=2.197, TAw acc= 43.7% |
| Epoch  31, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.549, TAw acc= 36.4% | Valid: time=  1.3s loss=2.138, TAw acc= 44.4% | *
| Epoch  32, lr=2.6e-02 time=  5.8s/  7.9s | Train: loss=2.547, TAw acc= 36.4% | Valid: time=  1.1s loss=2.139, TAw acc= 44.8% |
| Epoch  33, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.528, TAw acc= 36.5% | Valid: time=  1.1s loss=2.152, TAw acc= 44.7% |
| Epoch  34, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.517, TAw acc= 37.0% | Valid: time=  1.1s loss=2.150, TAw acc= 44.4% |
| Epoch  35, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.524, TAw acc= 36.7% | Valid: time=  1.1s loss=2.195, TAw acc= 43.8% |
| Epoch  36, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.537, TAw acc= 36.5% | Valid: time=  1.1s loss=2.123, TAw acc= 43.9% | *
| Epoch  37, lr=2.6e-02 time=  5.6s/  7.7s | Train: loss=2.512, TAw acc= 36.7% | Valid: time=  1.1s loss=2.145, TAw acc= 44.9% |
| Epoch  38, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.530, TAw acc= 36.5% | Valid: time=  1.1s loss=2.166, TAw acc= 44.7% |
| Epoch  39, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.508, TAw acc= 36.8% | Valid: time=  1.1s loss=2.131, TAw acc= 44.6% |
| Epoch  40, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.498, TAw acc= 37.3% | Valid: time=  1.1s loss=2.135, TAw acc= 45.3% |
| Epoch  41, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.496, TAw acc= 37.7% | Valid: time=  1.1s loss=2.140, TAw acc= 44.4% |
| Epoch  42, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.495, TAw acc= 37.7% | Valid: time=  1.1s loss=2.148, TAw acc= 44.5% |
| Epoch  43, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.477, TAw acc= 37.9% | Valid: time=  1.1s loss=2.135, TAw acc= 45.1% |
| Epoch  44, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.476, TAw acc= 37.7% | Valid: time=  1.1s loss=2.172, TAw acc= 44.2% |
| Epoch  45, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.496, TAw acc= 37.3% | Valid: time=  1.2s loss=2.161, TAw acc= 44.6% |
| Epoch  46, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.490, TAw acc= 37.4% | Valid: time=  1.1s loss=2.168, TAw acc= 45.1% |
| Epoch  47, lr=2.6e-02 time=  5.9s/  7.7s | Train: loss=2.477, TAw acc= 37.4% | Valid: time=  1.1s loss=2.129, TAw acc= 45.6% |
| Epoch  48, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.471, TAw acc= 37.8% | Valid: time=  1.1s loss=2.125, TAw acc= 45.5% |
| Epoch  49, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.477, TAw acc= 37.4% | Valid: time=  1.1s loss=2.155, TAw acc= 45.0% |
| Epoch  50, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.474, TAw acc= 38.4% | Valid: time=  1.1s loss=2.124, TAw acc= 44.9% |
| Epoch  51, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.464, TAw acc= 38.4% | Valid: time=  1.1s loss=2.157, TAw acc= 44.5% |
| Epoch  52, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.446, TAw acc= 38.1% | Valid: time=  1.1s loss=2.189, TAw acc= 44.4% |
| Epoch  53, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.451, TAw acc= 38.4% | Valid: time=  1.1s loss=2.131, TAw acc= 45.3% |
| Epoch  54, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.452, TAw acc= 38.2% | Valid: time=  1.1s loss=2.149, TAw acc= 45.1% |
| Epoch  55, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.449, TAw acc= 38.4% | Valid: time=  1.1s loss=2.140, TAw acc= 44.9% |
| Epoch  56, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.452, TAw acc= 38.2% | Valid: time=  1.1s loss=2.164, TAw acc= 44.7% |
| Epoch  57, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.451, TAw acc= 38.3% | Valid: time=  1.1s loss=2.159, TAw acc= 44.1% |
| Epoch  58, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.446, TAw acc= 38.9% | Valid: time=  1.1s loss=2.161, TAw acc= 44.0% |
| Epoch  59, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.439, TAw acc= 38.7% | Valid: time=  1.1s loss=2.130, TAw acc= 44.9% |
| Epoch  60, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.451, TAw acc= 38.1% | Valid: time=  1.1s loss=2.107, TAw acc= 45.5% | *
| Epoch  61, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.437, TAw acc= 38.8% | Valid: time=  1.1s loss=2.119, TAw acc= 45.5% |
| Epoch  62, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.449, TAw acc= 38.5% | Valid: time=  1.1s loss=2.127, TAw acc= 45.4% |
| Epoch  63, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.435, TAw acc= 38.5% | Valid: time=  1.1s loss=2.111, TAw acc= 45.5% |
| Epoch  64, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.441, TAw acc= 38.7% | Valid: time=  1.1s loss=2.160, TAw acc= 45.0% |
| Epoch  65, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.436, TAw acc= 38.9% | Valid: time=  1.1s loss=2.152, TAw acc= 46.2% |
| Epoch  66, lr=2.6e-02 time=  5.9s/  7.7s | Train: loss=2.427, TAw acc= 39.0% | Valid: time=  1.1s loss=2.158, TAw acc= 45.4% |
| Epoch  67, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.416, TAw acc= 38.7% | Valid: time=  1.1s loss=2.164, TAw acc= 44.9% |
| Epoch  68, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.416, TAw acc= 39.1% | Valid: time=  1.1s loss=2.154, TAw acc= 45.1% |
| Epoch  69, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.428, TAw acc= 38.6% | Valid: time=  1.1s loss=2.174, TAw acc= 44.8% |
| Epoch  70, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.424, TAw acc= 38.7% | Valid: time=  1.2s loss=2.128, TAw acc= 45.6% |
| Epoch  71, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.419, TAw acc= 39.0% | Valid: time=  1.1s loss=2.136, TAw acc= 45.8% |
| Epoch  72, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.405, TAw acc= 39.6% | Valid: time=  1.1s loss=2.171, TAw acc= 45.3% |
| Epoch  73, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.404, TAw acc= 39.8% | Valid: time=  1.2s loss=2.127, TAw acc= 45.8% |
| Epoch  74, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.398, TAw acc= 39.5% | Valid: time=  1.1s loss=2.158, TAw acc= 44.9% |
| Epoch  75, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.412, TAw acc= 39.0% | Valid: time=  1.1s loss=2.136, TAw acc= 45.3% |
| Epoch  76, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.396, TAw acc= 39.7% | Valid: time=  1.1s loss=2.138, TAw acc= 45.6% |
| Epoch  77, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.409, TAw acc= 39.5% | Valid: time=  1.1s loss=2.133, TAw acc= 45.7% |
| Epoch  78, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.389, TAw acc= 40.0% | Valid: time=  1.1s loss=2.160, TAw acc= 44.9% |
| Epoch  79, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.379, TAw acc= 39.8% | Valid: time=  1.1s loss=2.152, TAw acc= 44.7% |
| Epoch  80, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.382, TAw acc= 39.4% | Valid: time=  1.1s loss=2.147, TAw acc= 45.2% |
| Epoch  81, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.388, TAw acc= 39.7% | Valid: time=  1.1s loss=2.178, TAw acc= 44.8% |
| Epoch  82, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.391, TAw acc= 39.7% | Valid: time=  1.1s loss=2.171, TAw acc= 45.1% |
| Epoch  83, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.381, TAw acc= 40.1% | Valid: time=  1.1s loss=2.143, TAw acc= 45.2% |
| Epoch  84, lr=2.6e-02 time=  6.0s/  7.8s | Train: loss=2.385, TAw acc= 40.0% | Valid: time=  1.1s loss=2.149, TAw acc= 45.3% |
| Epoch  85, lr=2.6e-02 time=  5.8s/  7.8s | Train: loss=2.388, TAw acc= 39.6% | Valid: time=  1.1s loss=2.164, TAw acc= 44.6% |
| Epoch  86, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.373, TAw acc= 40.4% | Valid: time=  1.1s loss=2.126, TAw acc= 45.9% |
| Epoch  87, lr=2.6e-02 time=  5.7s/  7.8s | Train: loss=2.382, TAw acc= 40.1% | Valid: time=  1.1s loss=2.187, TAw acc= 44.7% |
| Epoch  88, lr=2.6e-02 time=  5.7s/  7.7s | Train: loss=2.369, TAw acc= 40.0% | Valid: time=  1.1s loss=2.182, TAw acc= 45.1% |
| Epoch  89, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.374, TAw acc= 40.0% | Valid: time=  1.1s loss=2.145, TAw acc= 45.5% |
| Epoch  90, lr=2.6e-02 time=  5.8s/  7.7s | Train: loss=2.368, TAw acc= 39.9% | Valid: time=  1.1s loss=2.188, TAw acc= 45.9% | lr=8.8e-03
| Epoch  91, lr=8.8e-03 time=  5.8s/  7.9s | Train: loss=2.390, TAw acc= 40.1% | Valid: time=  1.1s loss=2.094, TAw acc= 46.0% | *
| Epoch  92, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.373, TAw acc= 40.2% | Valid: time=  1.1s loss=2.123, TAw acc= 46.0% |
| Epoch  93, lr=8.8e-03 time=  5.7s/  7.9s | Train: loss=2.371, TAw acc= 40.3% | Valid: time=  1.1s loss=2.077, TAw acc= 46.7% | *
| Epoch  94, lr=8.8e-03 time=  5.8s/  7.9s | Train: loss=2.354, TAw acc= 41.0% | Valid: time=  1.1s loss=2.081, TAw acc= 46.5% |
| Epoch  95, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.360, TAw acc= 40.7% | Valid: time=  1.2s loss=2.076, TAw acc= 46.6% | *
| Epoch  96, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.348, TAw acc= 40.9% | Valid: time=  1.1s loss=2.108, TAw acc= 45.8% |
| Epoch  97, lr=8.8e-03 time=  6.0s/  7.7s | Train: loss=2.360, TAw acc= 40.7% | Valid: time=  1.1s loss=2.098, TAw acc= 46.0% |
| Epoch  98, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.346, TAw acc= 41.2% | Valid: time=  1.1s loss=2.102, TAw acc= 46.1% |
| Epoch  99, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.346, TAw acc= 40.8% | Valid: time=  1.1s loss=2.088, TAw acc= 46.5% |
| Epoch 100, lr=8.8e-03 time=  5.7s/  7.9s | Train: loss=2.338, TAw acc= 41.0% | Valid: time=  1.2s loss=2.077, TAw acc= 46.6% |
| Epoch 101, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.350, TAw acc= 41.3% | Valid: time=  1.1s loss=2.095, TAw acc= 46.3% |
| Epoch 102, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.344, TAw acc= 40.8% | Valid: time=  1.1s loss=2.088, TAw acc= 46.4% |
| Epoch 103, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.345, TAw acc= 40.9% | Valid: time=  1.1s loss=2.101, TAw acc= 46.3% |
| Epoch 104, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.337, TAw acc= 41.1% | Valid: time=  1.1s loss=2.081, TAw acc= 46.7% |
| Epoch 105, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.335, TAw acc= 41.1% | Valid: time=  1.1s loss=2.091, TAw acc= 46.9% |
| Epoch 106, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.324, TAw acc= 41.5% | Valid: time=  1.1s loss=2.065, TAw acc= 46.5% | *
| Epoch 107, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.336, TAw acc= 41.2% | Valid: time=  1.1s loss=2.071, TAw acc= 46.8% |
| Epoch 108, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.318, TAw acc= 41.6% | Valid: time=  1.1s loss=2.067, TAw acc= 46.7% |
| Epoch 109, lr=8.8e-03 time=  5.7s/  7.6s | Train: loss=2.326, TAw acc= 41.6% | Valid: time=  1.1s loss=2.089, TAw acc= 46.5% |
| Epoch 110, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.321, TAw acc= 41.3% | Valid: time=  1.1s loss=2.079, TAw acc= 46.6% |
| Epoch 111, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.320, TAw acc= 41.2% | Valid: time=  1.1s loss=2.096, TAw acc= 46.4% |
| Epoch 112, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.309, TAw acc= 41.5% | Valid: time=  1.1s loss=2.116, TAw acc= 46.5% |
| Epoch 113, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.323, TAw acc= 41.4% | Valid: time=  1.1s loss=2.099, TAw acc= 46.3% |
| Epoch 114, lr=8.8e-03 time=  5.7s/  7.6s | Train: loss=2.316, TAw acc= 41.5% | Valid: time=  1.1s loss=2.073, TAw acc= 46.5% |
| Epoch 115, lr=8.8e-03 time=  5.7s/  7.9s | Train: loss=2.316, TAw acc= 41.7% | Valid: time=  1.1s loss=2.082, TAw acc= 46.4% |
| Epoch 116, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.314, TAw acc= 41.7% | Valid: time=  1.1s loss=2.078, TAw acc= 46.7% |
| Epoch 117, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.319, TAw acc= 41.5% | Valid: time=  1.1s loss=2.035, TAw acc= 47.2% | *
| Epoch 118, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.317, TAw acc= 41.6% | Valid: time=  1.1s loss=2.085, TAw acc= 46.4% |
| Epoch 119, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.310, TAw acc= 41.5% | Valid: time=  1.1s loss=2.067, TAw acc= 46.8% |
| Epoch 120, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.312, TAw acc= 41.3% | Valid: time=  1.1s loss=2.087, TAw acc= 45.6% |
| Epoch 121, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.313, TAw acc= 41.5% | Valid: time=  1.1s loss=2.082, TAw acc= 46.6% |
| Epoch 122, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.301, TAw acc= 41.7% | Valid: time=  1.1s loss=2.105, TAw acc= 46.3% |
| Epoch 123, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.294, TAw acc= 42.0% | Valid: time=  1.1s loss=2.080, TAw acc= 46.6% |
| Epoch 124, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.305, TAw acc= 41.8% | Valid: time=  1.1s loss=2.083, TAw acc= 46.9% |
| Epoch 125, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.294, TAw acc= 42.0% | Valid: time=  1.1s loss=2.094, TAw acc= 46.7% |
| Epoch 126, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.308, TAw acc= 41.7% | Valid: time=  1.1s loss=2.091, TAw acc= 46.7% |
| Epoch 127, lr=8.8e-03 time=  5.9s/  7.7s | Train: loss=2.307, TAw acc= 42.0% | Valid: time=  1.1s loss=2.071, TAw acc= 46.6% |
| Epoch 128, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.303, TAw acc= 41.6% | Valid: time=  1.1s loss=2.076, TAw acc= 46.8% |
| Epoch 129, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.315, TAw acc= 41.3% | Valid: time=  1.1s loss=2.076, TAw acc= 47.2% |
| Epoch 130, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.300, TAw acc= 41.7% | Valid: time=  1.1s loss=2.083, TAw acc= 46.8% |
| Epoch 131, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.295, TAw acc= 42.1% | Valid: time=  1.1s loss=2.074, TAw acc= 46.9% |
| Epoch 132, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.298, TAw acc= 41.8% | Valid: time=  1.1s loss=2.080, TAw acc= 46.9% |
| Epoch 133, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.298, TAw acc= 41.6% | Valid: time=  1.2s loss=2.096, TAw acc= 46.3% |
| Epoch 134, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.299, TAw acc= 41.5% | Valid: time=  1.1s loss=2.073, TAw acc= 46.9% |
| Epoch 135, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.289, TAw acc= 42.0% | Valid: time=  1.1s loss=2.103, TAw acc= 46.3% |
| Epoch 136, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.286, TAw acc= 42.2% | Valid: time=  1.1s loss=2.078, TAw acc= 46.5% |
| Epoch 137, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.291, TAw acc= 42.3% | Valid: time=  1.1s loss=2.080, TAw acc= 46.6% |
| Epoch 138, lr=8.8e-03 time=  5.8s/  7.8s | Train: loss=2.286, TAw acc= 42.3% | Valid: time=  1.1s loss=2.080, TAw acc= 46.2% |
| Epoch 139, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.295, TAw acc= 42.3% | Valid: time=  1.1s loss=2.091, TAw acc= 46.7% |
| Epoch 140, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.297, TAw acc= 42.1% | Valid: time=  1.1s loss=2.081, TAw acc= 46.7% |
| Epoch 141, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.291, TAw acc= 41.9% | Valid: time=  1.1s loss=2.097, TAw acc= 46.8% |
| Epoch 142, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.287, TAw acc= 42.3% | Valid: time=  1.2s loss=2.119, TAw acc= 46.0% |
| Epoch 143, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.289, TAw acc= 42.3% | Valid: time=  1.1s loss=2.094, TAw acc= 46.2% |
| Epoch 144, lr=8.8e-03 time=  5.7s/  7.7s | Train: loss=2.288, TAw acc= 42.2% | Valid: time=  1.1s loss=2.089, TAw acc= 46.6% |
| Epoch 145, lr=8.8e-03 time=  5.8s/  7.7s | Train: loss=2.283, TAw acc= 42.5% | Valid: time=  1.1s loss=2.084, TAw acc= 46.1% |
| Epoch 146, lr=8.8e-03 time=  5.9s/  7.7s | Train: loss=2.281, TAw acc= 42.5% | Valid: time=  1.1s loss=2.097, TAw acc= 46.4% |
| Epoch 147, lr=8.8e-03 time=  5.7s/  7.8s | Train: loss=2.289, TAw acc= 41.9% | Valid: time=  1.1s loss=2.093, TAw acc= 46.1% | lr=2.9e-03
| Epoch 148, lr=2.9e-03 time=  5.9s/  7.9s | Train: loss=2.302, TAw acc= 41.8% | Valid: time=  1.1s loss=2.073, TAw acc= 46.6% |
| Epoch 149, lr=2.9e-03 time=  6.1s/  8.0s | Train: loss=2.297, TAw acc= 42.0% | Valid: time=  1.1s loss=2.073, TAw acc= 46.8% |
| Epoch 150, lr=2.9e-03 time=  6.0s/  8.0s | Train: loss=2.290, TAw acc= 42.3% | Valid: time=  1.1s loss=2.062, TAw acc= 47.3% |
| Epoch 151, lr=2.9e-03 time=  5.8s/  7.9s | Train: loss=2.289, TAw acc= 42.1% | Valid: time=  1.1s loss=2.062, TAw acc= 47.2% |
| Epoch 152, lr=2.9e-03 time=  5.9s/  7.8s | Train: loss=2.292, TAw acc= 42.2% | Valid: time=  1.1s loss=2.070, TAw acc= 47.0% |
| Epoch 153, lr=2.9e-03 time=  5.9s/  7.8s | Train: loss=2.290, TAw acc= 42.1% | Valid: time=  1.2s loss=2.066, TAw acc= 47.4% |
| Epoch 154, lr=2.9e-03 time=  5.9s/  7.9s | Train: loss=2.286, TAw acc= 42.1% | Valid: time=  1.2s loss=2.065, TAw acc= 47.2% |
| Epoch 155, lr=2.9e-03 time=  6.1s/  7.8s | Train: loss=2.294, TAw acc= 42.0% | Valid: time=  1.1s loss=2.066, TAw acc= 47.2% |
| Epoch 156, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.300, TAw acc= 42.1% | Valid: time=  1.1s loss=2.067, TAw acc= 47.1% |
| Epoch 157, lr=2.9e-03 time=  5.8s/  7.7s | Train: loss=2.282, TAw acc= 42.4% | Valid: time=  1.1s loss=2.067, TAw acc= 46.6% |
| Epoch 158, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.288, TAw acc= 42.0% | Valid: time=  1.1s loss=2.068, TAw acc= 46.6% |
| Epoch 159, lr=2.9e-03 time=  5.8s/  7.7s | Train: loss=2.286, TAw acc= 42.1% | Valid: time=  1.1s loss=2.057, TAw acc= 46.9% |
| Epoch 160, lr=2.9e-03 time=  5.8s/  7.8s | Train: loss=2.287, TAw acc= 42.1% | Valid: time=  1.3s loss=2.065, TAw acc= 47.3% |
| Epoch 161, lr=2.9e-03 time=  5.7s/  7.7s | Train: loss=2.280, TAw acc= 42.2% | Valid: time=  1.1s loss=2.059, TAw acc= 47.4% |
| Epoch 162, lr=2.9e-03 time=  5.8s/  7.7s | Train: loss=2.288, TAw acc= 42.1% | Valid: time=  1.1s loss=2.072, TAw acc= 46.6% |
| Epoch 163, lr=2.9e-03 time=  5.9s/  7.7s | Train: loss=2.284, TAw acc= 42.4% | Valid: time=  1.1s loss=2.050, TAw acc= 47.0% |
| Epoch 164, lr=2.9e-03 time=  5.8s/  7.8s | Train: loss=2.282, TAw acc= 42.3% | Valid: time=  1.1s loss=2.063, TAw acc= 46.9% |
| Epoch 165, lr=2.9e-03 time=  5.8s/  7.8s | Train: loss=2.284, TAw acc= 42.5% | Valid: time=  1.1s loss=2.055, TAw acc= 47.3% |
| Epoch 166, lr=2.9e-03 time=  5.8s/  7.8s | Train: loss=2.282, TAw acc= 42.6% | Valid: time=  1.3s loss=2.056, TAw acc= 46.8% |
| Epoch 167, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.278, TAw acc= 42.4% | Valid: time=  1.1s loss=2.060, TAw acc= 46.9% |
| Epoch 168, lr=2.9e-03 time=  5.8s/  7.9s | Train: loss=2.280, TAw acc= 42.4% | Valid: time=  1.1s loss=2.069, TAw acc= 46.9% |
| Epoch 169, lr=2.9e-03 time=  5.8s/  7.9s | Train: loss=2.270, TAw acc= 42.7% | Valid: time=  1.1s loss=2.063, TAw acc= 46.9% |
| Epoch 170, lr=2.9e-03 time=  5.7s/  7.7s | Train: loss=2.274, TAw acc= 42.3% | Valid: time=  1.3s loss=2.052, TAw acc= 47.7% |
| Epoch 171, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.283, TAw acc= 42.6% | Valid: time=  1.1s loss=2.063, TAw acc= 46.9% |
| Epoch 172, lr=2.9e-03 time=  5.8s/  7.8s | Train: loss=2.278, TAw acc= 42.6% | Valid: time=  1.1s loss=2.055, TAw acc= 46.8% |
| Epoch 173, lr=2.9e-03 time=  5.7s/  7.7s | Train: loss=2.288, TAw acc= 42.2% | Valid: time=  1.2s loss=2.060, TAw acc= 47.2% |
| Epoch 174, lr=2.9e-03 time=  5.9s/  7.8s | Train: loss=2.276, TAw acc= 42.6% | Valid: time=  1.1s loss=2.058, TAw acc= 46.9% |
| Epoch 175, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.274, TAw acc= 42.8% | Valid: time=  1.1s loss=2.062, TAw acc= 46.9% |
| Epoch 176, lr=2.9e-03 time=  5.7s/  7.8s | Train: loss=2.287, TAw acc= 41.8% | Valid: time=  1.1s loss=2.059, TAw acc= 47.2% |
| Epoch 177, lr=2.9e-03 time=  5.7s/  7.7s | Train: loss=2.277, TAw acc= 42.6% | Valid: time=  1.1s loss=2.058, TAw acc= 47.5% | lr=9.7e-04
| Epoch 178, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.306, TAw acc= 41.9% | Valid: time=  1.1s loss=2.054, TAw acc= 46.9% |
| Epoch 179, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.296, TAw acc= 42.4% | Valid: time=  1.1s loss=2.058, TAw acc= 46.8% |
| Epoch 180, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.294, TAw acc= 42.0% | Valid: time=  1.1s loss=2.059, TAw acc= 47.0% |
| Epoch 181, lr=9.7e-04 time=  5.8s/  7.8s | Train: loss=2.294, TAw acc= 42.2% | Valid: time=  1.1s loss=2.060, TAw acc= 47.1% |
| Epoch 182, lr=9.7e-04 time=  5.9s/  7.7s | Train: loss=2.281, TAw acc= 42.4% | Valid: time=  1.1s loss=2.063, TAw acc= 47.1% |
| Epoch 183, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.284, TAw acc= 42.5% | Valid: time=  1.1s loss=2.062, TAw acc= 47.0% |
| Epoch 184, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.283, TAw acc= 42.2% | Valid: time=  1.1s loss=2.058, TAw acc= 47.0% |
| Epoch 185, lr=9.7e-04 time=  5.9s/  7.8s | Train: loss=2.294, TAw acc= 42.0% | Valid: time=  1.1s loss=2.068, TAw acc= 46.8% |
| Epoch 186, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.290, TAw acc= 42.3% | Valid: time=  1.1s loss=2.058, TAw acc= 47.0% |
| Epoch 187, lr=9.7e-04 time=  5.8s/  7.9s | Train: loss=2.284, TAw acc= 42.4% | Valid: time=  1.1s loss=2.063, TAw acc= 46.8% |
| Epoch 188, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.280, TAw acc= 42.2% | Valid: time=  1.1s loss=2.063, TAw acc= 46.8% |
| Epoch 189, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.289, TAw acc= 42.3% | Valid: time=  1.2s loss=2.059, TAw acc= 47.0% |
| Epoch 190, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.293, TAw acc= 42.1% | Valid: time=  1.1s loss=2.064, TAw acc= 46.8% |
| Epoch 191, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.283, TAw acc= 42.5% | Valid: time=  1.1s loss=2.068, TAw acc= 46.9% |
| Epoch 192, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.277, TAw acc= 42.4% | Valid: time=  1.1s loss=2.065, TAw acc= 46.8% |
| Epoch 193, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.285, TAw acc= 42.2% | Valid: time=  1.1s loss=2.062, TAw acc= 46.9% |
| Epoch 194, lr=9.7e-04 time=  5.7s/  7.8s | Train: loss=2.285, TAw acc= 42.4% | Valid: time=  1.1s loss=2.066, TAw acc= 46.8% |
| Epoch 195, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.289, TAw acc= 42.0% | Valid: time=  1.1s loss=2.061, TAw acc= 46.9% |
| Epoch 196, lr=9.7e-04 time=  5.7s/  7.8s | Train: loss=2.283, TAw acc= 42.4% | Valid: time=  1.1s loss=2.064, TAw acc= 46.6% |
| Epoch 197, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.284, TAw acc= 42.3% | Valid: time=  1.1s loss=2.064, TAw acc= 46.8% |
| Epoch 198, lr=9.7e-04 time=  5.6s/  7.7s | Train: loss=2.285, TAw acc= 42.5% | Valid: time=  1.2s loss=2.058, TAw acc= 47.0% |
| Epoch 199, lr=9.7e-04 time=  5.8s/  7.7s | Train: loss=2.279, TAw acc= 42.2% | Valid: time=  1.1s loss=2.063, TAw acc= 46.8% |
| Epoch 200, lr=9.7e-04 time=  5.7s/  7.7s | Train: loss=2.279, TAw acc= 42.4% | Valid: time=  1.1s loss=2.057, TAw acc= 47.2% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=2.051 | TAw acc= 47.1%, forg=  0.0%| TAg acc= 47.1%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR1/0/cifar100_finetuning
************************************************************************************************************
TAw Acc
	 47.1% 	Avg.: 47.1% 
************************************************************************************************************
TAg Acc
	 47.1% 	Avg.: 47.1% 
************************************************************************************************************
TAw Forg
	  0.0% 
************************************************************************************************************
TAg Forg
	  0.0% 
************************************************************************************************************
[Elapsed time = 0.8 h]
Done!
