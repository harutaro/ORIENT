============================================================================================================
Arguments =
	approach: finetuning
	batch_size: 64
	clipping: 1.0
	datasets: ['cifar100']
	eval_on_train: True
	exp_name: None
	fix_bn: True
	gpu: 4
	gridsearch_tasks: -1
	keep_existing_head: False
	last_layer_analysis: False
	log: ['disk']
	lr: 0.0263039750973134
	lr_factor: 3.0
	lr_first: None
	lr_min: 1e-05
	lr_patience: 30
	momentum: 0.9
	multi_softmax: True
	nc_first_task: None
	nepochs: 200
	network: resnet50_32
	no_cudnn_deterministic: False
	num_tasks: 10
	num_workers: 4
	pin_memory: True
	pretrained: False
	results_path: ../RESULT_AAAI2026/CR10/0
	save_models: True
	seed: 0
	stop_at_task: 0
	validation: 0.1
	warmup_lr_factor: 1.0
	warmup_nepochs: 0
	weight_decay: 0.0
============================================================================================================
	device: cuda:4
============================================================================================================
Network arguments =
	dropout: 0.417598542370663
	fix_features: True
	load_features: True
	pretrained_path: ../Conv-Model/ResNet50-TinyImageNet.pt
============================================================================================================
ResNet50_32.__init__: features is loadded (../Conv-Model/ResNet50-TinyImageNet.pt)
Fix_Features: Done
Approach arguments =
	all_outputs: False
============================================================================================================
Exemplars dataset arguments =
	exemplar_selection: random
	num_exemplars: 0
	num_exemplars_per_class: 0
============================================================================================================
class_indices: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
[(0, 10), (1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10), (8, 10), (9, 10)]
************************************************************************************************************
Task  0
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.4s/  1.0s | Train: loss=1.406, TAw acc= 53.3% | Valid: time=  0.3s loss=1.117, TAw acc= 58.4% | *
| Epoch   2, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.271, TAw acc= 57.8% | Valid: time=  0.3s loss=0.870, TAw acc= 70.6% | *
| Epoch   3, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.232, TAw acc= 57.2% | Valid: time=  0.3s loss=0.844, TAw acc= 67.4% | *
| Epoch   4, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.193, TAw acc= 59.3% | Valid: time=  0.3s loss=0.722, TAw acc= 75.4% | *
| Epoch   5, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=1.122, TAw acc= 62.6% | Valid: time=  0.3s loss=0.769, TAw acc= 73.0% |
| Epoch   6, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.106, TAw acc= 63.0% | Valid: time=  0.3s loss=0.801, TAw acc= 70.4% |
| Epoch   7, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.153, TAw acc= 60.4% | Valid: time=  0.3s loss=0.761, TAw acc= 73.0% |
| Epoch   8, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.114, TAw acc= 61.6% | Valid: time=  0.4s loss=0.784, TAw acc= 73.2% |
| Epoch   9, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.104, TAw acc= 62.9% | Valid: time=  0.3s loss=0.726, TAw acc= 73.2% |
| Epoch  10, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.095, TAw acc= 62.8% | Valid: time=  0.3s loss=0.761, TAw acc= 74.6% |
| Epoch  11, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.024, TAw acc= 66.1% | Valid: time=  0.3s loss=0.656, TAw acc= 77.2% | *
| Epoch  12, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.040, TAw acc= 64.3% | Valid: time=  0.3s loss=0.700, TAw acc= 76.2% |
| Epoch  13, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.038, TAw acc= 65.2% | Valid: time=  0.3s loss=0.775, TAw acc= 73.6% |
| Epoch  14, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.021, TAw acc= 65.2% | Valid: time=  0.4s loss=0.695, TAw acc= 75.2% |
| Epoch  15, lr=2.6e-02 time=  1.1s/  1.0s | Train: loss=1.044, TAw acc= 63.9% | Valid: time=  0.3s loss=0.690, TAw acc= 76.8% |
| Epoch  16, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.025, TAw acc= 64.3% | Valid: time=  0.3s loss=0.653, TAw acc= 76.2% | *
| Epoch  17, lr=2.6e-02 time=  0.8s/  1.8s | Train: loss=0.982, TAw acc= 67.0% | Valid: time=  0.4s loss=0.678, TAw acc= 76.6% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  1.1s | Train: loss=0.978, TAw acc= 66.5% | Valid: time=  0.3s loss=0.647, TAw acc= 78.2% | *
| Epoch  19, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.011, TAw acc= 66.4% | Valid: time=  0.3s loss=0.663, TAw acc= 79.2% |
| Epoch  20, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.960, TAw acc= 68.0% | Valid: time=  0.3s loss=0.674, TAw acc= 76.4% |
| Epoch  21, lr=2.6e-02 time=  0.8s/  1.1s | Train: loss=0.997, TAw acc= 66.8% | Valid: time=  0.4s loss=0.638, TAw acc= 77.2% | *
| Epoch  22, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.994, TAw acc= 65.2% | Valid: time=  0.4s loss=0.583, TAw acc= 80.8% | *
| Epoch  23, lr=2.6e-02 time=  1.3s/  1.2s | Train: loss=0.964, TAw acc= 68.0% | Valid: time=  0.3s loss=0.693, TAw acc= 76.2% |
