============================================================================================================
Arguments =
	approach: finetuning
	batch_size: 64
	clipping: 1.0
	datasets: ['cifar100']
	eval_on_train: True
	exp_name: None
	fix_bn: True
	gpu: 4
	gridsearch_tasks: -1
	keep_existing_head: False
	last_layer_analysis: False
	log: ['disk']
	lr: 0.0263039750973134
	lr_factor: 3.0
	lr_first: None
	lr_min: 1e-05
	lr_patience: 30
	momentum: 0.9
	multi_softmax: True
	nc_first_task: None
	nepochs: 200
	network: resnet50_32
	no_cudnn_deterministic: False
	num_tasks: 10
	num_workers: 4
	pin_memory: True
	pretrained: False
	results_path: ../RESULT_AAAI2026/CR10/0
	save_models: True
	seed: 0
	stop_at_task: 0
	validation: 0.1
	warmup_lr_factor: 1.0
	warmup_nepochs: 0
	weight_decay: 0.0
============================================================================================================
	device: cuda:4
============================================================================================================
Network arguments =
	dropout: 0.417598542370663
	fix_features: True
	load_features: True
	pretrained_path: ../Conv-Model/ResNet50-TinyImageNet.pt
============================================================================================================
ResNet50_32.__init__: features is loadded (../Conv-Model/ResNet50-TinyImageNet.pt)
Fix_Features: Done
Approach arguments =
	all_outputs: False
============================================================================================================
Exemplars dataset arguments =
	exemplar_selection: random
	num_exemplars: 0
	num_exemplars_per_class: 0
============================================================================================================
class_indices: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
[(0, 10), (1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10), (8, 10), (9, 10)]
************************************************************************************************************
Task  0
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.6s/  1.0s | Train: loss=1.406, TAw acc= 53.3% | Valid: time=  0.3s loss=1.117, TAw acc= 58.4% | *
| Epoch   2, lr=2.6e-02 time=  0.8s/  1.2s | Train: loss=1.271, TAw acc= 57.8% | Valid: time=  0.5s loss=0.870, TAw acc= 70.6% | *
| Epoch   3, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=1.232, TAw acc= 57.2% | Valid: time=  0.3s loss=0.844, TAw acc= 67.4% | *
| Epoch   4, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.193, TAw acc= 59.3% | Valid: time=  0.3s loss=0.722, TAw acc= 75.4% | *
| Epoch   5, lr=2.6e-02 time=  0.8s/  2.4s | Train: loss=1.122, TAw acc= 62.6% | Valid: time=  0.5s loss=0.769, TAw acc= 73.0% |
| Epoch   6, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=1.106, TAw acc= 63.0% | Valid: time=  0.4s loss=0.801, TAw acc= 70.4% |
| Epoch   7, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=1.153, TAw acc= 60.4% | Valid: time=  0.3s loss=0.761, TAw acc= 73.0% |
| Epoch   8, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.114, TAw acc= 61.6% | Valid: time=  0.3s loss=0.784, TAw acc= 73.2% |
| Epoch   9, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.104, TAw acc= 62.9% | Valid: time=  0.3s loss=0.726, TAw acc= 73.2% |
| Epoch  10, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.095, TAw acc= 62.8% | Valid: time=  0.4s loss=0.761, TAw acc= 74.6% |
| Epoch  11, lr=2.6e-02 time=  1.1s/  1.4s | Train: loss=1.024, TAw acc= 66.1% | Valid: time=  0.3s loss=0.656, TAw acc= 77.2% | *
| Epoch  12, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.040, TAw acc= 64.3% | Valid: time=  0.5s loss=0.700, TAw acc= 76.2% |
| Epoch  13, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=1.038, TAw acc= 65.2% | Valid: time=  0.5s loss=0.775, TAw acc= 73.6% |
| Epoch  14, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=1.021, TAw acc= 65.2% | Valid: time=  0.5s loss=0.695, TAw acc= 75.2% |
| Epoch  15, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.044, TAw acc= 63.9% | Valid: time=  0.5s loss=0.690, TAw acc= 76.8% |
| Epoch  16, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.025, TAw acc= 64.3% | Valid: time=  0.5s loss=0.653, TAw acc= 76.2% | *
| Epoch  17, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.982, TAw acc= 67.0% | Valid: time=  0.5s loss=0.678, TAw acc= 76.6% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.978, TAw acc= 66.5% | Valid: time=  0.5s loss=0.647, TAw acc= 78.2% | *
| Epoch  19, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=1.011, TAw acc= 66.4% | Valid: time=  0.4s loss=0.663, TAw acc= 79.2% |
| Epoch  20, lr=2.6e-02 time=  1.1s/  2.0s | Train: loss=0.960, TAw acc= 68.0% | Valid: time=  0.5s loss=0.674, TAw acc= 76.4% |
| Epoch  21, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.997, TAw acc= 66.8% | Valid: time=  0.5s loss=0.638, TAw acc= 77.2% | *
| Epoch  22, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.994, TAw acc= 65.2% | Valid: time=  0.5s loss=0.583, TAw acc= 80.8% | *
| Epoch  23, lr=2.6e-02 time=  1.1s/  1.0s | Train: loss=0.964, TAw acc= 68.0% | Valid: time=  0.3s loss=0.693, TAw acc= 76.2% |
| Epoch  24, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.935, TAw acc= 69.0% | Valid: time=  0.5s loss=0.647, TAw acc= 78.8% |
| Epoch  25, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.953, TAw acc= 67.7% | Valid: time=  0.5s loss=0.618, TAw acc= 80.4% |
| Epoch  26, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.946, TAw acc= 68.6% | Valid: time=  0.5s loss=0.649, TAw acc= 77.8% |
| Epoch  27, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.943, TAw acc= 68.8% | Valid: time=  0.5s loss=0.643, TAw acc= 78.2% |
| Epoch  28, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.953, TAw acc= 67.5% | Valid: time=  0.4s loss=0.602, TAw acc= 79.0% |
| Epoch  29, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.915, TAw acc= 69.9% | Valid: time=  0.5s loss=0.630, TAw acc= 77.8% |
| Epoch  30, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.948, TAw acc= 68.5% | Valid: time=  0.5s loss=0.608, TAw acc= 81.4% |
| Epoch  31, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.907, TAw acc= 69.2% | Valid: time=  0.5s loss=0.614, TAw acc= 79.6% |
| Epoch  32, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.947, TAw acc= 67.9% | Valid: time=  0.4s loss=0.587, TAw acc= 79.8% |
| Epoch  33, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.921, TAw acc= 69.1% | Valid: time=  0.4s loss=0.646, TAw acc= 77.0% |
| Epoch  34, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.939, TAw acc= 67.7% | Valid: time=  0.4s loss=0.610, TAw acc= 79.4% |
| Epoch  35, lr=2.6e-02 time=  0.8s/  1.9s | Train: loss=0.911, TAw acc= 69.2% | Valid: time=  0.5s loss=0.605, TAw acc= 79.4% |
| Epoch  36, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.928, TAw acc= 68.7% | Valid: time=  0.5s loss=0.591, TAw acc= 81.4% |
| Epoch  37, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.897, TAw acc= 69.8% | Valid: time=  0.5s loss=0.640, TAw acc= 77.0% |
| Epoch  38, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.880, TAw acc= 69.6% | Valid: time=  0.5s loss=0.614, TAw acc= 79.0% |
| Epoch  39, lr=2.6e-02 time=  1.3s/  1.6s | Train: loss=0.898, TAw acc= 70.0% | Valid: time=  0.5s loss=0.637, TAw acc= 78.2% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.917, TAw acc= 69.0% | Valid: time=  0.5s loss=0.572, TAw acc= 80.4% | *
| Epoch  41, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.880, TAw acc= 70.8% | Valid: time=  0.5s loss=0.604, TAw acc= 80.2% |
| Epoch  42, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.905, TAw acc= 70.0% | Valid: time=  0.3s loss=0.573, TAw acc= 82.4% |
| Epoch  43, lr=2.6e-02 time=  1.0s/  2.0s | Train: loss=0.917, TAw acc= 68.4% | Valid: time=  0.5s loss=0.646, TAw acc= 78.4% |
| Epoch  44, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.893, TAw acc= 70.4% | Valid: time=  0.5s loss=0.587, TAw acc= 81.2% |
| Epoch  45, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.902, TAw acc= 70.2% | Valid: time=  0.5s loss=0.601, TAw acc= 79.4% |
| Epoch  46, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.897, TAw acc= 69.6% | Valid: time=  0.5s loss=0.657, TAw acc= 78.0% |
| Epoch  47, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.884, TAw acc= 70.6% | Valid: time=  0.5s loss=0.623, TAw acc= 80.8% |
| Epoch  48, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.863, TAw acc= 71.8% | Valid: time=  0.5s loss=0.601, TAw acc= 80.4% |
| Epoch  49, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.921, TAw acc= 69.1% | Valid: time=  0.4s loss=0.649, TAw acc= 80.6% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.846, TAw acc= 71.5% | Valid: time=  0.4s loss=0.623, TAw acc= 79.4% |
| Epoch  51, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.853, TAw acc= 71.1% | Valid: time=  0.5s loss=0.570, TAw acc= 81.6% | *
| Epoch  52, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.866, TAw acc= 70.7% | Valid: time=  0.5s loss=0.607, TAw acc= 80.0% |
| Epoch  53, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.885, TAw acc= 70.3% | Valid: time=  0.5s loss=0.558, TAw acc= 82.0% | *
| Epoch  54, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.896, TAw acc= 69.4% | Valid: time=  0.5s loss=0.601, TAw acc= 79.2% |
| Epoch  55, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.882, TAw acc= 70.7% | Valid: time=  0.5s loss=0.603, TAw acc= 80.6% |
| Epoch  56, lr=2.6e-02 time=  1.5s/  2.5s | Train: loss=0.889, TAw acc= 70.1% | Valid: time=  0.5s loss=0.605, TAw acc= 81.2% |
| Epoch  57, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.859, TAw acc= 71.6% | Valid: time=  0.5s loss=0.662, TAw acc= 80.0% |
| Epoch  58, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.864, TAw acc= 70.8% | Valid: time=  0.5s loss=0.642, TAw acc= 79.8% |
| Epoch  59, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.871, TAw acc= 70.8% | Valid: time=  0.5s loss=0.558, TAw acc= 81.6% | *
| Epoch  60, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.831, TAw acc= 71.7% | Valid: time=  0.5s loss=0.602, TAw acc= 81.2% |
| Epoch  61, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.825, TAw acc= 72.9% | Valid: time=  0.4s loss=0.641, TAw acc= 80.4% |
| Epoch  62, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.855, TAw acc= 70.6% | Valid: time=  0.5s loss=0.590, TAw acc= 81.4% |
| Epoch  63, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.861, TAw acc= 71.2% | Valid: time=  0.4s loss=0.600, TAw acc= 79.6% |
| Epoch  64, lr=2.6e-02 time=  1.2s/  1.1s | Train: loss=0.843, TAw acc= 71.4% | Valid: time=  0.6s loss=0.587, TAw acc= 81.6% |
| Epoch  65, lr=2.6e-02 time=  1.5s/  2.1s | Train: loss=0.843, TAw acc= 72.2% | Valid: time=  0.5s loss=0.573, TAw acc= 81.6% |
| Epoch  66, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.839, TAw acc= 72.2% | Valid: time=  0.5s loss=0.635, TAw acc= 79.4% |
| Epoch  67, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.837, TAw acc= 72.3% | Valid: time=  0.5s loss=0.647, TAw acc= 80.4% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.858, TAw acc= 70.4% | Valid: time=  0.5s loss=0.658, TAw acc= 78.2% |
| Epoch  69, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.848, TAw acc= 71.6% | Valid: time=  0.5s loss=0.678, TAw acc= 77.6% |
| Epoch  70, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.832, TAw acc= 73.2% | Valid: time=  0.5s loss=0.606, TAw acc= 79.8% |
| Epoch  71, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.834, TAw acc= 72.7% | Valid: time=  0.5s loss=0.587, TAw acc= 79.2% |
| Epoch  72, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.816, TAw acc= 72.3% | Valid: time=  0.4s loss=0.592, TAw acc= 80.8% |
| Epoch  73, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.844, TAw acc= 72.5% | Valid: time=  0.5s loss=0.616, TAw acc= 78.4% |
| Epoch  74, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.840, TAw acc= 72.2% | Valid: time=  0.5s loss=0.621, TAw acc= 79.6% |
| Epoch  75, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.812, TAw acc= 72.2% | Valid: time=  0.5s loss=0.630, TAw acc= 80.2% |
| Epoch  76, lr=2.6e-02 time=  1.0s/  1.8s | Train: loss=0.850, TAw acc= 71.2% | Valid: time=  0.5s loss=0.613, TAw acc= 79.6% |
| Epoch  77, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.811, TAw acc= 72.7% | Valid: time=  0.5s loss=0.610, TAw acc= 78.8% |
| Epoch  78, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.825, TAw acc= 72.8% | Valid: time=  0.5s loss=0.562, TAw acc= 81.4% |
| Epoch  79, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.803, TAw acc= 73.6% | Valid: time=  0.5s loss=0.618, TAw acc= 79.8% |
| Epoch  80, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.812, TAw acc= 73.4% | Valid: time=  0.5s loss=0.658, TAw acc= 78.8% |
| Epoch  81, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.803, TAw acc= 72.8% | Valid: time=  0.4s loss=0.597, TAw acc= 80.2% |
| Epoch  82, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.804, TAw acc= 73.2% | Valid: time=  0.4s loss=0.614, TAw acc= 81.0% |
| Epoch  83, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.815, TAw acc= 72.5% | Valid: time=  0.5s loss=0.632, TAw acc= 79.4% |
| Epoch  84, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.812, TAw acc= 72.7% | Valid: time=  0.3s loss=0.646, TAw acc= 78.6% |
| Epoch  85, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.808, TAw acc= 73.5% | Valid: time=  0.5s loss=0.629, TAw acc= 79.6% |
| Epoch  86, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.802, TAw acc= 73.4% | Valid: time=  0.5s loss=0.557, TAw acc= 81.8% | *
| Epoch  87, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.806, TAw acc= 73.9% | Valid: time=  0.5s loss=0.614, TAw acc= 79.6% |
| Epoch  88, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.803, TAw acc= 73.4% | Valid: time=  0.5s loss=0.628, TAw acc= 79.2% |
| Epoch  89, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.832, TAw acc= 71.7% | Valid: time=  0.5s loss=0.637, TAw acc= 78.0% |
| Epoch  90, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.855, TAw acc= 70.4% | Valid: time=  0.5s loss=0.640, TAw acc= 78.0% |
| Epoch  91, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.827, TAw acc= 72.5% | Valid: time=  0.5s loss=0.607, TAw acc= 79.0% |
| Epoch  92, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.788, TAw acc= 74.6% | Valid: time=  0.5s loss=0.592, TAw acc= 80.2% |
| Epoch  93, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.796, TAw acc= 73.3% | Valid: time=  0.5s loss=0.582, TAw acc= 82.4% |
| Epoch  94, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.817, TAw acc= 72.5% | Valid: time=  0.5s loss=0.603, TAw acc= 79.6% |
| Epoch  95, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.805, TAw acc= 73.5% | Valid: time=  0.5s loss=0.592, TAw acc= 80.6% |
| Epoch  96, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.805, TAw acc= 73.7% | Valid: time=  0.5s loss=0.585, TAw acc= 81.4% |
| Epoch  97, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.792, TAw acc= 73.8% | Valid: time=  0.4s loss=0.646, TAw acc= 78.8% |
| Epoch  98, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.793, TAw acc= 73.7% | Valid: time=  0.4s loss=0.652, TAw acc= 78.0% |
| Epoch  99, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.808, TAw acc= 72.7% | Valid: time=  0.5s loss=0.607, TAw acc= 81.8% |
| Epoch 100, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.778, TAw acc= 74.3% | Valid: time=  0.5s loss=0.600, TAw acc= 80.6% |
| Epoch 101, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.784, TAw acc= 74.2% | Valid: time=  0.5s loss=0.633, TAw acc= 78.8% |
| Epoch 102, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.787, TAw acc= 73.5% | Valid: time=  0.5s loss=0.655, TAw acc= 77.6% |
| Epoch 103, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.804, TAw acc= 73.3% | Valid: time=  0.5s loss=0.659, TAw acc= 77.8% |
| Epoch 104, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.793, TAw acc= 73.3% | Valid: time=  0.3s loss=0.599, TAw acc= 81.4% |
| Epoch 105, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=0.773, TAw acc= 73.8% | Valid: time=  0.5s loss=0.586, TAw acc= 81.0% |
| Epoch 106, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.815, TAw acc= 72.8% | Valid: time=  0.4s loss=0.575, TAw acc= 81.8% |
| Epoch 107, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.782, TAw acc= 74.2% | Valid: time=  0.4s loss=0.668, TAw acc= 77.6% |
| Epoch 108, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.790, TAw acc= 72.8% | Valid: time=  0.5s loss=0.614, TAw acc= 80.6% |
| Epoch 109, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.779, TAw acc= 73.7% | Valid: time=  0.5s loss=0.618, TAw acc= 80.4% |
| Epoch 110, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.808, TAw acc= 73.3% | Valid: time=  0.5s loss=0.590, TAw acc= 82.8% |
| Epoch 111, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.830, TAw acc= 72.0% | Valid: time=  0.5s loss=0.730, TAw acc= 75.4% |
| Epoch 112, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.792, TAw acc= 73.6% | Valid: time=  0.4s loss=0.601, TAw acc= 80.6% |
| Epoch 113, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.785, TAw acc= 74.0% | Valid: time=  0.5s loss=0.640, TAw acc= 80.2% |
| Epoch 114, lr=2.6e-02 time=  1.3s/  1.4s | Train: loss=0.762, TAw acc= 75.0% | Valid: time=  0.5s loss=0.669, TAw acc= 78.8% |
| Epoch 115, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.764, TAw acc= 74.9% | Valid: time=  0.5s loss=0.589, TAw acc= 79.6% |
| Epoch 116, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.759, TAw acc= 74.3% | Valid: time=  0.5s loss=0.648, TAw acc= 79.8% | lr=8.8e-03
| Epoch 117, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.781, TAw acc= 74.5% | Valid: time=  0.5s loss=0.581, TAw acc= 81.0% |
| Epoch 118, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.787, TAw acc= 74.2% | Valid: time=  0.5s loss=0.580, TAw acc= 81.4% |
| Epoch 119, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.775, TAw acc= 73.7% | Valid: time=  0.5s loss=0.576, TAw acc= 81.8% |
| Epoch 120, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.768, TAw acc= 74.4% | Valid: time=  0.5s loss=0.540, TAw acc= 82.2% | *
| Epoch 121, lr=8.8e-03 time=  1.2s/  1.7s | Train: loss=0.754, TAw acc= 74.9% | Valid: time=  0.5s loss=0.631, TAw acc= 79.4% |
| Epoch 122, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.761, TAw acc= 74.6% | Valid: time=  0.5s loss=0.579, TAw acc= 81.8% |
| Epoch 123, lr=8.8e-03 time=  1.3s/  2.1s | Train: loss=0.772, TAw acc= 74.8% | Valid: time=  0.4s loss=0.558, TAw acc= 82.2% |
| Epoch 124, lr=8.8e-03 time=  1.0s/  1.9s | Train: loss=0.774, TAw acc= 74.8% | Valid: time=  0.5s loss=0.584, TAw acc= 81.2% |
| Epoch 125, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.737, TAw acc= 76.1% | Valid: time=  0.5s loss=0.580, TAw acc= 80.0% |
| Epoch 126, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.763, TAw acc= 74.6% | Valid: time=  0.5s loss=0.571, TAw acc= 81.6% |
| Epoch 127, lr=8.8e-03 time=  1.1s/  2.1s | Train: loss=0.747, TAw acc= 75.6% | Valid: time=  0.5s loss=0.597, TAw acc= 80.2% |
| Epoch 128, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.757, TAw acc= 74.8% | Valid: time=  0.5s loss=0.563, TAw acc= 81.8% |
| Epoch 129, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.758, TAw acc= 74.7% | Valid: time=  0.5s loss=0.610, TAw acc= 78.6% |
| Epoch 130, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.755, TAw acc= 75.0% | Valid: time=  0.5s loss=0.565, TAw acc= 81.6% |
| Epoch 131, lr=8.8e-03 time=  1.2s/  2.2s | Train: loss=0.762, TAw acc= 74.9% | Valid: time=  0.5s loss=0.575, TAw acc= 80.2% |
| Epoch 132, lr=8.8e-03 time=  1.3s/  1.7s | Train: loss=0.765, TAw acc= 74.7% | Valid: time=  0.5s loss=0.594, TAw acc= 78.8% |
| Epoch 133, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.748, TAw acc= 75.2% | Valid: time=  0.5s loss=0.580, TAw acc= 80.0% |
| Epoch 134, lr=8.8e-03 time=  1.2s/  2.1s | Train: loss=0.756, TAw acc= 75.5% | Valid: time=  0.3s loss=0.568, TAw acc= 80.2% |
| Epoch 135, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.764, TAw acc= 74.9% | Valid: time=  0.4s loss=0.573, TAw acc= 80.8% |
| Epoch 136, lr=8.8e-03 time=  1.1s/  1.9s | Train: loss=0.752, TAw acc= 75.0% | Valid: time=  0.5s loss=0.602, TAw acc= 80.6% |
| Epoch 137, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.743, TAw acc= 75.7% | Valid: time=  0.5s loss=0.616, TAw acc= 79.2% |
| Epoch 138, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.761, TAw acc= 74.8% | Valid: time=  0.5s loss=0.619, TAw acc= 80.6% |
| Epoch 139, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.739, TAw acc= 76.0% | Valid: time=  0.5s loss=0.577, TAw acc= 80.6% |
| Epoch 140, lr=8.8e-03 time=  1.3s/  1.7s | Train: loss=0.750, TAw acc= 76.0% | Valid: time=  0.5s loss=0.561, TAw acc= 81.8% |
| Epoch 141, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.746, TAw acc= 74.7% | Valid: time=  0.5s loss=0.585, TAw acc= 81.6% |
| Epoch 142, lr=8.8e-03 time=  1.3s/  1.8s | Train: loss=0.750, TAw acc= 75.2% | Valid: time=  0.4s loss=0.567, TAw acc= 81.4% |
| Epoch 143, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.745, TAw acc= 75.5% | Valid: time=  0.4s loss=0.579, TAw acc= 80.2% |
| Epoch 144, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.759, TAw acc= 74.9% | Valid: time=  0.5s loss=0.604, TAw acc= 78.6% |
| Epoch 145, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.750, TAw acc= 74.8% | Valid: time=  0.5s loss=0.599, TAw acc= 81.0% |
| Epoch 146, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.726, TAw acc= 76.3% | Valid: time=  0.5s loss=0.581, TAw acc= 79.8% |
| Epoch 147, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.737, TAw acc= 75.2% | Valid: time=  0.5s loss=0.618, TAw acc= 79.2% |
| Epoch 148, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.719, TAw acc= 76.0% | Valid: time=  0.5s loss=0.570, TAw acc= 82.0% |
| Epoch 149, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.726, TAw acc= 76.5% | Valid: time=  0.5s loss=0.589, TAw acc= 80.0% |
| Epoch 150, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.735, TAw acc= 75.9% | Valid: time=  0.4s loss=0.587, TAw acc= 80.4% | lr=2.9e-03
| Epoch 151, lr=2.9e-03 time=  1.2s/  1.5s | Train: loss=0.745, TAw acc= 74.6% | Valid: time=  0.5s loss=0.563, TAw acc= 81.0% |
| Epoch 152, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.766, TAw acc= 74.4% | Valid: time=  0.5s loss=0.571, TAw acc= 81.6% |
| Epoch 153, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.767, TAw acc= 74.6% | Valid: time=  0.5s loss=0.554, TAw acc= 82.0% |
| Epoch 154, lr=2.9e-03 time=  1.3s/  1.6s | Train: loss=0.760, TAw acc= 75.1% | Valid: time=  0.4s loss=0.593, TAw acc= 80.4% |
| Epoch 155, lr=2.9e-03 time=  1.2s/  1.8s | Train: loss=0.755, TAw acc= 75.5% | Valid: time=  0.5s loss=0.583, TAw acc= 80.2% |
| Epoch 156, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.761, TAw acc= 74.3% | Valid: time=  0.5s loss=0.557, TAw acc= 81.6% |
| Epoch 157, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.763, TAw acc= 74.9% | Valid: time=  0.5s loss=0.556, TAw acc= 82.0% |
| Epoch 158, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.779, TAw acc= 74.8% | Valid: time=  0.5s loss=0.567, TAw acc= 81.2% |
| Epoch 159, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.744, TAw acc= 74.9% | Valid: time=  0.5s loss=0.567, TAw acc= 80.4% |
| Epoch 160, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=0.733, TAw acc= 76.1% | Valid: time=  0.5s loss=0.566, TAw acc= 80.0% |
| Epoch 161, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.738, TAw acc= 75.8% | Valid: time=  0.5s loss=0.555, TAw acc= 81.0% |
| Epoch 162, lr=2.9e-03 time=  1.3s/  1.9s | Train: loss=0.762, TAw acc= 74.6% | Valid: time=  0.4s loss=0.582, TAw acc= 79.8% |
| Epoch 163, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.763, TAw acc= 74.3% | Valid: time=  0.5s loss=0.561, TAw acc= 80.4% |
| Epoch 164, lr=2.9e-03 time=  1.0s/  2.3s | Train: loss=0.757, TAw acc= 75.1% | Valid: time=  0.4s loss=0.573, TAw acc= 80.0% |
| Epoch 165, lr=2.9e-03 time=  1.1s/  2.0s | Train: loss=0.781, TAw acc= 72.8% | Valid: time=  0.5s loss=0.590, TAw acc= 79.4% |
| Epoch 166, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.770, TAw acc= 74.4% | Valid: time=  0.5s loss=0.571, TAw acc= 80.8% |
| Epoch 167, lr=2.9e-03 time=  1.1s/  2.2s | Train: loss=0.748, TAw acc= 75.2% | Valid: time=  0.5s loss=0.579, TAw acc= 79.8% |
| Epoch 168, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.768, TAw acc= 73.8% | Valid: time=  0.5s loss=0.568, TAw acc= 80.8% |
| Epoch 169, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.736, TAw acc= 75.5% | Valid: time=  0.4s loss=0.580, TAw acc= 79.8% |
| Epoch 170, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.726, TAw acc= 76.3% | Valid: time=  0.5s loss=0.576, TAw acc= 80.4% |
| Epoch 171, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.757, TAw acc= 75.3% | Valid: time=  0.5s loss=0.573, TAw acc= 81.4% |
| Epoch 172, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.761, TAw acc= 74.6% | Valid: time=  0.4s loss=0.594, TAw acc= 79.6% |
| Epoch 173, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.762, TAw acc= 74.9% | Valid: time=  0.4s loss=0.576, TAw acc= 80.8% |
| Epoch 174, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.746, TAw acc= 75.7% | Valid: time=  0.4s loss=0.579, TAw acc= 79.8% |
| Epoch 175, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.734, TAw acc= 75.2% | Valid: time=  0.5s loss=0.568, TAw acc= 80.4% |
| Epoch 176, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.738, TAw acc= 75.6% | Valid: time=  0.5s loss=0.581, TAw acc= 80.2% |
| Epoch 177, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.742, TAw acc= 75.8% | Valid: time=  0.5s loss=0.571, TAw acc= 79.8% |
| Epoch 178, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.751, TAw acc= 74.7% | Valid: time=  0.5s loss=0.595, TAw acc= 79.0% |
| Epoch 179, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.743, TAw acc= 75.2% | Valid: time=  0.5s loss=0.568, TAw acc= 80.0% |
| Epoch 180, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.747, TAw acc= 76.0% | Valid: time=  0.5s loss=0.581, TAw acc= 80.6% | lr=9.7e-04
| Epoch 181, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.775, TAw acc= 74.0% | Valid: time=  0.5s loss=0.554, TAw acc= 82.0% |
| Epoch 182, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.769, TAw acc= 75.1% | Valid: time=  0.5s loss=0.554, TAw acc= 81.8% |
| Epoch 183, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.756, TAw acc= 75.8% | Valid: time=  0.4s loss=0.564, TAw acc= 81.2% |
| Epoch 184, lr=9.7e-04 time=  1.1s/  1.6s | Train: loss=0.772, TAw acc= 74.0% | Valid: time=  0.5s loss=0.561, TAw acc= 81.0% |
| Epoch 185, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.762, TAw acc= 74.7% | Valid: time=  0.4s loss=0.568, TAw acc= 81.0% |
| Epoch 186, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.788, TAw acc= 74.6% | Valid: time=  0.5s loss=0.560, TAw acc= 81.0% |
| Epoch 187, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.759, TAw acc= 75.2% | Valid: time=  0.4s loss=0.564, TAw acc= 81.0% |
| Epoch 188, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.755, TAw acc= 75.7% | Valid: time=  0.5s loss=0.565, TAw acc= 81.0% |
| Epoch 189, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.757, TAw acc= 75.0% | Valid: time=  0.5s loss=0.574, TAw acc= 80.6% |
| Epoch 190, lr=9.7e-04 time=  1.3s/  1.9s | Train: loss=0.780, TAw acc= 74.8% | Valid: time=  0.3s loss=0.563, TAw acc= 81.2% |
| Epoch 191, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.781, TAw acc= 74.3% | Valid: time=  0.5s loss=0.569, TAw acc= 80.6% |
| Epoch 192, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.748, TAw acc= 75.3% | Valid: time=  0.5s loss=0.570, TAw acc= 80.6% |
| Epoch 193, lr=9.7e-04 time=  1.4s/  1.6s | Train: loss=0.757, TAw acc= 74.6% | Valid: time=  0.4s loss=0.561, TAw acc= 80.4% |
| Epoch 194, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.757, TAw acc= 74.9% | Valid: time=  0.5s loss=0.564, TAw acc= 81.8% |
| Epoch 195, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.745, TAw acc= 75.5% | Valid: time=  0.4s loss=0.564, TAw acc= 81.6% |
| Epoch 196, lr=9.7e-04 time=  1.3s/  1.8s | Train: loss=0.750, TAw acc= 74.4% | Valid: time=  0.3s loss=0.562, TAw acc= 81.0% |
| Epoch 197, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.735, TAw acc= 75.9% | Valid: time=  0.5s loss=0.565, TAw acc= 81.0% |
| Epoch 198, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.749, TAw acc= 75.6% | Valid: time=  0.4s loss=0.563, TAw acc= 80.8% |
| Epoch 199, lr=9.7e-04 time=  1.2s/  1.6s | Train: loss=0.752, TAw acc= 74.8% | Valid: time=  0.5s loss=0.558, TAw acc= 81.0% |
| Epoch 200, lr=9.7e-04 time=  1.3s/  1.7s | Train: loss=0.754, TAw acc= 74.5% | Valid: time=  0.4s loss=0.557, TAw acc= 80.8% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.611 | TAw acc= 80.2%, forg=  0.0%| TAg acc= 80.2%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  1
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-1): 2 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.495, TAw acc= 45.4% | Valid: time=  0.5s loss=1.253, TAw acc= 54.2% | *
| Epoch   2, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.352, TAw acc= 52.6% | Valid: time=  0.4s loss=1.088, TAw acc= 62.6% | *
| Epoch   3, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=1.313, TAw acc= 54.8% | Valid: time=  0.3s loss=1.081, TAw acc= 61.4% | *
| Epoch   4, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.296, TAw acc= 54.7% | Valid: time=  0.3s loss=1.043, TAw acc= 64.6% | *
| Epoch   5, lr=2.6e-02 time=  0.8s/  2.3s | Train: loss=1.311, TAw acc= 53.8% | Valid: time=  0.5s loss=1.098, TAw acc= 62.2% |
| Epoch   6, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.280, TAw acc= 55.8% | Valid: time=  0.5s loss=0.999, TAw acc= 65.4% | *
| Epoch   7, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=1.266, TAw acc= 56.0% | Valid: time=  0.4s loss=0.991, TAw acc= 65.2% | *
| Epoch   8, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=1.228, TAw acc= 57.6% | Valid: time=  0.5s loss=1.044, TAw acc= 65.8% |
| Epoch   9, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.240, TAw acc= 56.6% | Valid: time=  0.5s loss=1.040, TAw acc= 64.4% |
| Epoch  10, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.221, TAw acc= 57.5% | Valid: time=  0.4s loss=0.997, TAw acc= 66.0% |
| Epoch  11, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=1.204, TAw acc= 58.2% | Valid: time=  0.3s loss=0.981, TAw acc= 67.0% | *
| Epoch  12, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=1.215, TAw acc= 58.3% | Valid: time=  0.5s loss=0.957, TAw acc= 66.2% | *
| Epoch  13, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.194, TAw acc= 58.4% | Valid: time=  0.5s loss=1.031, TAw acc= 67.0% |
| Epoch  14, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=1.182, TAw acc= 59.1% | Valid: time=  0.5s loss=1.042, TAw acc= 64.8% |
| Epoch  15, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.208, TAw acc= 58.6% | Valid: time=  0.5s loss=0.996, TAw acc= 65.6% |
| Epoch  16, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.169, TAw acc= 60.4% | Valid: time=  0.5s loss=0.991, TAw acc= 66.4% |
| Epoch  17, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=1.175, TAw acc= 59.0% | Valid: time=  0.5s loss=1.021, TAw acc= 66.4% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.170, TAw acc= 59.7% | Valid: time=  0.5s loss=0.969, TAw acc= 68.2% |
| Epoch  19, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.173, TAw acc= 58.8% | Valid: time=  0.4s loss=1.095, TAw acc= 64.2% |
| Epoch  20, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.176, TAw acc= 58.3% | Valid: time=  0.5s loss=1.031, TAw acc= 65.6% |
| Epoch  21, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.158, TAw acc= 59.6% | Valid: time=  0.4s loss=0.937, TAw acc= 67.4% | *
| Epoch  22, lr=2.6e-02 time=  1.1s/  2.0s | Train: loss=1.159, TAw acc= 58.8% | Valid: time=  0.5s loss=0.995, TAw acc= 66.8% |
| Epoch  23, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.166, TAw acc= 58.9% | Valid: time=  0.4s loss=0.982, TAw acc= 66.6% |
| Epoch  24, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.138, TAw acc= 60.9% | Valid: time=  0.5s loss=0.996, TAw acc= 66.0% |
| Epoch  25, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.161, TAw acc= 59.9% | Valid: time=  0.4s loss=0.984, TAw acc= 66.6% |
| Epoch  26, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.155, TAw acc= 60.0% | Valid: time=  0.5s loss=0.946, TAw acc= 67.6% |
| Epoch  27, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.133, TAw acc= 60.8% | Valid: time=  0.5s loss=0.937, TAw acc= 67.6% | *
| Epoch  28, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.148, TAw acc= 60.8% | Valid: time=  0.5s loss=0.936, TAw acc= 68.8% | *
| Epoch  29, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.127, TAw acc= 60.8% | Valid: time=  0.5s loss=0.957, TAw acc= 66.8% |
| Epoch  30, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=1.147, TAw acc= 60.0% | Valid: time=  0.4s loss=1.016, TAw acc= 67.4% |
| Epoch  31, lr=2.6e-02 time=  1.2s/  1.5s | Train: loss=1.112, TAw acc= 61.6% | Valid: time=  0.5s loss=0.995, TAw acc= 67.2% |
| Epoch  32, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.117, TAw acc= 62.2% | Valid: time=  0.5s loss=0.902, TAw acc= 69.4% | *
| Epoch  33, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.119, TAw acc= 61.8% | Valid: time=  0.5s loss=0.962, TAw acc= 68.2% |
| Epoch  34, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.121, TAw acc= 61.9% | Valid: time=  0.5s loss=0.935, TAw acc= 67.2% |
| Epoch  35, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.109, TAw acc= 61.4% | Valid: time=  0.5s loss=1.006, TAw acc= 67.0% |
| Epoch  36, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.103, TAw acc= 62.4% | Valid: time=  0.5s loss=1.015, TAw acc= 68.4% |
| Epoch  37, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.130, TAw acc= 60.9% | Valid: time=  0.5s loss=1.003, TAw acc= 69.0% |
| Epoch  38, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.124, TAw acc= 61.5% | Valid: time=  0.5s loss=0.941, TAw acc= 69.6% |
| Epoch  39, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=1.103, TAw acc= 62.2% | Valid: time=  0.5s loss=0.921, TAw acc= 68.8% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=1.116, TAw acc= 61.4% | Valid: time=  0.4s loss=0.937, TAw acc= 69.0% |
| Epoch  41, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=1.092, TAw acc= 62.5% | Valid: time=  0.5s loss=0.914, TAw acc= 68.6% |
| Epoch  42, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.088, TAw acc= 63.3% | Valid: time=  0.5s loss=0.948, TAw acc= 68.0% |
| Epoch  43, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.091, TAw acc= 62.2% | Valid: time=  0.5s loss=0.932, TAw acc= 68.8% |
| Epoch  44, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.080, TAw acc= 63.2% | Valid: time=  0.4s loss=0.949, TAw acc= 68.0% |
| Epoch  45, lr=2.6e-02 time=  1.3s/  1.1s | Train: loss=1.086, TAw acc= 62.6% | Valid: time=  0.3s loss=0.923, TAw acc= 69.0% |
| Epoch  46, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=1.079, TAw acc= 62.5% | Valid: time=  0.5s loss=0.961, TAw acc= 67.4% |
| Epoch  47, lr=2.6e-02 time=  1.2s/  1.0s | Train: loss=1.077, TAw acc= 62.7% | Valid: time=  0.3s loss=0.941, TAw acc= 70.0% |
| Epoch  48, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=1.071, TAw acc= 63.7% | Valid: time=  0.5s loss=0.913, TAw acc= 69.4% |
| Epoch  49, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.082, TAw acc= 62.8% | Valid: time=  0.3s loss=0.940, TAw acc= 68.2% |
| Epoch  50, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=1.107, TAw acc= 61.9% | Valid: time=  0.3s loss=0.922, TAw acc= 68.6% |
| Epoch  51, lr=2.6e-02 time=  1.0s/  2.2s | Train: loss=1.079, TAw acc= 63.4% | Valid: time=  0.5s loss=0.917, TAw acc= 69.8% |
| Epoch  52, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.058, TAw acc= 63.7% | Valid: time=  0.5s loss=0.977, TAw acc= 68.2% |
| Epoch  53, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.072, TAw acc= 63.7% | Valid: time=  0.4s loss=0.920, TAw acc= 69.8% |
| Epoch  54, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.068, TAw acc= 63.5% | Valid: time=  0.3s loss=0.961, TAw acc= 68.6% |
| Epoch  55, lr=2.6e-02 time=  0.8s/  1.4s | Train: loss=1.067, TAw acc= 62.8% | Valid: time=  0.5s loss=0.945, TAw acc= 69.0% |
| Epoch  56, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=1.080, TAw acc= 62.8% | Valid: time=  0.5s loss=1.007, TAw acc= 67.6% |
| Epoch  57, lr=2.6e-02 time=  1.2s/  1.6s | Train: loss=1.070, TAw acc= 62.6% | Valid: time=  0.3s loss=0.910, TAw acc= 69.2% |
| Epoch  58, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.053, TAw acc= 63.8% | Valid: time=  0.3s loss=0.913, TAw acc= 68.8% |
| Epoch  59, lr=2.6e-02 time=  0.8s/  2.1s | Train: loss=1.054, TAw acc= 64.0% | Valid: time=  0.5s loss=0.945, TAw acc= 67.6% |
| Epoch  60, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=1.045, TAw acc= 63.5% | Valid: time=  0.5s loss=0.955, TAw acc= 67.8% |
| Epoch  61, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.045, TAw acc= 63.6% | Valid: time=  0.3s loss=0.956, TAw acc= 67.0% |
| Epoch  62, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.065, TAw acc= 63.6% | Valid: time=  0.5s loss=0.925, TAw acc= 69.2% | lr=8.8e-03
| Epoch  63, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=1.098, TAw acc= 62.4% | Valid: time=  0.4s loss=0.930, TAw acc= 69.4% |
| Epoch  64, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.104, TAw acc= 62.0% | Valid: time=  0.5s loss=0.920, TAw acc= 68.6% |
| Epoch  65, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.085, TAw acc= 63.0% | Valid: time=  0.4s loss=0.923, TAw acc= 69.6% |
| Epoch  66, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=1.071, TAw acc= 62.9% | Valid: time=  0.4s loss=0.949, TAw acc= 67.2% |
| Epoch  67, lr=8.8e-03 time=  1.1s/  2.3s | Train: loss=1.080, TAw acc= 63.7% | Valid: time=  0.5s loss=0.967, TAw acc= 68.8% |
| Epoch  68, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=1.082, TAw acc= 64.2% | Valid: time=  0.5s loss=0.937, TAw acc= 70.6% |
| Epoch  69, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.075, TAw acc= 62.8% | Valid: time=  0.5s loss=0.977, TAw acc= 70.0% |
| Epoch  70, lr=8.8e-03 time=  1.3s/  1.5s | Train: loss=1.077, TAw acc= 62.4% | Valid: time=  0.4s loss=0.935, TAw acc= 68.6% |
| Epoch  71, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=1.074, TAw acc= 63.3% | Valid: time=  0.3s loss=0.946, TAw acc= 69.0% |
| Epoch  72, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=1.058, TAw acc= 63.8% | Valid: time=  0.5s loss=0.952, TAw acc= 68.6% |
| Epoch  73, lr=8.8e-03 time=  1.2s/  2.0s | Train: loss=1.046, TAw acc= 64.6% | Valid: time=  0.4s loss=0.978, TAw acc= 67.6% |
| Epoch  74, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=1.090, TAw acc= 62.4% | Valid: time=  0.5s loss=0.941, TAw acc= 68.2% |
| Epoch  75, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.061, TAw acc= 63.8% | Valid: time=  0.5s loss=0.894, TAw acc= 69.2% | *
| Epoch  76, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.055, TAw acc= 63.6% | Valid: time=  0.5s loss=0.932, TAw acc= 68.2% |
| Epoch  77, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.062, TAw acc= 64.0% | Valid: time=  0.5s loss=0.924, TAw acc= 68.0% |
| Epoch  78, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.057, TAw acc= 63.6% | Valid: time=  0.5s loss=0.931, TAw acc= 67.8% |
| Epoch  79, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.054, TAw acc= 64.4% | Valid: time=  0.5s loss=0.929, TAw acc= 68.4% |
| Epoch  80, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.047, TAw acc= 64.2% | Valid: time=  0.5s loss=0.924, TAw acc= 68.8% |
| Epoch  81, lr=8.8e-03 time=  1.3s/  1.5s | Train: loss=1.053, TAw acc= 64.5% | Valid: time=  0.5s loss=0.932, TAw acc= 68.6% |
| Epoch  82, lr=8.8e-03 time=  1.3s/  2.1s | Train: loss=1.056, TAw acc= 64.3% | Valid: time=  0.5s loss=0.934, TAw acc= 69.0% |
| Epoch  83, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.048, TAw acc= 64.3% | Valid: time=  0.5s loss=0.935, TAw acc= 68.6% |
| Epoch  84, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=1.059, TAw acc= 64.0% | Valid: time=  0.5s loss=0.919, TAw acc= 69.4% |
| Epoch  85, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=1.061, TAw acc= 63.3% | Valid: time=  0.5s loss=0.913, TAw acc= 69.6% |
| Epoch  86, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.073, TAw acc= 63.3% | Valid: time=  0.4s loss=0.933, TAw acc= 68.6% |
| Epoch  87, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=1.049, TAw acc= 64.3% | Valid: time=  0.4s loss=0.931, TAw acc= 69.0% |
| Epoch  88, lr=8.8e-03 time=  1.2s/  1.9s | Train: loss=1.046, TAw acc= 64.3% | Valid: time=  0.4s loss=0.940, TAw acc= 69.6% |
| Epoch  89, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=1.057, TAw acc= 63.6% | Valid: time=  0.5s loss=0.934, TAw acc= 70.0% |
| Epoch  90, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=1.026, TAw acc= 65.3% | Valid: time=  0.5s loss=0.952, TAw acc= 68.6% |
| Epoch  91, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=1.038, TAw acc= 65.4% | Valid: time=  0.3s loss=0.945, TAw acc= 69.6% |
| Epoch  92, lr=8.8e-03 time=  1.1s/  1.4s | Train: loss=1.051, TAw acc= 64.3% | Valid: time=  0.5s loss=0.938, TAw acc= 69.6% |
| Epoch  93, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.032, TAw acc= 64.7% | Valid: time=  0.5s loss=0.930, TAw acc= 68.6% |
| Epoch  94, lr=8.8e-03 time=  1.2s/  2.2s | Train: loss=1.022, TAw acc= 64.9% | Valid: time=  0.5s loss=0.959, TAw acc= 69.6% |
| Epoch  95, lr=8.8e-03 time=  1.2s/  1.6s | Train: loss=1.018, TAw acc= 66.0% | Valid: time=  0.3s loss=0.908, TAw acc= 70.2% |
| Epoch  96, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.048, TAw acc= 65.0% | Valid: time=  0.5s loss=0.898, TAw acc= 71.4% |
| Epoch  97, lr=8.8e-03 time=  1.3s/  2.1s | Train: loss=1.032, TAw acc= 64.6% | Valid: time=  0.5s loss=0.916, TAw acc= 70.6% |
| Epoch  98, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.047, TAw acc= 65.6% | Valid: time=  0.5s loss=0.920, TAw acc= 69.2% |
| Epoch  99, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.030, TAw acc= 64.6% | Valid: time=  0.5s loss=0.940, TAw acc= 68.6% |
| Epoch 100, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=1.028, TAw acc= 65.0% | Valid: time=  0.5s loss=0.947, TAw acc= 68.6% |
| Epoch 101, lr=8.8e-03 time=  1.2s/  1.4s | Train: loss=1.029, TAw acc= 64.0% | Valid: time=  0.3s loss=0.931, TAw acc= 70.4% |
| Epoch 102, lr=8.8e-03 time=  1.1s/  2.0s | Train: loss=1.018, TAw acc= 65.6% | Valid: time=  0.5s loss=0.916, TAw acc= 69.8% |
| Epoch 103, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=1.022, TAw acc= 65.3% | Valid: time=  0.5s loss=0.942, TAw acc= 69.8% |
| Epoch 104, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=1.036, TAw acc= 64.8% | Valid: time=  0.5s loss=0.930, TAw acc= 69.0% |
| Epoch 105, lr=8.8e-03 time=  1.3s/  2.1s | Train: loss=1.041, TAw acc= 65.0% | Valid: time=  0.4s loss=0.923, TAw acc= 70.2% | lr=2.9e-03
| Epoch 106, lr=2.9e-03 time=  1.1s/  2.0s | Train: loss=1.064, TAw acc= 63.8% | Valid: time=  0.5s loss=0.910, TAw acc= 68.8% |
| Epoch 107, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.049, TAw acc= 64.4% | Valid: time=  0.5s loss=0.940, TAw acc= 68.0% |
| Epoch 108, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=1.054, TAw acc= 63.7% | Valid: time=  0.5s loss=0.927, TAw acc= 67.8% |
| Epoch 109, lr=2.9e-03 time=  1.3s/  2.1s | Train: loss=1.031, TAw acc= 65.0% | Valid: time=  0.5s loss=0.912, TAw acc= 67.4% |
| Epoch 110, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.038, TAw acc= 64.8% | Valid: time=  0.4s loss=0.917, TAw acc= 68.4% |
| Epoch 111, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=1.044, TAw acc= 64.2% | Valid: time=  0.5s loss=0.924, TAw acc= 68.0% |
| Epoch 112, lr=2.9e-03 time=  1.3s/  1.7s | Train: loss=1.043, TAw acc= 63.9% | Valid: time=  0.4s loss=0.907, TAw acc= 67.6% |
| Epoch 113, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=1.059, TAw acc= 64.1% | Valid: time=  0.5s loss=0.918, TAw acc= 68.2% |
| Epoch 114, lr=2.9e-03 time=  1.3s/  2.1s | Train: loss=1.041, TAw acc= 64.4% | Valid: time=  0.5s loss=0.927, TAw acc= 68.0% |
| Epoch 115, lr=2.9e-03 time=  1.3s/  2.1s | Train: loss=1.050, TAw acc= 64.6% | Valid: time=  0.5s loss=0.907, TAw acc= 68.0% |
| Epoch 116, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.059, TAw acc= 64.3% | Valid: time=  0.5s loss=0.931, TAw acc= 68.6% |
| Epoch 117, lr=2.9e-03 time=  1.2s/  1.6s | Train: loss=1.037, TAw acc= 65.2% | Valid: time=  0.5s loss=0.901, TAw acc= 68.2% |
| Epoch 118, lr=2.9e-03 time=  1.2s/  1.0s | Train: loss=1.036, TAw acc= 64.2% | Valid: time=  0.3s loss=0.914, TAw acc= 67.8% |
| Epoch 119, lr=2.9e-03 time=  0.8s/  2.4s | Train: loss=1.034, TAw acc= 64.3% | Valid: time=  0.5s loss=0.906, TAw acc= 69.2% |
| Epoch 120, lr=2.9e-03 time=  1.3s/  1.9s | Train: loss=1.054, TAw acc= 64.7% | Valid: time=  0.5s loss=0.903, TAw acc= 68.6% |
| Epoch 121, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.032, TAw acc= 64.4% | Valid: time=  0.5s loss=0.904, TAw acc= 69.2% |
| Epoch 122, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=1.041, TAw acc= 65.1% | Valid: time=  0.5s loss=0.915, TAw acc= 69.6% |
| Epoch 123, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.039, TAw acc= 64.5% | Valid: time=  0.5s loss=0.913, TAw acc= 69.2% |
| Epoch 124, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.055, TAw acc= 63.7% | Valid: time=  0.5s loss=0.904, TAw acc= 69.0% |
| Epoch 125, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=1.045, TAw acc= 63.9% | Valid: time=  0.5s loss=0.910, TAw acc= 68.8% |
| Epoch 126, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.033, TAw acc= 65.0% | Valid: time=  0.5s loss=0.895, TAw acc= 69.6% |
| Epoch 127, lr=2.9e-03 time=  1.2s/  2.0s | Train: loss=1.027, TAw acc= 65.7% | Valid: time=  0.5s loss=0.901, TAw acc= 69.2% |
| Epoch 128, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.047, TAw acc= 63.9% | Valid: time=  0.5s loss=0.907, TAw acc= 69.2% |
| Epoch 129, lr=2.9e-03 time=  1.3s/  1.8s | Train: loss=1.046, TAw acc= 64.6% | Valid: time=  0.5s loss=0.916, TAw acc= 68.8% |
| Epoch 130, lr=2.9e-03 time=  1.3s/  1.8s | Train: loss=1.029, TAw acc= 65.6% | Valid: time=  0.4s loss=0.908, TAw acc= 69.2% |
| Epoch 131, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=1.055, TAw acc= 64.0% | Valid: time=  0.5s loss=0.909, TAw acc= 69.6% |
| Epoch 132, lr=2.9e-03 time=  1.3s/  1.7s | Train: loss=1.045, TAw acc= 65.3% | Valid: time=  0.4s loss=0.896, TAw acc= 68.8% |
| Epoch 133, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=1.052, TAw acc= 63.2% | Valid: time=  0.5s loss=0.902, TAw acc= 69.2% |
| Epoch 134, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=1.048, TAw acc= 64.7% | Valid: time=  0.5s loss=0.904, TAw acc= 68.2% |
| Epoch 135, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=1.039, TAw acc= 64.1% | Valid: time=  0.5s loss=0.900, TAw acc= 69.0% | lr=9.7e-04
| Epoch 136, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=1.056, TAw acc= 64.6% | Valid: time=  0.5s loss=0.903, TAw acc= 68.6% |
| Epoch 137, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.069, TAw acc= 63.1% | Valid: time=  0.5s loss=0.917, TAw acc= 68.8% |
| Epoch 138, lr=9.7e-04 time=  1.3s/  2.0s | Train: loss=1.048, TAw acc= 64.4% | Valid: time=  0.5s loss=0.922, TAw acc= 68.6% |
| Epoch 139, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.069, TAw acc= 63.5% | Valid: time=  0.5s loss=0.918, TAw acc= 68.6% |
| Epoch 140, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.047, TAw acc= 64.3% | Valid: time=  0.5s loss=0.921, TAw acc= 68.4% |
| Epoch 141, lr=9.7e-04 time=  1.4s/  1.9s | Train: loss=1.045, TAw acc= 63.9% | Valid: time=  0.4s loss=0.923, TAw acc= 68.2% |
| Epoch 142, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.052, TAw acc= 63.8% | Valid: time=  0.5s loss=0.925, TAw acc= 68.0% |
| Epoch 143, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.047, TAw acc= 64.0% | Valid: time=  0.4s loss=0.922, TAw acc= 67.8% |
| Epoch 144, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=1.055, TAw acc= 64.1% | Valid: time=  0.5s loss=0.923, TAw acc= 68.0% |
| Epoch 145, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.049, TAw acc= 64.2% | Valid: time=  0.5s loss=0.925, TAw acc= 68.0% |
| Epoch 146, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.055, TAw acc= 63.9% | Valid: time=  0.5s loss=0.919, TAw acc= 68.4% |
| Epoch 147, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.063, TAw acc= 63.4% | Valid: time=  0.5s loss=0.915, TAw acc= 68.0% |
| Epoch 148, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.060, TAw acc= 64.5% | Valid: time=  0.5s loss=0.905, TAw acc= 69.0% |
| Epoch 149, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.057, TAw acc= 64.3% | Valid: time=  0.5s loss=0.917, TAw acc= 67.8% |
| Epoch 150, lr=9.7e-04 time=  1.3s/  2.1s | Train: loss=1.045, TAw acc= 63.8% | Valid: time=  0.3s loss=0.914, TAw acc= 68.8% |
| Epoch 151, lr=9.7e-04 time=  1.1s/  2.4s | Train: loss=1.037, TAw acc= 64.6% | Valid: time=  0.5s loss=0.912, TAw acc= 68.4% |
| Epoch 152, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.060, TAw acc= 63.5% | Valid: time=  0.5s loss=0.912, TAw acc= 69.0% |
| Epoch 153, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.038, TAw acc= 65.0% | Valid: time=  0.5s loss=0.908, TAw acc= 68.6% |
| Epoch 154, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.018, TAw acc= 65.6% | Valid: time=  0.5s loss=0.908, TAw acc= 69.2% |
| Epoch 155, lr=9.7e-04 time=  1.3s/  1.6s | Train: loss=1.056, TAw acc= 64.3% | Valid: time=  0.5s loss=0.912, TAw acc= 68.6% |
| Epoch 156, lr=9.7e-04 time=  1.3s/  1.7s | Train: loss=1.048, TAw acc= 64.4% | Valid: time=  0.5s loss=0.916, TAw acc= 68.6% |
| Epoch 157, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=1.033, TAw acc= 65.3% | Valid: time=  0.5s loss=0.909, TAw acc= 68.6% |
| Epoch 158, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.035, TAw acc= 64.8% | Valid: time=  0.5s loss=0.917, TAw acc= 68.2% |
| Epoch 159, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.052, TAw acc= 64.8% | Valid: time=  0.5s loss=0.911, TAw acc= 68.6% |
| Epoch 160, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=1.044, TAw acc= 64.7% | Valid: time=  0.4s loss=0.912, TAw acc= 68.2% |
| Epoch 161, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.043, TAw acc= 64.4% | Valid: time=  0.5s loss=0.911, TAw acc= 68.8% |
| Epoch 162, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.021, TAw acc= 65.4% | Valid: time=  0.5s loss=0.909, TAw acc= 68.6% |
| Epoch 163, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.070, TAw acc= 62.7% | Valid: time=  0.5s loss=0.911, TAw acc= 68.8% |
| Epoch 164, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=1.035, TAw acc= 64.4% | Valid: time=  0.5s loss=0.910, TAw acc= 68.0% |
| Epoch 165, lr=9.7e-04 time=  1.2s/  2.1s | Train: loss=1.041, TAw acc= 64.3% | Valid: time=  0.5s loss=0.905, TAw acc= 68.8% | lr=3.2e-04
| Epoch 166, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.066, TAw acc= 63.4% | Valid: time=  0.5s loss=0.897, TAw acc= 69.0% |
| Epoch 167, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=1.045, TAw acc= 64.5% | Valid: time=  0.5s loss=0.899, TAw acc= 69.2% |
| Epoch 168, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.062, TAw acc= 64.0% | Valid: time=  0.5s loss=0.901, TAw acc= 68.6% |
| Epoch 169, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.080, TAw acc= 62.7% | Valid: time=  0.5s loss=0.905, TAw acc= 69.0% |
| Epoch 170, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.043, TAw acc= 64.9% | Valid: time=  0.5s loss=0.905, TAw acc= 68.6% |
| Epoch 171, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.056, TAw acc= 63.7% | Valid: time=  0.5s loss=0.908, TAw acc= 68.8% |
| Epoch 172, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.067, TAw acc= 62.6% | Valid: time=  0.5s loss=0.908, TAw acc= 68.8% |
| Epoch 173, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=1.070, TAw acc= 63.7% | Valid: time=  0.5s loss=0.910, TAw acc= 68.8% |
| Epoch 174, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.056, TAw acc= 64.1% | Valid: time=  0.5s loss=0.913, TAw acc= 68.6% |
| Epoch 175, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.064, TAw acc= 64.3% | Valid: time=  0.5s loss=0.912, TAw acc= 68.4% |
| Epoch 176, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.041, TAw acc= 64.7% | Valid: time=  0.4s loss=0.913, TAw acc= 68.6% |
| Epoch 177, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.067, TAw acc= 63.8% | Valid: time=  0.5s loss=0.913, TAw acc= 68.6% |
| Epoch 178, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.062, TAw acc= 64.0% | Valid: time=  0.4s loss=0.916, TAw acc= 68.4% |
| Epoch 179, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=1.045, TAw acc= 65.2% | Valid: time=  0.4s loss=0.916, TAw acc= 68.0% |
| Epoch 180, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=1.073, TAw acc= 63.1% | Valid: time=  0.5s loss=0.918, TAw acc= 68.0% |
| Epoch 181, lr=3.2e-04 time=  1.3s/  2.1s | Train: loss=1.059, TAw acc= 64.0% | Valid: time=  0.5s loss=0.916, TAw acc= 68.0% |
| Epoch 182, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=1.049, TAw acc= 65.2% | Valid: time=  0.5s loss=0.916, TAw acc= 68.4% |
| Epoch 183, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.038, TAw acc= 65.5% | Valid: time=  0.5s loss=0.915, TAw acc= 68.4% |
| Epoch 184, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.067, TAw acc= 63.4% | Valid: time=  0.5s loss=0.913, TAw acc= 68.4% |
| Epoch 185, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=1.074, TAw acc= 63.4% | Valid: time=  0.4s loss=0.914, TAw acc= 68.2% |
| Epoch 186, lr=3.2e-04 time=  1.2s/  2.4s | Train: loss=1.040, TAw acc= 64.2% | Valid: time=  0.5s loss=0.911, TAw acc= 68.2% |
| Epoch 187, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.036, TAw acc= 65.1% | Valid: time=  0.5s loss=0.912, TAw acc= 68.2% |
| Epoch 188, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.052, TAw acc= 64.8% | Valid: time=  0.5s loss=0.913, TAw acc= 68.2% |
| Epoch 189, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.050, TAw acc= 63.9% | Valid: time=  0.5s loss=0.911, TAw acc= 68.6% |
| Epoch 190, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.060, TAw acc= 64.1% | Valid: time=  0.5s loss=0.912, TAw acc= 68.6% |
| Epoch 191, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.061, TAw acc= 63.4% | Valid: time=  0.5s loss=0.912, TAw acc= 68.6% |
| Epoch 192, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.050, TAw acc= 64.0% | Valid: time=  0.5s loss=0.912, TAw acc= 68.8% |
| Epoch 193, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=1.054, TAw acc= 64.2% | Valid: time=  0.5s loss=0.912, TAw acc= 68.8% |
| Epoch 194, lr=3.2e-04 time=  1.3s/  1.8s | Train: loss=1.045, TAw acc= 63.8% | Valid: time=  0.5s loss=0.912, TAw acc= 68.8% |
| Epoch 195, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=1.044, TAw acc= 64.1% | Valid: time=  0.5s loss=0.912, TAw acc= 68.6% | lr=1.1e-04
| Epoch 196, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=1.073, TAw acc= 63.2% | Valid: time=  0.5s loss=0.895, TAw acc= 69.0% |
| Epoch 197, lr=1.1e-04 time=  1.3s/  2.4s | Train: loss=1.066, TAw acc= 63.5% | Valid: time=  0.5s loss=0.896, TAw acc= 69.2% |
| Epoch 198, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=1.058, TAw acc= 63.9% | Valid: time=  0.5s loss=0.898, TAw acc= 69.2% |
| Epoch 199, lr=1.1e-04 time=  1.3s/  2.4s | Train: loss=1.066, TAw acc= 63.6% | Valid: time=  0.5s loss=0.899, TAw acc= 69.0% |
| Epoch 200, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=1.041, TAw acc= 64.0% | Valid: time=  0.5s loss=0.900, TAw acc= 69.2% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.662 | TAw acc= 79.4%, forg=  0.8%| TAg acc= 65.9%, forg= 14.3% <<<
>>> Test on task  1 : loss=0.944 | TAw acc= 69.0%, forg=  0.0%| TAg acc= 50.0%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  2
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-2): 3 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.128, TAw acc= 61.3% | Valid: time=  0.5s loss=0.730, TAw acc= 74.2% | *
| Epoch   2, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.031, TAw acc= 65.0% | Valid: time=  0.4s loss=0.650, TAw acc= 78.2% | *
| Epoch   3, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.977, TAw acc= 67.2% | Valid: time=  0.5s loss=0.596, TAw acc= 79.8% | *
| Epoch   4, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.975, TAw acc= 66.1% | Valid: time=  0.5s loss=0.614, TAw acc= 77.6% |
| Epoch   5, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.978, TAw acc= 65.9% | Valid: time=  0.5s loss=0.633, TAw acc= 77.2% |
| Epoch   6, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.949, TAw acc= 67.6% | Valid: time=  0.5s loss=0.609, TAw acc= 78.4% |
| Epoch   7, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.928, TAw acc= 69.2% | Valid: time=  0.4s loss=0.531, TAw acc= 81.6% | *
| Epoch   8, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.921, TAw acc= 69.6% | Valid: time=  0.4s loss=0.552, TAw acc= 82.2% |
| Epoch   9, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.913, TAw acc= 68.5% | Valid: time=  0.4s loss=0.525, TAw acc= 82.2% | *
| Epoch  10, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.868, TAw acc= 70.1% | Valid: time=  0.5s loss=0.518, TAw acc= 81.4% | *
| Epoch  11, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.908, TAw acc= 68.6% | Valid: time=  0.4s loss=0.541, TAw acc= 81.8% |
| Epoch  12, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.861, TAw acc= 69.9% | Valid: time=  0.5s loss=0.548, TAw acc= 82.0% |
| Epoch  13, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.876, TAw acc= 69.6% | Valid: time=  0.5s loss=0.521, TAw acc= 82.2% |
| Epoch  14, lr=2.6e-02 time=  1.3s/  1.4s | Train: loss=0.861, TAw acc= 70.6% | Valid: time=  0.4s loss=0.551, TAw acc= 80.6% |
| Epoch  15, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.865, TAw acc= 70.4% | Valid: time=  0.4s loss=0.512, TAw acc= 84.2% | *
| Epoch  16, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.864, TAw acc= 70.8% | Valid: time=  0.4s loss=0.533, TAw acc= 82.2% |
| Epoch  17, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.868, TAw acc= 70.6% | Valid: time=  0.5s loss=0.527, TAw acc= 83.6% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.857, TAw acc= 70.7% | Valid: time=  0.5s loss=0.500, TAw acc= 83.4% | *
| Epoch  19, lr=2.6e-02 time=  1.2s/  1.5s | Train: loss=0.816, TAw acc= 72.4% | Valid: time=  0.5s loss=0.513, TAw acc= 82.2% |
| Epoch  20, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.809, TAw acc= 72.9% | Valid: time=  0.5s loss=0.507, TAw acc= 83.0% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.839, TAw acc= 71.5% | Valid: time=  0.5s loss=0.505, TAw acc= 83.4% |
| Epoch  22, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.840, TAw acc= 71.2% | Valid: time=  0.5s loss=0.518, TAw acc= 82.4% |
| Epoch  23, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.824, TAw acc= 72.2% | Valid: time=  0.5s loss=0.548, TAw acc= 82.2% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.824, TAw acc= 71.8% | Valid: time=  0.5s loss=0.550, TAw acc= 83.2% |
| Epoch  25, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.819, TAw acc= 71.9% | Valid: time=  0.5s loss=0.527, TAw acc= 81.6% |
| Epoch  26, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.801, TAw acc= 72.6% | Valid: time=  0.5s loss=0.517, TAw acc= 82.8% |
| Epoch  27, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.808, TAw acc= 72.5% | Valid: time=  0.5s loss=0.572, TAw acc= 81.6% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.816, TAw acc= 72.2% | Valid: time=  0.5s loss=0.555, TAw acc= 81.4% |
| Epoch  29, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 72.6% | Valid: time=  0.5s loss=0.552, TAw acc= 81.4% |
| Epoch  30, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.788, TAw acc= 72.6% | Valid: time=  0.5s loss=0.529, TAw acc= 82.6% |
| Epoch  31, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.801, TAw acc= 72.2% | Valid: time=  0.4s loss=0.490, TAw acc= 84.8% | *
| Epoch  32, lr=2.6e-02 time=  1.2s/  1.7s | Train: loss=0.808, TAw acc= 71.6% | Valid: time=  0.5s loss=0.551, TAw acc= 81.8% |
| Epoch  33, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.796, TAw acc= 73.0% | Valid: time=  0.4s loss=0.513, TAw acc= 84.2% |
| Epoch  34, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.793, TAw acc= 73.3% | Valid: time=  0.4s loss=0.520, TAw acc= 82.4% |
| Epoch  35, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.792, TAw acc= 73.2% | Valid: time=  0.5s loss=0.515, TAw acc= 84.0% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.799, TAw acc= 73.1% | Valid: time=  0.5s loss=0.545, TAw acc= 82.6% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.806, TAw acc= 73.1% | Valid: time=  0.5s loss=0.583, TAw acc= 80.8% |
| Epoch  38, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.789, TAw acc= 72.6% | Valid: time=  0.4s loss=0.533, TAw acc= 83.2% |
| Epoch  39, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.774, TAw acc= 73.8% | Valid: time=  0.5s loss=0.501, TAw acc= 83.6% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.785, TAw acc= 73.0% | Valid: time=  0.4s loss=0.488, TAw acc= 84.0% | *
| Epoch  41, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.768, TAw acc= 74.3% | Valid: time=  0.5s loss=0.533, TAw acc= 82.4% |
| Epoch  42, lr=2.6e-02 time=  1.2s/  1.5s | Train: loss=0.800, TAw acc= 72.5% | Valid: time=  0.5s loss=0.519, TAw acc= 82.8% |
| Epoch  43, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.806, TAw acc= 72.8% | Valid: time=  0.3s loss=0.576, TAw acc= 82.2% |
| Epoch  44, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.757, TAw acc= 74.4% | Valid: time=  0.5s loss=0.503, TAw acc= 83.6% |
| Epoch  45, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.744, TAw acc= 74.9% | Valid: time=  0.5s loss=0.515, TAw acc= 82.8% |
| Epoch  46, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.766, TAw acc= 73.6% | Valid: time=  0.5s loss=0.566, TAw acc= 81.4% |
| Epoch  47, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.785, TAw acc= 73.2% | Valid: time=  0.5s loss=0.513, TAw acc= 83.6% |
| Epoch  48, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.773, TAw acc= 74.1% | Valid: time=  0.5s loss=0.465, TAw acc= 83.6% | *
| Epoch  49, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.791, TAw acc= 73.2% | Valid: time=  0.4s loss=0.483, TAw acc= 82.8% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.753, TAw acc= 74.6% | Valid: time=  0.5s loss=0.505, TAw acc= 81.6% |
| Epoch  51, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.777, TAw acc= 73.0% | Valid: time=  0.5s loss=0.516, TAw acc= 82.8% |
| Epoch  52, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.758, TAw acc= 75.0% | Valid: time=  0.5s loss=0.520, TAw acc= 83.6% |
| Epoch  53, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.748, TAw acc= 74.2% | Valid: time=  0.5s loss=0.504, TAw acc= 84.0% |
| Epoch  54, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.749, TAw acc= 74.8% | Valid: time=  0.5s loss=0.490, TAw acc= 84.6% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.725, TAw acc= 75.9% | Valid: time=  0.5s loss=0.518, TAw acc= 83.0% |
| Epoch  56, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.768, TAw acc= 73.7% | Valid: time=  0.5s loss=0.546, TAw acc= 83.2% |
| Epoch  57, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.758, TAw acc= 73.9% | Valid: time=  0.5s loss=0.538, TAw acc= 81.8% |
| Epoch  58, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.753, TAw acc= 75.6% | Valid: time=  0.5s loss=0.551, TAw acc= 82.4% |
| Epoch  59, lr=2.6e-02 time=  1.3s/  1.5s | Train: loss=0.749, TAw acc= 74.6% | Valid: time=  0.5s loss=0.524, TAw acc= 82.8% |
| Epoch  60, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.720, TAw acc= 75.7% | Valid: time=  0.5s loss=0.535, TAw acc= 83.6% |
| Epoch  61, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.746, TAw acc= 75.4% | Valid: time=  0.4s loss=0.507, TAw acc= 83.2% |
| Epoch  62, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.717, TAw acc= 75.8% | Valid: time=  0.5s loss=0.523, TAw acc= 82.0% |
| Epoch  63, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.760, TAw acc= 73.6% | Valid: time=  0.4s loss=0.488, TAw acc= 84.0% |
| Epoch  64, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.738, TAw acc= 75.6% | Valid: time=  0.5s loss=0.466, TAw acc= 83.4% |
| Epoch  65, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.746, TAw acc= 74.0% | Valid: time=  0.5s loss=0.489, TAw acc= 83.2% |
| Epoch  66, lr=2.6e-02 time=  1.3s/  1.6s | Train: loss=0.763, TAw acc= 73.3% | Valid: time=  0.4s loss=0.526, TAw acc= 82.8% |
| Epoch  67, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.743, TAw acc= 75.4% | Valid: time=  0.5s loss=0.493, TAw acc= 83.8% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.755, TAw acc= 74.7% | Valid: time=  0.5s loss=0.531, TAw acc= 82.6% |
| Epoch  69, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.743, TAw acc= 75.3% | Valid: time=  0.5s loss=0.532, TAw acc= 83.8% |
| Epoch  70, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.719, TAw acc= 75.9% | Valid: time=  0.4s loss=0.495, TAw acc= 84.4% |
| Epoch  71, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.721, TAw acc= 76.5% | Valid: time=  0.4s loss=0.530, TAw acc= 82.6% |
| Epoch  72, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.732, TAw acc= 75.7% | Valid: time=  0.5s loss=0.447, TAw acc= 84.6% | *
| Epoch  73, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.747, TAw acc= 74.8% | Valid: time=  0.5s loss=0.496, TAw acc= 82.6% |
| Epoch  74, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.720, TAw acc= 76.4% | Valid: time=  0.5s loss=0.469, TAw acc= 84.0% |
| Epoch  75, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.718, TAw acc= 75.4% | Valid: time=  0.5s loss=0.495, TAw acc= 83.6% |
| Epoch  76, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.736, TAw acc= 75.3% | Valid: time=  0.4s loss=0.467, TAw acc= 84.2% |
| Epoch  77, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.737, TAw acc= 75.4% | Valid: time=  0.5s loss=0.481, TAw acc= 85.6% |
| Epoch  78, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.758, TAw acc= 74.8% | Valid: time=  0.3s loss=0.502, TAw acc= 84.4% |
| Epoch  79, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.718, TAw acc= 76.2% | Valid: time=  0.5s loss=0.502, TAw acc= 83.0% |
| Epoch  80, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.733, TAw acc= 74.7% | Valid: time=  0.4s loss=0.469, TAw acc= 84.0% |
| Epoch  81, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.724, TAw acc= 76.4% | Valid: time=  0.5s loss=0.480, TAw acc= 84.0% |
| Epoch  82, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.732, TAw acc= 74.5% | Valid: time=  0.5s loss=0.466, TAw acc= 84.8% |
| Epoch  83, lr=2.6e-02 time=  1.0s/  2.3s | Train: loss=0.711, TAw acc= 75.8% | Valid: time=  0.5s loss=0.486, TAw acc= 83.6% |
| Epoch  84, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.732, TAw acc= 75.8% | Valid: time=  0.4s loss=0.503, TAw acc= 82.4% |
| Epoch  85, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.731, TAw acc= 74.4% | Valid: time=  0.5s loss=0.510, TAw acc= 82.8% |
| Epoch  86, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.717, TAw acc= 76.8% | Valid: time=  0.5s loss=0.491, TAw acc= 83.2% |
| Epoch  87, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.705, TAw acc= 76.5% | Valid: time=  0.5s loss=0.484, TAw acc= 84.0% |
| Epoch  88, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.710, TAw acc= 75.9% | Valid: time=  0.4s loss=0.544, TAw acc= 82.8% |
| Epoch  89, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.692, TAw acc= 76.6% | Valid: time=  0.5s loss=0.499, TAw acc= 85.2% |
| Epoch  90, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.683, TAw acc= 76.3% | Valid: time=  0.5s loss=0.512, TAw acc= 84.2% |
| Epoch  91, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.706, TAw acc= 75.9% | Valid: time=  0.5s loss=0.497, TAw acc= 83.6% |
| Epoch  92, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.723, TAw acc= 75.4% | Valid: time=  0.4s loss=0.487, TAw acc= 84.8% |
| Epoch  93, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.695, TAw acc= 76.7% | Valid: time=  0.5s loss=0.489, TAw acc= 83.2% |
| Epoch  94, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.683, TAw acc= 77.0% | Valid: time=  0.5s loss=0.508, TAw acc= 82.4% |
| Epoch  95, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.687, TAw acc= 77.3% | Valid: time=  0.5s loss=0.490, TAw acc= 83.2% |
| Epoch  96, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.701, TAw acc= 76.8% | Valid: time=  0.5s loss=0.518, TAw acc= 82.6% |
| Epoch  97, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.733, TAw acc= 74.9% | Valid: time=  0.4s loss=0.532, TAw acc= 81.8% |
| Epoch  98, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.687, TAw acc= 76.8% | Valid: time=  0.5s loss=0.517, TAw acc= 83.2% |
| Epoch  99, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.694, TAw acc= 76.3% | Valid: time=  0.5s loss=0.528, TAw acc= 84.8% |
| Epoch 100, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.709, TAw acc= 75.6% | Valid: time=  0.5s loss=0.519, TAw acc= 82.4% |
| Epoch 101, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.702, TAw acc= 76.4% | Valid: time=  0.5s loss=0.557, TAw acc= 82.8% |
| Epoch 102, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 76.3% | Valid: time=  0.5s loss=0.499, TAw acc= 83.4% | lr=8.8e-03
| Epoch 103, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.698, TAw acc= 77.1% | Valid: time=  0.5s loss=0.458, TAw acc= 85.6% |
| Epoch 104, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.695, TAw acc= 76.5% | Valid: time=  0.5s loss=0.456, TAw acc= 84.6% |
| Epoch 105, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.688, TAw acc= 77.3% | Valid: time=  0.5s loss=0.464, TAw acc= 84.4% |
| Epoch 106, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.703, TAw acc= 76.6% | Valid: time=  0.5s loss=0.472, TAw acc= 84.4% |
| Epoch 107, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.694, TAw acc= 77.1% | Valid: time=  0.5s loss=0.480, TAw acc= 83.8% |
| Epoch 108, lr=8.8e-03 time=  1.3s/  1.6s | Train: loss=0.695, TAw acc= 76.8% | Valid: time=  0.3s loss=0.468, TAw acc= 83.6% |
| Epoch 109, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.681, TAw acc= 76.7% | Valid: time=  0.5s loss=0.472, TAw acc= 84.4% |
| Epoch 110, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.685, TAw acc= 76.9% | Valid: time=  0.5s loss=0.452, TAw acc= 85.2% |
| Epoch 111, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.702, TAw acc= 76.2% | Valid: time=  0.5s loss=0.453, TAw acc= 85.6% |
| Epoch 112, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.682, TAw acc= 77.6% | Valid: time=  0.5s loss=0.466, TAw acc= 85.2% |
| Epoch 113, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.679, TAw acc= 78.0% | Valid: time=  0.5s loss=0.476, TAw acc= 84.6% |
| Epoch 114, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.688, TAw acc= 76.5% | Valid: time=  0.5s loss=0.472, TAw acc= 85.6% |
| Epoch 115, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.677, TAw acc= 77.2% | Valid: time=  0.5s loss=0.491, TAw acc= 84.2% |
| Epoch 116, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.674, TAw acc= 78.1% | Valid: time=  0.5s loss=0.474, TAw acc= 85.0% |
| Epoch 117, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.676, TAw acc= 77.9% | Valid: time=  0.5s loss=0.475, TAw acc= 84.4% |
| Epoch 118, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.678, TAw acc= 77.3% | Valid: time=  0.5s loss=0.477, TAw acc= 84.0% |
| Epoch 119, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.683, TAw acc= 77.4% | Valid: time=  0.5s loss=0.475, TAw acc= 84.6% |
| Epoch 120, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.667, TAw acc= 78.4% | Valid: time=  0.5s loss=0.468, TAw acc= 83.2% |
| Epoch 121, lr=8.8e-03 time=  1.4s/  1.9s | Train: loss=0.671, TAw acc= 77.1% | Valid: time=  0.4s loss=0.479, TAw acc= 84.4% |
| Epoch 122, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.671, TAw acc= 77.5% | Valid: time=  0.4s loss=0.488, TAw acc= 83.6% |
| Epoch 123, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.683, TAw acc= 77.0% | Valid: time=  0.5s loss=0.488, TAw acc= 83.4% |
| Epoch 124, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.671, TAw acc= 77.2% | Valid: time=  0.5s loss=0.508, TAw acc= 82.2% |
| Epoch 125, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.646, TAw acc= 78.1% | Valid: time=  0.3s loss=0.494, TAw acc= 84.0% |
| Epoch 126, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.664, TAw acc= 77.9% | Valid: time=  0.4s loss=0.476, TAw acc= 82.6% |
| Epoch 127, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.666, TAw acc= 77.2% | Valid: time=  0.5s loss=0.453, TAw acc= 83.8% |
| Epoch 128, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.676, TAw acc= 77.3% | Valid: time=  0.5s loss=0.461, TAw acc= 84.2% |
| Epoch 129, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.679, TAw acc= 77.2% | Valid: time=  0.5s loss=0.464, TAw acc= 84.2% |
| Epoch 130, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.672, TAw acc= 77.7% | Valid: time=  0.5s loss=0.463, TAw acc= 83.2% |
| Epoch 131, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.652, TAw acc= 78.2% | Valid: time=  0.5s loss=0.453, TAw acc= 84.2% |
| Epoch 132, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.688, TAw acc= 76.9% | Valid: time=  0.5s loss=0.465, TAw acc= 84.0% | lr=2.9e-03
| Epoch 133, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.719, TAw acc= 76.1% | Valid: time=  0.5s loss=0.464, TAw acc= 84.0% |
| Epoch 134, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.720, TAw acc= 75.9% | Valid: time=  0.5s loss=0.466, TAw acc= 84.4% |
| Epoch 135, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.690, TAw acc= 77.2% | Valid: time=  0.5s loss=0.463, TAw acc= 84.4% |
| Epoch 136, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.675, TAw acc= 77.4% | Valid: time=  0.5s loss=0.455, TAw acc= 84.6% |
| Epoch 137, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.687, TAw acc= 77.4% | Valid: time=  0.5s loss=0.459, TAw acc= 84.2% |
| Epoch 138, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.691, TAw acc= 77.0% | Valid: time=  0.5s loss=0.463, TAw acc= 84.4% |
| Epoch 139, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.695, TAw acc= 77.3% | Valid: time=  0.4s loss=0.466, TAw acc= 83.8% |
| Epoch 140, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=0.678, TAw acc= 78.2% | Valid: time=  0.5s loss=0.462, TAw acc= 83.6% |
| Epoch 141, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.690, TAw acc= 77.1% | Valid: time=  0.5s loss=0.471, TAw acc= 84.0% |
| Epoch 142, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.711, TAw acc= 76.6% | Valid: time=  0.5s loss=0.467, TAw acc= 84.2% |
| Epoch 143, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.701, TAw acc= 76.5% | Valid: time=  0.5s loss=0.478, TAw acc= 84.6% |
| Epoch 144, lr=2.9e-03 time=  1.1s/  2.4s | Train: loss=0.674, TAw acc= 77.0% | Valid: time=  0.5s loss=0.472, TAw acc= 84.4% |
| Epoch 145, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.675, TAw acc= 77.2% | Valid: time=  0.5s loss=0.475, TAw acc= 84.4% |
| Epoch 146, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.665, TAw acc= 78.3% | Valid: time=  0.5s loss=0.476, TAw acc= 84.0% |
| Epoch 147, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.685, TAw acc= 77.6% | Valid: time=  0.5s loss=0.467, TAw acc= 84.0% |
| Epoch 148, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.666, TAw acc= 78.6% | Valid: time=  0.5s loss=0.471, TAw acc= 84.8% |
| Epoch 149, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.666, TAw acc= 77.9% | Valid: time=  0.5s loss=0.474, TAw acc= 84.0% |
| Epoch 150, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.683, TAw acc= 76.6% | Valid: time=  0.5s loss=0.470, TAw acc= 84.0% |
| Epoch 151, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.668, TAw acc= 77.4% | Valid: time=  0.5s loss=0.463, TAw acc= 84.2% |
| Epoch 152, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.678, TAw acc= 77.5% | Valid: time=  0.5s loss=0.464, TAw acc= 83.8% |
| Epoch 153, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.654, TAw acc= 78.8% | Valid: time=  0.5s loss=0.471, TAw acc= 84.4% |
| Epoch 154, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=0.655, TAw acc= 78.4% | Valid: time=  0.5s loss=0.457, TAw acc= 84.2% |
| Epoch 155, lr=2.9e-03 time=  1.2s/  1.5s | Train: loss=0.680, TAw acc= 77.6% | Valid: time=  0.4s loss=0.464, TAw acc= 84.0% |
| Epoch 156, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.684, TAw acc= 77.4% | Valid: time=  0.3s loss=0.458, TAw acc= 84.8% |
| Epoch 157, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.672, TAw acc= 78.5% | Valid: time=  0.5s loss=0.469, TAw acc= 84.4% |
| Epoch 158, lr=2.9e-03 time=  1.3s/  1.9s | Train: loss=0.669, TAw acc= 77.2% | Valid: time=  0.4s loss=0.469, TAw acc= 84.8% |
| Epoch 159, lr=2.9e-03 time=  1.1s/  1.5s | Train: loss=0.687, TAw acc= 77.6% | Valid: time=  0.4s loss=0.470, TAw acc= 84.6% |
| Epoch 160, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.691, TAw acc= 77.0% | Valid: time=  0.5s loss=0.465, TAw acc= 85.2% |
| Epoch 161, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.665, TAw acc= 77.8% | Valid: time=  0.5s loss=0.467, TAw acc= 84.4% |
| Epoch 162, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.647, TAw acc= 78.6% | Valid: time=  0.5s loss=0.469, TAw acc= 84.4% | lr=9.7e-04
| Epoch 163, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.745, TAw acc= 74.9% | Valid: time=  0.5s loss=0.453, TAw acc= 84.2% |
| Epoch 164, lr=9.7e-04 time=  1.3s/  2.1s | Train: loss=0.712, TAw acc= 76.2% | Valid: time=  0.4s loss=0.458, TAw acc= 84.4% |
| Epoch 165, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.704, TAw acc= 76.5% | Valid: time=  0.5s loss=0.455, TAw acc= 85.0% |
| Epoch 166, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 76.3% | Valid: time=  0.5s loss=0.454, TAw acc= 84.4% |
| Epoch 167, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.732, TAw acc= 76.0% | Valid: time=  0.4s loss=0.455, TAw acc= 84.6% |
| Epoch 168, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.696, TAw acc= 76.9% | Valid: time=  0.4s loss=0.456, TAw acc= 84.4% |
| Epoch 169, lr=9.7e-04 time=  1.3s/  1.5s | Train: loss=0.701, TAw acc= 77.0% | Valid: time=  0.4s loss=0.457, TAw acc= 84.4% |
| Epoch 170, lr=9.7e-04 time=  1.1s/  1.4s | Train: loss=0.703, TAw acc= 76.6% | Valid: time=  0.4s loss=0.459, TAw acc= 84.6% |
| Epoch 171, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.701, TAw acc= 77.3% | Valid: time=  0.5s loss=0.461, TAw acc= 84.6% |
| Epoch 172, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.691, TAw acc= 77.3% | Valid: time=  0.5s loss=0.467, TAw acc= 84.6% |
| Epoch 173, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.681, TAw acc= 76.9% | Valid: time=  0.4s loss=0.463, TAw acc= 84.4% |
| Epoch 174, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.683, TAw acc= 77.6% | Valid: time=  0.5s loss=0.459, TAw acc= 84.6% |
| Epoch 175, lr=9.7e-04 time=  1.2s/  1.5s | Train: loss=0.701, TAw acc= 76.2% | Valid: time=  0.5s loss=0.464, TAw acc= 84.8% |
| Epoch 176, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.715, TAw acc= 76.5% | Valid: time=  0.5s loss=0.469, TAw acc= 85.0% |
| Epoch 177, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.709, TAw acc= 76.4% | Valid: time=  0.5s loss=0.470, TAw acc= 84.0% |
| Epoch 178, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.677, TAw acc= 77.2% | Valid: time=  0.5s loss=0.472, TAw acc= 84.6% |
| Epoch 179, lr=9.7e-04 time=  1.3s/  2.1s | Train: loss=0.698, TAw acc= 76.9% | Valid: time=  0.4s loss=0.469, TAw acc= 84.4% |
| Epoch 180, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.697, TAw acc= 76.4% | Valid: time=  0.5s loss=0.465, TAw acc= 84.6% |
| Epoch 181, lr=9.7e-04 time=  1.3s/  2.1s | Train: loss=0.681, TAw acc= 77.6% | Valid: time=  0.4s loss=0.463, TAw acc= 84.6% |
| Epoch 182, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.697, TAw acc= 77.2% | Valid: time=  0.5s loss=0.462, TAw acc= 84.6% |
| Epoch 183, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.687, TAw acc= 77.8% | Valid: time=  0.5s loss=0.462, TAw acc= 83.8% |
| Epoch 184, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.679, TAw acc= 77.7% | Valid: time=  0.5s loss=0.463, TAw acc= 84.4% |
| Epoch 185, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.681, TAw acc= 76.5% | Valid: time=  0.5s loss=0.463, TAw acc= 84.2% |
| Epoch 186, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.677, TAw acc= 77.6% | Valid: time=  0.5s loss=0.465, TAw acc= 84.2% |
| Epoch 187, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.668, TAw acc= 78.9% | Valid: time=  0.5s loss=0.466, TAw acc= 84.2% |
| Epoch 188, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.696, TAw acc= 76.9% | Valid: time=  0.5s loss=0.468, TAw acc= 83.8% |
| Epoch 189, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.687, TAw acc= 76.5% | Valid: time=  0.5s loss=0.466, TAw acc= 84.0% |
| Epoch 190, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.673, TAw acc= 78.3% | Valid: time=  0.5s loss=0.468, TAw acc= 84.0% |
| Epoch 191, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.678, TAw acc= 77.6% | Valid: time=  0.4s loss=0.465, TAw acc= 83.8% |
| Epoch 192, lr=9.7e-04 time=  1.3s/  1.9s | Train: loss=0.679, TAw acc= 78.1% | Valid: time=  0.3s loss=0.463, TAw acc= 83.6% | lr=3.2e-04
| Epoch 193, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.712, TAw acc= 75.4% | Valid: time=  0.5s loss=0.447, TAw acc= 84.4% |
| Epoch 194, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.709, TAw acc= 76.3% | Valid: time=  0.5s loss=0.451, TAw acc= 84.4% |
| Epoch 195, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.706, TAw acc= 76.2% | Valid: time=  0.5s loss=0.454, TAw acc= 84.2% |
| Epoch 196, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 77.0% | Valid: time=  0.5s loss=0.455, TAw acc= 84.6% |
| Epoch 197, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.703, TAw acc= 76.8% | Valid: time=  0.5s loss=0.455, TAw acc= 84.8% |
| Epoch 198, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 76.4% | Valid: time=  0.5s loss=0.456, TAw acc= 84.8% |
| Epoch 199, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.712, TAw acc= 75.9% | Valid: time=  0.5s loss=0.456, TAw acc= 85.0% |
| Epoch 200, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=0.725, TAw acc= 75.9% | Valid: time=  0.5s loss=0.457, TAw acc= 85.0% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.668 | TAw acc= 78.4%, forg=  1.8%| TAg acc= 54.0%, forg= 26.2% <<<
>>> Test on task  1 : loss=1.013 | TAw acc= 64.5%, forg=  4.5%| TAg acc= 32.3%, forg= 17.7% <<<
>>> Test on task  2 : loss=0.542 | TAw acc= 82.1%, forg=  0.0%| TAg acc= 64.3%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  3
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.139, TAw acc= 59.6% | Valid: time=  0.5s loss=0.853, TAw acc= 66.4% | *
| Epoch   2, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.044, TAw acc= 63.7% | Valid: time=  0.3s loss=0.729, TAw acc= 73.6% | *
| Epoch   3, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.013, TAw acc= 64.2% | Valid: time=  0.5s loss=0.705, TAw acc= 76.4% | *
| Epoch   4, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.987, TAw acc= 66.0% | Valid: time=  0.5s loss=0.727, TAw acc= 72.8% |
| Epoch   5, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.993, TAw acc= 65.6% | Valid: time=  0.5s loss=0.785, TAw acc= 70.8% |
| Epoch   6, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.970, TAw acc= 65.4% | Valid: time=  0.5s loss=0.742, TAw acc= 71.6% |
| Epoch   7, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.959, TAw acc= 66.5% | Valid: time=  0.5s loss=0.751, TAw acc= 73.0% |
| Epoch   8, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.940, TAw acc= 67.2% | Valid: time=  0.4s loss=0.761, TAw acc= 73.2% |
| Epoch   9, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.907, TAw acc= 69.2% | Valid: time=  0.5s loss=0.669, TAw acc= 76.0% | *
| Epoch  10, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.926, TAw acc= 67.2% | Valid: time=  0.5s loss=0.652, TAw acc= 76.0% | *
| Epoch  11, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.912, TAw acc= 68.1% | Valid: time=  0.5s loss=0.670, TAw acc= 75.8% |
| Epoch  12, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.934, TAw acc= 67.1% | Valid: time=  0.4s loss=0.736, TAw acc= 73.4% |
| Epoch  13, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.897, TAw acc= 68.3% | Valid: time=  0.5s loss=0.715, TAw acc= 74.0% |
| Epoch  14, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.887, TAw acc= 69.3% | Valid: time=  0.5s loss=0.632, TAw acc= 76.6% | *
| Epoch  15, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.891, TAw acc= 68.8% | Valid: time=  0.5s loss=0.719, TAw acc= 74.4% |
| Epoch  16, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.883, TAw acc= 68.8% | Valid: time=  0.5s loss=0.683, TAw acc= 75.8% |
| Epoch  17, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.846, TAw acc= 71.1% | Valid: time=  0.5s loss=0.691, TAw acc= 76.2% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.866, TAw acc= 69.6% | Valid: time=  0.5s loss=0.721, TAw acc= 73.6% |
| Epoch  19, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.859, TAw acc= 70.0% | Valid: time=  0.5s loss=0.704, TAw acc= 77.2% |
| Epoch  20, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.885, TAw acc= 69.3% | Valid: time=  0.4s loss=0.650, TAw acc= 77.2% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.871, TAw acc= 69.7% | Valid: time=  0.5s loss=0.692, TAw acc= 74.6% |
| Epoch  22, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.875, TAw acc= 69.0% | Valid: time=  0.5s loss=0.646, TAw acc= 75.6% |
| Epoch  23, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.847, TAw acc= 71.2% | Valid: time=  0.5s loss=0.637, TAw acc= 76.8% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.873, TAw acc= 69.6% | Valid: time=  0.5s loss=0.692, TAw acc= 73.6% |
| Epoch  25, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.853, TAw acc= 70.2% | Valid: time=  0.5s loss=0.688, TAw acc= 74.2% |
| Epoch  26, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.860, TAw acc= 70.3% | Valid: time=  0.5s loss=0.682, TAw acc= 74.4% |
| Epoch  27, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.828, TAw acc= 71.3% | Valid: time=  0.5s loss=0.664, TAw acc= 76.2% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.858, TAw acc= 69.9% | Valid: time=  0.4s loss=0.668, TAw acc= 74.8% |
| Epoch  29, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.836, TAw acc= 71.5% | Valid: time=  0.5s loss=0.647, TAw acc= 77.6% |
| Epoch  30, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.841, TAw acc= 71.0% | Valid: time=  0.5s loss=0.635, TAw acc= 77.0% |
| Epoch  31, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 72.3% | Valid: time=  0.5s loss=0.635, TAw acc= 77.2% |
| Epoch  32, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.832, TAw acc= 70.2% | Valid: time=  0.5s loss=0.752, TAw acc= 75.0% |
| Epoch  33, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.829, TAw acc= 71.5% | Valid: time=  0.4s loss=0.694, TAw acc= 75.8% |
| Epoch  34, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.818, TAw acc= 71.6% | Valid: time=  0.5s loss=0.652, TAw acc= 76.8% |
| Epoch  35, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.823, TAw acc= 71.2% | Valid: time=  0.5s loss=0.620, TAw acc= 78.0% | *
| Epoch  36, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.824, TAw acc= 71.9% | Valid: time=  0.5s loss=0.625, TAw acc= 77.4% |
| Epoch  37, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.808, TAw acc= 71.3% | Valid: time=  0.5s loss=0.623, TAw acc= 78.0% |
| Epoch  38, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.827, TAw acc= 70.6% | Valid: time=  0.4s loss=0.628, TAw acc= 79.0% |
| Epoch  39, lr=2.6e-02 time=  1.1s/  2.1s | Train: loss=0.833, TAw acc= 70.8% | Valid: time=  0.5s loss=0.676, TAw acc= 75.6% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.835, TAw acc= 70.7% | Valid: time=  0.5s loss=0.662, TAw acc= 75.8% |
| Epoch  41, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.825, TAw acc= 71.0% | Valid: time=  0.5s loss=0.598, TAw acc= 77.8% | *
| Epoch  42, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.846, TAw acc= 70.3% | Valid: time=  0.5s loss=0.651, TAw acc= 76.8% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.818, TAw acc= 71.5% | Valid: time=  0.5s loss=0.622, TAw acc= 75.6% |
| Epoch  44, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 71.8% | Valid: time=  0.5s loss=0.711, TAw acc= 75.8% |
| Epoch  45, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 70.3% | Valid: time=  0.5s loss=0.713, TAw acc= 75.0% |
| Epoch  46, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.820, TAw acc= 71.2% | Valid: time=  0.5s loss=0.651, TAw acc= 76.0% |
| Epoch  47, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.792, TAw acc= 72.7% | Valid: time=  0.5s loss=0.681, TAw acc= 75.4% |
| Epoch  48, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.788, TAw acc= 72.0% | Valid: time=  0.5s loss=0.649, TAw acc= 77.4% |
| Epoch  49, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.796, TAw acc= 73.1% | Valid: time=  0.5s loss=0.649, TAw acc= 76.8% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.806, TAw acc= 71.6% | Valid: time=  0.4s loss=0.695, TAw acc= 75.4% |
| Epoch  51, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.815, TAw acc= 71.3% | Valid: time=  0.4s loss=0.683, TAw acc= 74.8% |
| Epoch  52, lr=2.6e-02 time=  1.1s/  1.4s | Train: loss=0.839, TAw acc= 70.7% | Valid: time=  0.4s loss=0.696, TAw acc= 76.4% |
| Epoch  53, lr=2.6e-02 time=  1.1s/  2.1s | Train: loss=0.808, TAw acc= 71.2% | Valid: time=  0.5s loss=0.653, TAw acc= 77.0% |
| Epoch  54, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.775, TAw acc= 72.7% | Valid: time=  0.5s loss=0.681, TAw acc= 77.6% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.793, TAw acc= 72.5% | Valid: time=  0.5s loss=0.623, TAw acc= 78.0% |
| Epoch  56, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.784, TAw acc= 73.0% | Valid: time=  0.5s loss=0.655, TAw acc= 76.8% |
| Epoch  57, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.777, TAw acc= 73.2% | Valid: time=  0.4s loss=0.661, TAw acc= 76.0% |
| Epoch  58, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.779, TAw acc= 73.8% | Valid: time=  0.5s loss=0.610, TAw acc= 77.4% |
| Epoch  59, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.780, TAw acc= 73.3% | Valid: time=  0.4s loss=0.674, TAw acc= 75.6% |
| Epoch  60, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.794, TAw acc= 72.2% | Valid: time=  0.5s loss=0.636, TAw acc= 77.4% |
| Epoch  61, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.792, TAw acc= 72.5% | Valid: time=  0.5s loss=0.634, TAw acc= 77.6% |
| Epoch  62, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.783, TAw acc= 72.7% | Valid: time=  0.5s loss=0.663, TAw acc= 75.8% |
| Epoch  63, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.790, TAw acc= 72.4% | Valid: time=  0.5s loss=0.708, TAw acc= 75.8% |
| Epoch  64, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.782, TAw acc= 71.7% | Valid: time=  0.5s loss=0.655, TAw acc= 76.4% |
| Epoch  65, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.763, TAw acc= 73.4% | Valid: time=  0.5s loss=0.610, TAw acc= 78.2% |
| Epoch  66, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.780, TAw acc= 72.5% | Valid: time=  0.5s loss=0.629, TAw acc= 77.4% |
| Epoch  67, lr=2.6e-02 time=  1.2s/  1.9s | Train: loss=0.797, TAw acc= 71.9% | Valid: time=  0.5s loss=0.672, TAw acc= 76.6% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.767, TAw acc= 73.3% | Valid: time=  0.5s loss=0.602, TAw acc= 79.0% |
| Epoch  69, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.772, TAw acc= 73.0% | Valid: time=  0.5s loss=0.607, TAw acc= 77.4% |
| Epoch  70, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.784, TAw acc= 71.9% | Valid: time=  0.5s loss=0.624, TAw acc= 76.8% |
| Epoch  71, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.761, TAw acc= 72.7% | Valid: time=  0.5s loss=0.641, TAw acc= 77.6% | lr=8.8e-03
| Epoch  72, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.782, TAw acc= 72.6% | Valid: time=  0.5s loss=0.638, TAw acc= 77.8% |
| Epoch  73, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.782, TAw acc= 72.6% | Valid: time=  0.5s loss=0.629, TAw acc= 77.8% |
| Epoch  74, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.795, TAw acc= 72.6% | Valid: time=  0.5s loss=0.614, TAw acc= 78.4% |
| Epoch  75, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.795, TAw acc= 72.4% | Valid: time=  0.5s loss=0.632, TAw acc= 77.8% |
| Epoch  76, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.772, TAw acc= 73.7% | Valid: time=  0.4s loss=0.623, TAw acc= 78.2% |
| Epoch  77, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.772, TAw acc= 73.8% | Valid: time=  0.5s loss=0.626, TAw acc= 78.2% |
| Epoch  78, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.760, TAw acc= 72.9% | Valid: time=  0.5s loss=0.609, TAw acc= 78.8% |
| Epoch  79, lr=8.8e-03 time=  1.3s/  1.5s | Train: loss=0.744, TAw acc= 75.1% | Valid: time=  0.5s loss=0.636, TAw acc= 77.2% |
| Epoch  80, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.762, TAw acc= 74.1% | Valid: time=  0.5s loss=0.622, TAw acc= 78.4% |
| Epoch  81, lr=8.8e-03 time=  1.3s/  1.6s | Train: loss=0.767, TAw acc= 73.6% | Valid: time=  0.4s loss=0.622, TAw acc= 78.0% |
| Epoch  82, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.765, TAw acc= 75.0% | Valid: time=  0.5s loss=0.596, TAw acc= 78.0% | *
| Epoch  83, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.806, TAw acc= 72.1% | Valid: time=  0.5s loss=0.618, TAw acc= 79.0% |
| Epoch  84, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.768, TAw acc= 72.8% | Valid: time=  0.5s loss=0.605, TAw acc= 78.6% |
| Epoch  85, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.753, TAw acc= 74.0% | Valid: time=  0.5s loss=0.610, TAw acc= 78.2% |
| Epoch  86, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.763, TAw acc= 74.0% | Valid: time=  0.5s loss=0.594, TAw acc= 79.2% | *
| Epoch  87, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.762, TAw acc= 73.6% | Valid: time=  0.5s loss=0.601, TAw acc= 79.6% |
| Epoch  88, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.760, TAw acc= 73.5% | Valid: time=  0.5s loss=0.643, TAw acc= 77.0% |
| Epoch  89, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.753, TAw acc= 73.9% | Valid: time=  0.3s loss=0.625, TAw acc= 77.6% |
| Epoch  90, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.761, TAw acc= 74.2% | Valid: time=  0.5s loss=0.607, TAw acc= 78.8% |
| Epoch  91, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.742, TAw acc= 74.3% | Valid: time=  0.5s loss=0.614, TAw acc= 78.6% |
| Epoch  92, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.743, TAw acc= 74.8% | Valid: time=  0.5s loss=0.630, TAw acc= 77.6% |
| Epoch  93, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.751, TAw acc= 74.6% | Valid: time=  0.4s loss=0.639, TAw acc= 78.0% |
| Epoch  94, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.735, TAw acc= 74.6% | Valid: time=  0.5s loss=0.620, TAw acc= 78.6% |
| Epoch  95, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.738, TAw acc= 74.6% | Valid: time=  0.5s loss=0.642, TAw acc= 78.0% |
| Epoch  96, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.753, TAw acc= 74.6% | Valid: time=  0.5s loss=0.597, TAw acc= 78.6% |
| Epoch  97, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.747, TAw acc= 74.5% | Valid: time=  0.5s loss=0.614, TAw acc= 78.8% |
| Epoch  98, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.745, TAw acc= 74.5% | Valid: time=  0.5s loss=0.621, TAw acc= 78.0% |
| Epoch  99, lr=8.8e-03 time=  1.3s/  1.9s | Train: loss=0.770, TAw acc= 73.7% | Valid: time=  0.3s loss=0.632, TAw acc= 77.8% |
| Epoch 100, lr=8.8e-03 time=  1.0s/  1.9s | Train: loss=0.763, TAw acc= 73.4% | Valid: time=  0.4s loss=0.625, TAw acc= 78.0% |
| Epoch 101, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.740, TAw acc= 75.0% | Valid: time=  0.5s loss=0.622, TAw acc= 78.6% |
| Epoch 102, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.741, TAw acc= 74.3% | Valid: time=  0.5s loss=0.607, TAw acc= 77.6% |
| Epoch 103, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.756, TAw acc= 73.9% | Valid: time=  0.5s loss=0.622, TAw acc= 78.2% |
| Epoch 104, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.747, TAw acc= 74.3% | Valid: time=  0.5s loss=0.610, TAw acc= 79.2% |
| Epoch 105, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.728, TAw acc= 75.4% | Valid: time=  0.5s loss=0.640, TAw acc= 77.4% |
| Epoch 106, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.735, TAw acc= 74.6% | Valid: time=  0.5s loss=0.621, TAw acc= 78.6% |
| Epoch 107, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.745, TAw acc= 74.5% | Valid: time=  0.5s loss=0.603, TAw acc= 79.4% |
| Epoch 108, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.736, TAw acc= 75.2% | Valid: time=  0.5s loss=0.599, TAw acc= 79.4% |
| Epoch 109, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.754, TAw acc= 74.5% | Valid: time=  0.5s loss=0.606, TAw acc= 78.2% |
| Epoch 110, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.750, TAw acc= 74.2% | Valid: time=  0.5s loss=0.622, TAw acc= 78.2% |
| Epoch 111, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 74.8% | Valid: time=  0.5s loss=0.605, TAw acc= 78.0% |
| Epoch 112, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.742, TAw acc= 74.8% | Valid: time=  0.5s loss=0.675, TAw acc= 74.2% |
| Epoch 113, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.713, TAw acc= 75.5% | Valid: time=  0.5s loss=0.614, TAw acc= 79.4% |
| Epoch 114, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.740, TAw acc= 73.5% | Valid: time=  0.5s loss=0.619, TAw acc= 78.2% |
| Epoch 115, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.745, TAw acc= 74.6% | Valid: time=  0.5s loss=0.611, TAw acc= 78.0% |
| Epoch 116, lr=8.8e-03 time=  1.2s/  1.8s | Train: loss=0.740, TAw acc= 74.3% | Valid: time=  0.5s loss=0.613, TAw acc= 79.4% | lr=2.9e-03
| Epoch 117, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.750, TAw acc= 74.3% | Valid: time=  0.5s loss=0.612, TAw acc= 78.6% |
| Epoch 118, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.756, TAw acc= 74.4% | Valid: time=  0.5s loss=0.612, TAw acc= 78.4% |
| Epoch 119, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.755, TAw acc= 74.2% | Valid: time=  0.5s loss=0.612, TAw acc= 78.0% |
| Epoch 120, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.751, TAw acc= 74.3% | Valid: time=  0.4s loss=0.611, TAw acc= 78.4% |
| Epoch 121, lr=2.9e-03 time=  1.1s/  2.0s | Train: loss=0.741, TAw acc= 74.7% | Valid: time=  0.5s loss=0.615, TAw acc= 78.2% |
| Epoch 122, lr=2.9e-03 time=  1.2s/  1.5s | Train: loss=0.764, TAw acc= 74.0% | Valid: time=  0.5s loss=0.614, TAw acc= 78.2% |
| Epoch 123, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.749, TAw acc= 74.9% | Valid: time=  0.5s loss=0.613, TAw acc= 77.8% |
| Epoch 124, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.750, TAw acc= 74.2% | Valid: time=  0.5s loss=0.611, TAw acc= 78.2% |
| Epoch 125, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.754, TAw acc= 73.6% | Valid: time=  0.5s loss=0.627, TAw acc= 77.8% |
| Epoch 126, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.728, TAw acc= 75.9% | Valid: time=  0.5s loss=0.614, TAw acc= 78.4% |
| Epoch 127, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.748, TAw acc= 73.1% | Valid: time=  0.5s loss=0.602, TAw acc= 79.0% |
| Epoch 128, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.754, TAw acc= 74.0% | Valid: time=  0.5s loss=0.625, TAw acc= 77.6% |
| Epoch 129, lr=2.9e-03 time=  1.2s/  2.1s | Train: loss=0.750, TAw acc= 74.0% | Valid: time=  0.5s loss=0.616, TAw acc= 78.6% |
| Epoch 130, lr=2.9e-03 time=  1.2s/  2.2s | Train: loss=0.715, TAw acc= 75.2% | Valid: time=  0.5s loss=0.620, TAw acc= 78.2% |
| Epoch 131, lr=2.9e-03 time=  1.3s/  1.8s | Train: loss=0.756, TAw acc= 74.2% | Valid: time=  0.5s loss=0.614, TAw acc= 78.4% |
| Epoch 132, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.762, TAw acc= 74.5% | Valid: time=  0.5s loss=0.596, TAw acc= 78.6% |
| Epoch 133, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.756, TAw acc= 74.9% | Valid: time=  0.5s loss=0.601, TAw acc= 79.0% |
| Epoch 134, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.743, TAw acc= 74.2% | Valid: time=  0.5s loss=0.606, TAw acc= 78.6% |
| Epoch 135, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.747, TAw acc= 74.6% | Valid: time=  0.5s loss=0.607, TAw acc= 78.6% |
| Epoch 136, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.724, TAw acc= 75.4% | Valid: time=  0.5s loss=0.623, TAw acc= 77.8% |
| Epoch 137, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.763, TAw acc= 73.8% | Valid: time=  0.4s loss=0.617, TAw acc= 78.0% |
| Epoch 138, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.740, TAw acc= 74.4% | Valid: time=  0.5s loss=0.605, TAw acc= 78.2% |
| Epoch 139, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.743, TAw acc= 75.0% | Valid: time=  0.5s loss=0.596, TAw acc= 77.8% |
| Epoch 140, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.745, TAw acc= 74.6% | Valid: time=  0.5s loss=0.608, TAw acc= 78.4% |
| Epoch 141, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.751, TAw acc= 73.8% | Valid: time=  0.5s loss=0.600, TAw acc= 78.8% |
| Epoch 142, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 74.9% | Valid: time=  0.5s loss=0.596, TAw acc= 79.6% |
| Epoch 143, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.750, TAw acc= 74.3% | Valid: time=  0.5s loss=0.620, TAw acc= 77.6% |
| Epoch 144, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.763, TAw acc= 73.4% | Valid: time=  0.5s loss=0.610, TAw acc= 78.2% |
| Epoch 145, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.736, TAw acc= 74.1% | Valid: time=  0.5s loss=0.594, TAw acc= 78.6% | *
| Epoch 146, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.731, TAw acc= 74.8% | Valid: time=  0.5s loss=0.606, TAw acc= 78.4% |
| Epoch 147, lr=2.9e-03 time=  1.4s/  1.7s | Train: loss=0.754, TAw acc= 74.1% | Valid: time=  0.4s loss=0.610, TAw acc= 79.6% |
| Epoch 148, lr=2.9e-03 time=  1.1s/  2.1s | Train: loss=0.754, TAw acc= 74.8% | Valid: time=  0.5s loss=0.613, TAw acc= 78.8% |
| Epoch 149, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.747, TAw acc= 74.7% | Valid: time=  0.5s loss=0.610, TAw acc= 78.4% |
| Epoch 150, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.737, TAw acc= 74.7% | Valid: time=  0.5s loss=0.617, TAw acc= 78.2% |
| Epoch 151, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.734, TAw acc= 75.0% | Valid: time=  0.5s loss=0.600, TAw acc= 78.6% |
| Epoch 152, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.754, TAw acc= 73.7% | Valid: time=  0.5s loss=0.609, TAw acc= 79.0% |
| Epoch 153, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.735, TAw acc= 75.4% | Valid: time=  0.5s loss=0.616, TAw acc= 78.0% |
| Epoch 154, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.736, TAw acc= 74.8% | Valid: time=  0.5s loss=0.613, TAw acc= 77.0% |
| Epoch 155, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.739, TAw acc= 75.2% | Valid: time=  0.5s loss=0.606, TAw acc= 78.0% |
| Epoch 156, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 74.2% | Valid: time=  0.5s loss=0.603, TAw acc= 79.2% |
| Epoch 157, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.743, TAw acc= 74.7% | Valid: time=  0.4s loss=0.600, TAw acc= 78.6% |
| Epoch 158, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.735, TAw acc= 75.0% | Valid: time=  0.5s loss=0.595, TAw acc= 78.8% |
| Epoch 159, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.754, TAw acc= 73.8% | Valid: time=  0.5s loss=0.606, TAw acc= 79.0% |
| Epoch 160, lr=2.9e-03 time=  1.4s/  1.8s | Train: loss=0.717, TAw acc= 75.2% | Valid: time=  0.5s loss=0.596, TAw acc= 78.4% |
| Epoch 161, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.733, TAw acc= 75.2% | Valid: time=  0.5s loss=0.604, TAw acc= 79.4% |
| Epoch 162, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.753, TAw acc= 74.4% | Valid: time=  0.5s loss=0.605, TAw acc= 77.8% |
| Epoch 163, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.723, TAw acc= 75.6% | Valid: time=  0.5s loss=0.599, TAw acc= 78.4% |
| Epoch 164, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.729, TAw acc= 75.2% | Valid: time=  0.5s loss=0.602, TAw acc= 78.8% |
| Epoch 165, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.760, TAw acc= 74.0% | Valid: time=  0.5s loss=0.604, TAw acc= 77.2% |
| Epoch 166, lr=2.9e-03 time=  1.4s/  2.0s | Train: loss=0.728, TAw acc= 75.1% | Valid: time=  0.4s loss=0.600, TAw acc= 78.4% |
| Epoch 167, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.733, TAw acc= 74.8% | Valid: time=  0.5s loss=0.606, TAw acc= 78.8% |
| Epoch 168, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.731, TAw acc= 75.5% | Valid: time=  0.5s loss=0.608, TAw acc= 78.0% |
| Epoch 169, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.728, TAw acc= 75.2% | Valid: time=  0.5s loss=0.612, TAw acc= 77.8% |
| Epoch 170, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.737, TAw acc= 74.8% | Valid: time=  0.5s loss=0.605, TAw acc= 77.8% |
| Epoch 171, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.715, TAw acc= 76.1% | Valid: time=  0.5s loss=0.605, TAw acc= 79.0% |
| Epoch 172, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 75.2% | Valid: time=  0.5s loss=0.609, TAw acc= 78.4% |
| Epoch 173, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.717, TAw acc= 75.3% | Valid: time=  0.5s loss=0.608, TAw acc= 78.0% |
| Epoch 174, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.716, TAw acc= 76.1% | Valid: time=  0.5s loss=0.624, TAw acc= 77.2% |
| Epoch 175, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.712, TAw acc= 75.1% | Valid: time=  0.5s loss=0.607, TAw acc= 78.2% | lr=9.7e-04
| Epoch 176, lr=9.7e-04 time=  1.1s/  1.8s | Train: loss=0.740, TAw acc= 74.5% | Valid: time=  0.5s loss=0.592, TAw acc= 79.2% | *
| Epoch 177, lr=9.7e-04 time=  1.3s/  1.9s | Train: loss=0.732, TAw acc= 74.2% | Valid: time=  0.4s loss=0.595, TAw acc= 78.6% |
| Epoch 178, lr=9.7e-04 time=  1.4s/  1.8s | Train: loss=0.738, TAw acc= 74.4% | Valid: time=  0.4s loss=0.601, TAw acc= 78.2% |
| Epoch 179, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.759, TAw acc= 74.2% | Valid: time=  0.5s loss=0.599, TAw acc= 78.6% |
| Epoch 180, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.742, TAw acc= 74.1% | Valid: time=  0.5s loss=0.598, TAw acc= 79.2% |
| Epoch 181, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.719, TAw acc= 75.2% | Valid: time=  0.5s loss=0.605, TAw acc= 78.2% |
| Epoch 182, lr=9.7e-04 time=  1.3s/  1.6s | Train: loss=0.741, TAw acc= 74.9% | Valid: time=  0.3s loss=0.604, TAw acc= 78.8% |
| Epoch 183, lr=9.7e-04 time=  1.2s/  1.3s | Train: loss=0.743, TAw acc= 74.4% | Valid: time=  0.3s loss=0.601, TAw acc= 78.4% |
| Epoch 184, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.736, TAw acc= 74.9% | Valid: time=  0.5s loss=0.604, TAw acc= 78.4% |
| Epoch 185, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.736, TAw acc= 74.9% | Valid: time=  0.5s loss=0.601, TAw acc= 78.4% |
| Epoch 186, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.748, TAw acc= 74.6% | Valid: time=  0.5s loss=0.608, TAw acc= 78.0% |
| Epoch 187, lr=9.7e-04 time=  1.3s/  1.8s | Train: loss=0.744, TAw acc= 74.0% | Valid: time=  0.5s loss=0.609, TAw acc= 78.0% |
| Epoch 188, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.734, TAw acc= 74.9% | Valid: time=  0.5s loss=0.608, TAw acc= 77.8% |
| Epoch 189, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.723, TAw acc= 75.0% | Valid: time=  0.5s loss=0.606, TAw acc= 77.6% |
| Epoch 190, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 75.6% | Valid: time=  0.5s loss=0.607, TAw acc= 77.8% |
| Epoch 191, lr=9.7e-04 time=  1.3s/  2.0s | Train: loss=0.726, TAw acc= 75.1% | Valid: time=  0.4s loss=0.614, TAw acc= 77.6% |
| Epoch 192, lr=9.7e-04 time=  1.2s/  1.6s | Train: loss=0.728, TAw acc= 75.0% | Valid: time=  0.4s loss=0.606, TAw acc= 78.4% |
| Epoch 193, lr=9.7e-04 time=  1.1s/  1.7s | Train: loss=0.733, TAw acc= 75.2% | Valid: time=  0.5s loss=0.608, TAw acc= 78.6% |
| Epoch 194, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.738, TAw acc= 75.0% | Valid: time=  0.5s loss=0.610, TAw acc= 78.2% |
| Epoch 195, lr=9.7e-04 time=  1.1s/  1.9s | Train: loss=0.762, TAw acc= 73.7% | Valid: time=  0.5s loss=0.607, TAw acc= 77.8% |
| Epoch 196, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.731, TAw acc= 75.2% | Valid: time=  0.5s loss=0.603, TAw acc= 77.8% |
| Epoch 197, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 76.0% | Valid: time=  0.5s loss=0.606, TAw acc= 78.2% |
| Epoch 198, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.721, TAw acc= 75.6% | Valid: time=  0.5s loss=0.603, TAw acc= 78.4% |
| Epoch 199, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.715, TAw acc= 75.5% | Valid: time=  0.5s loss=0.604, TAw acc= 78.0% |
| Epoch 200, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.720, TAw acc= 75.9% | Valid: time=  0.5s loss=0.608, TAw acc= 78.2% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.721 | TAw acc= 77.5%, forg=  2.7%| TAg acc= 42.0%, forg= 38.2% <<<
>>> Test on task  1 : loss=1.026 | TAw acc= 66.8%, forg=  2.2%| TAg acc= 25.6%, forg= 24.4% <<<
>>> Test on task  2 : loss=0.560 | TAw acc= 81.8%, forg=  0.3%| TAg acc= 56.5%, forg=  7.8% <<<
>>> Test on task  3 : loss=0.552 | TAw acc= 81.6%, forg=  0.0%| TAg acc= 42.9%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  4
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-4): 5 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.018, TAw acc= 66.2% | Valid: time=  0.5s loss=0.592, TAw acc= 81.0% | *
| Epoch   2, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.938, TAw acc= 67.6% | Valid: time=  0.5s loss=0.603, TAw acc= 82.4% |
| Epoch   3, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.924, TAw acc= 68.1% | Valid: time=  0.5s loss=0.496, TAw acc= 83.6% | *
| Epoch   4, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.899, TAw acc= 68.8% | Valid: time=  0.4s loss=0.519, TAw acc= 84.2% |
| Epoch   5, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.892, TAw acc= 70.5% | Valid: time=  0.5s loss=0.475, TAw acc= 84.4% | *
| Epoch   6, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.861, TAw acc= 70.1% | Valid: time=  0.5s loss=0.451, TAw acc= 85.2% | *
| Epoch   7, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.863, TAw acc= 71.0% | Valid: time=  0.5s loss=0.527, TAw acc= 82.8% |
| Epoch   8, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 72.4% | Valid: time=  0.5s loss=0.495, TAw acc= 84.2% |
| Epoch   9, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.805, TAw acc= 72.8% | Valid: time=  0.5s loss=0.460, TAw acc= 85.4% |
| Epoch  10, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.825, TAw acc= 72.7% | Valid: time=  0.5s loss=0.492, TAw acc= 84.8% |
| Epoch  11, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.810, TAw acc= 73.4% | Valid: time=  0.5s loss=0.450, TAw acc= 84.8% | *
| Epoch  12, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.805, TAw acc= 72.8% | Valid: time=  0.5s loss=0.480, TAw acc= 84.2% |
| Epoch  13, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.798, TAw acc= 72.9% | Valid: time=  0.5s loss=0.444, TAw acc= 86.0% | *
| Epoch  14, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.794, TAw acc= 73.6% | Valid: time=  0.5s loss=0.450, TAw acc= 85.2% |
| Epoch  15, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.817, TAw acc= 72.5% | Valid: time=  0.4s loss=0.431, TAw acc= 88.0% | *
| Epoch  16, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.786, TAw acc= 73.6% | Valid: time=  0.5s loss=0.448, TAw acc= 85.2% |
| Epoch  17, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.777, TAw acc= 74.2% | Valid: time=  0.5s loss=0.434, TAw acc= 85.8% |
| Epoch  18, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.788, TAw acc= 73.9% | Valid: time=  0.5s loss=0.471, TAw acc= 83.0% |
| Epoch  19, lr=2.6e-02 time=  1.0s/  1.6s | Train: loss=0.769, TAw acc= 74.3% | Valid: time=  0.4s loss=0.450, TAw acc= 86.2% |
| Epoch  20, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.785, TAw acc= 73.7% | Valid: time=  0.4s loss=0.464, TAw acc= 84.0% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.768, TAw acc= 74.5% | Valid: time=  0.5s loss=0.475, TAw acc= 83.8% |
| Epoch  22, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.774, TAw acc= 74.4% | Valid: time=  0.5s loss=0.453, TAw acc= 85.2% |
| Epoch  23, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.743, TAw acc= 75.4% | Valid: time=  0.4s loss=0.475, TAw acc= 85.6% |
| Epoch  24, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.742, TAw acc= 75.2% | Valid: time=  0.5s loss=0.444, TAw acc= 86.6% |
| Epoch  25, lr=2.6e-02 time=  1.2s/  1.6s | Train: loss=0.751, TAw acc= 75.1% | Valid: time=  0.5s loss=0.506, TAw acc= 84.6% |
| Epoch  26, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.739, TAw acc= 74.8% | Valid: time=  0.5s loss=0.462, TAw acc= 85.4% |
| Epoch  27, lr=2.6e-02 time=  1.4s/  2.0s | Train: loss=0.762, TAw acc= 74.3% | Valid: time=  0.4s loss=0.445, TAw acc= 85.6% |
| Epoch  28, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.731, TAw acc= 75.6% | Valid: time=  0.4s loss=0.468, TAw acc= 85.6% |
| Epoch  29, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.730, TAw acc= 75.9% | Valid: time=  0.3s loss=0.462, TAw acc= 85.2% |
| Epoch  30, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.756, TAw acc= 74.5% | Valid: time=  0.5s loss=0.451, TAw acc= 85.6% |
| Epoch  31, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.765, TAw acc= 74.8% | Valid: time=  0.5s loss=0.491, TAw acc= 84.4% |
| Epoch  32, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 75.9% | Valid: time=  0.5s loss=0.431, TAw acc= 86.8% |
| Epoch  33, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.741, TAw acc= 75.4% | Valid: time=  0.5s loss=0.484, TAw acc= 85.0% |
| Epoch  34, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.719, TAw acc= 76.2% | Valid: time=  0.5s loss=0.506, TAw acc= 85.0% |
| Epoch  35, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.719, TAw acc= 76.2% | Valid: time=  0.5s loss=0.475, TAw acc= 85.0% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.739, TAw acc= 75.5% | Valid: time=  0.5s loss=0.448, TAw acc= 84.8% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.711, TAw acc= 75.5% | Valid: time=  0.5s loss=0.417, TAw acc= 87.2% | *
| Epoch  38, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.706, TAw acc= 77.0% | Valid: time=  0.5s loss=0.419, TAw acc= 86.4% |
| Epoch  39, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.730, TAw acc= 76.0% | Valid: time=  0.5s loss=0.425, TAw acc= 86.2% |
| Epoch  40, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.761, TAw acc= 73.8% | Valid: time=  0.5s loss=0.474, TAw acc= 85.8% |
| Epoch  41, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=0.702, TAw acc= 76.4% | Valid: time=  0.5s loss=0.404, TAw acc= 87.0% | *
| Epoch  42, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.722, TAw acc= 76.0% | Valid: time=  0.5s loss=0.450, TAw acc= 85.4% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.695, TAw acc= 76.4% | Valid: time=  0.5s loss=0.439, TAw acc= 87.2% |
| Epoch  44, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.701, TAw acc= 76.6% | Valid: time=  0.4s loss=0.469, TAw acc= 85.4% |
| Epoch  45, lr=2.6e-02 time=  1.2s/  1.6s | Train: loss=0.695, TAw acc= 76.4% | Valid: time=  0.4s loss=0.477, TAw acc= 85.6% |
| Epoch  46, lr=2.6e-02 time=  1.1s/  1.5s | Train: loss=0.731, TAw acc= 75.7% | Valid: time=  0.5s loss=0.412, TAw acc= 86.0% |
| Epoch  47, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.692, TAw acc= 77.2% | Valid: time=  0.5s loss=0.401, TAw acc= 87.0% | *
| Epoch  48, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.695, TAw acc= 76.8% | Valid: time=  0.5s loss=0.436, TAw acc= 87.4% |
| Epoch  49, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.684, TAw acc= 77.4% | Valid: time=  0.5s loss=0.467, TAw acc= 86.6% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.707, TAw acc= 76.4% | Valid: time=  0.5s loss=0.414, TAw acc= 87.0% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.681, TAw acc= 77.3% | Valid: time=  0.5s loss=0.441, TAw acc= 86.0% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.689, TAw acc= 77.6% | Valid: time=  0.5s loss=0.516, TAw acc= 85.4% |
| Epoch  53, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.682, TAw acc= 78.0% | Valid: time=  0.5s loss=0.427, TAw acc= 87.6% |
| Epoch  54, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.696, TAw acc= 76.7% | Valid: time=  0.5s loss=0.472, TAw acc= 86.6% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.688, TAw acc= 76.4% | Valid: time=  0.5s loss=0.387, TAw acc= 88.2% | *
| Epoch  56, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.697, TAw acc= 76.7% | Valid: time=  0.5s loss=0.508, TAw acc= 85.2% |
| Epoch  57, lr=2.6e-02 time=  1.4s/  2.5s | Train: loss=0.671, TAw acc= 77.2% | Valid: time=  0.5s loss=0.459, TAw acc= 86.6% |
| Epoch  58, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.675, TAw acc= 77.3% | Valid: time=  0.5s loss=0.477, TAw acc= 86.8% |
| Epoch  59, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.686, TAw acc= 77.2% | Valid: time=  0.4s loss=0.500, TAw acc= 86.8% |
| Epoch  60, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.678, TAw acc= 77.9% | Valid: time=  0.5s loss=0.455, TAw acc= 87.6% |
| Epoch  61, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.685, TAw acc= 76.9% | Valid: time=  0.4s loss=0.473, TAw acc= 86.4% |
| Epoch  62, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.679, TAw acc= 77.7% | Valid: time=  0.4s loss=0.457, TAw acc= 87.6% |
| Epoch  63, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.679, TAw acc= 78.0% | Valid: time=  0.5s loss=0.440, TAw acc= 87.4% |
| Epoch  64, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.668, TAw acc= 77.6% | Valid: time=  0.5s loss=0.420, TAw acc= 87.6% |
| Epoch  65, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.686, TAw acc= 77.6% | Valid: time=  0.5s loss=0.472, TAw acc= 86.6% |
| Epoch  66, lr=2.6e-02 time=  1.1s/  2.3s | Train: loss=0.659, TAw acc= 78.2% | Valid: time=  0.5s loss=0.418, TAw acc= 87.4% |
| Epoch  67, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.677, TAw acc= 77.0% | Valid: time=  0.5s loss=0.432, TAw acc= 87.6% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.655, TAw acc= 78.2% | Valid: time=  0.3s loss=0.420, TAw acc= 87.4% |
| Epoch  69, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.676, TAw acc= 77.5% | Valid: time=  0.5s loss=0.406, TAw acc= 88.4% |
| Epoch  70, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.685, TAw acc= 77.5% | Valid: time=  0.5s loss=0.419, TAw acc= 89.0% |
| Epoch  71, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.671, TAw acc= 77.3% | Valid: time=  0.5s loss=0.451, TAw acc= 87.6% |
| Epoch  72, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.681, TAw acc= 77.7% | Valid: time=  0.5s loss=0.470, TAw acc= 86.6% |
| Epoch  73, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.659, TAw acc= 78.5% | Valid: time=  0.5s loss=0.451, TAw acc= 86.4% |
| Epoch  74, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.659, TAw acc= 77.5% | Valid: time=  0.5s loss=0.449, TAw acc= 87.4% |
| Epoch  75, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.657, TAw acc= 78.1% | Valid: time=  0.5s loss=0.476, TAw acc= 87.0% |
| Epoch  76, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.667, TAw acc= 77.9% | Valid: time=  0.5s loss=0.461, TAw acc= 87.2% |
| Epoch  77, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.659, TAw acc= 78.1% | Valid: time=  0.5s loss=0.458, TAw acc= 86.8% |
| Epoch  78, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.651, TAw acc= 78.8% | Valid: time=  0.5s loss=0.438, TAw acc= 86.2% |
| Epoch  79, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=0.681, TAw acc= 77.6% | Valid: time=  0.5s loss=0.470, TAw acc= 86.2% |
| Epoch  80, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.672, TAw acc= 76.7% | Valid: time=  0.4s loss=0.447, TAw acc= 88.0% |
| Epoch  81, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.644, TAw acc= 78.4% | Valid: time=  0.5s loss=0.447, TAw acc= 87.4% |
| Epoch  82, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.659, TAw acc= 77.9% | Valid: time=  0.5s loss=0.490, TAw acc= 87.4% |
| Epoch  83, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.636, TAw acc= 79.3% | Valid: time=  0.5s loss=0.463, TAw acc= 87.0% |
| Epoch  84, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.657, TAw acc= 78.8% | Valid: time=  0.5s loss=0.444, TAw acc= 86.8% |
| Epoch  85, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.613, TAw acc= 79.4% | Valid: time=  0.5s loss=0.446, TAw acc= 88.4% | lr=8.8e-03
| Epoch  86, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.661, TAw acc= 78.3% | Valid: time=  0.5s loss=0.421, TAw acc= 87.6% |
| Epoch  87, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.654, TAw acc= 78.4% | Valid: time=  0.5s loss=0.417, TAw acc= 87.4% |
| Epoch  88, lr=8.8e-03 time=  1.2s/  2.2s | Train: loss=0.644, TAw acc= 79.2% | Valid: time=  0.5s loss=0.432, TAw acc= 85.6% |
| Epoch  89, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.667, TAw acc= 77.7% | Valid: time=  0.5s loss=0.404, TAw acc= 87.2% |
| Epoch  90, lr=8.8e-03 time=  1.1s/  1.6s | Train: loss=0.662, TAw acc= 78.3% | Valid: time=  0.5s loss=0.429, TAw acc= 86.4% |
| Epoch  91, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.640, TAw acc= 79.9% | Valid: time=  0.5s loss=0.396, TAw acc= 87.0% |
| Epoch  92, lr=8.8e-03 time=  1.4s/  1.7s | Train: loss=0.665, TAw acc= 77.3% | Valid: time=  0.4s loss=0.411, TAw acc= 87.0% |
| Epoch  93, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.640, TAw acc= 79.2% | Valid: time=  0.5s loss=0.423, TAw acc= 87.2% |
| Epoch  94, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.630, TAw acc= 79.9% | Valid: time=  0.5s loss=0.449, TAw acc= 87.2% |
| Epoch  95, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.643, TAw acc= 77.8% | Valid: time=  0.5s loss=0.426, TAw acc= 87.2% |
| Epoch  96, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.641, TAw acc= 78.8% | Valid: time=  0.5s loss=0.416, TAw acc= 87.0% |
| Epoch  97, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.636, TAw acc= 79.2% | Valid: time=  0.5s loss=0.440, TAw acc= 87.4% |
| Epoch  98, lr=8.8e-03 time=  1.4s/  1.6s | Train: loss=0.629, TAw acc= 79.5% | Valid: time=  0.5s loss=0.412, TAw acc= 87.6% |
| Epoch  99, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.653, TAw acc= 78.4% | Valid: time=  0.5s loss=0.417, TAw acc= 86.4% |
| Epoch 100, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.620, TAw acc= 79.5% | Valid: time=  0.5s loss=0.430, TAw acc= 86.8% |
| Epoch 101, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.645, TAw acc= 79.7% | Valid: time=  0.5s loss=0.418, TAw acc= 87.4% |
| Epoch 102, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.642, TAw acc= 79.4% | Valid: time=  0.5s loss=0.418, TAw acc= 87.8% |
| Epoch 103, lr=8.8e-03 time=  1.4s/  1.9s | Train: loss=0.640, TAw acc= 79.3% | Valid: time=  0.5s loss=0.413, TAw acc= 88.6% |
| Epoch 104, lr=8.8e-03 time=  1.2s/  1.6s | Train: loss=0.618, TAw acc= 80.4% | Valid: time=  0.4s loss=0.410, TAw acc= 87.6% |
| Epoch 105, lr=8.8e-03 time=  0.8s/  1.0s | Train: loss=0.636, TAw acc= 79.2% | Valid: time=  0.5s loss=0.419, TAw acc= 87.6% |
| Epoch 106, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.615, TAw acc= 80.0% | Valid: time=  0.5s loss=0.423, TAw acc= 88.0% |
| Epoch 107, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.634, TAw acc= 79.5% | Valid: time=  0.5s loss=0.436, TAw acc= 88.0% |
| Epoch 108, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.616, TAw acc= 79.9% | Valid: time=  0.5s loss=0.409, TAw acc= 87.8% |
| Epoch 109, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.622, TAw acc= 79.7% | Valid: time=  0.5s loss=0.415, TAw acc= 88.6% |
| Epoch 110, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.631, TAw acc= 79.4% | Valid: time=  0.4s loss=0.400, TAw acc= 88.2% |
| Epoch 111, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.617, TAw acc= 80.2% | Valid: time=  0.5s loss=0.429, TAw acc= 87.4% |
| Epoch 112, lr=8.8e-03 time=  1.4s/  1.6s | Train: loss=0.628, TAw acc= 79.8% | Valid: time=  0.4s loss=0.414, TAw acc= 88.4% |
| Epoch 113, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.620, TAw acc= 79.7% | Valid: time=  0.4s loss=0.434, TAw acc= 88.0% |
| Epoch 114, lr=8.8e-03 time=  1.4s/  1.9s | Train: loss=0.613, TAw acc= 80.4% | Valid: time=  0.4s loss=0.445, TAw acc= 86.8% |
| Epoch 115, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.627, TAw acc= 79.6% | Valid: time=  0.5s loss=0.421, TAw acc= 87.6% | lr=2.9e-03
| Epoch 116, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.665, TAw acc= 78.3% | Valid: time=  0.5s loss=0.417, TAw acc= 87.4% |
| Epoch 117, lr=2.9e-03 time=  1.3s/  1.5s | Train: loss=0.660, TAw acc= 78.0% | Valid: time=  0.4s loss=0.421, TAw acc= 86.4% |
| Epoch 118, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.661, TAw acc= 78.0% | Valid: time=  0.5s loss=0.418, TAw acc= 87.0% |
| Epoch 119, lr=2.9e-03 time=  1.4s/  1.5s | Train: loss=0.661, TAw acc= 78.5% | Valid: time=  0.3s loss=0.425, TAw acc= 86.8% |
| Epoch 120, lr=2.9e-03 time=  0.8s/  1.0s | Train: loss=0.669, TAw acc= 78.5% | Valid: time=  0.3s loss=0.420, TAw acc= 87.4% |
| Epoch 121, lr=2.9e-03 time=  0.8s/  1.7s | Train: loss=0.652, TAw acc= 78.8% | Valid: time=  0.3s loss=0.423, TAw acc= 87.0% |
| Epoch 122, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.636, TAw acc= 78.7% | Valid: time=  0.5s loss=0.427, TAw acc= 87.0% |
| Epoch 123, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.651, TAw acc= 78.5% | Valid: time=  0.5s loss=0.432, TAw acc= 86.6% |
| Epoch 124, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.678, TAw acc= 78.9% | Valid: time=  0.5s loss=0.433, TAw acc= 87.0% |
| Epoch 125, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.650, TAw acc= 78.9% | Valid: time=  0.5s loss=0.420, TAw acc= 87.0% |
| Epoch 126, lr=2.9e-03 time=  1.2s/  1.4s | Train: loss=0.681, TAw acc= 77.3% | Valid: time=  0.5s loss=0.434, TAw acc= 86.4% |
| Epoch 127, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.643, TAw acc= 79.9% | Valid: time=  0.5s loss=0.422, TAw acc= 87.4% |
| Epoch 128, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.639, TAw acc= 78.8% | Valid: time=  0.5s loss=0.408, TAw acc= 87.6% |
| Epoch 129, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.632, TAw acc= 80.0% | Valid: time=  0.4s loss=0.428, TAw acc= 86.6% |
| Epoch 130, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.642, TAw acc= 79.0% | Valid: time=  0.5s loss=0.423, TAw acc= 86.8% |
| Epoch 131, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.650, TAw acc= 79.0% | Valid: time=  0.5s loss=0.430, TAw acc= 86.6% |
| Epoch 132, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.639, TAw acc= 79.2% | Valid: time=  0.5s loss=0.428, TAw acc= 87.2% |
| Epoch 133, lr=2.9e-03 time=  1.1s/  1.6s | Train: loss=0.647, TAw acc= 78.9% | Valid: time=  0.4s loss=0.415, TAw acc= 87.6% |
| Epoch 134, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.640, TAw acc= 79.5% | Valid: time=  0.5s loss=0.412, TAw acc= 87.2% |
| Epoch 135, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.630, TAw acc= 79.8% | Valid: time=  0.5s loss=0.423, TAw acc= 86.2% |
| Epoch 136, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.618, TAw acc= 80.0% | Valid: time=  0.5s loss=0.429, TAw acc= 86.6% |
| Epoch 137, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.652, TAw acc= 78.4% | Valid: time=  0.4s loss=0.432, TAw acc= 86.4% |
| Epoch 138, lr=2.9e-03 time=  1.1s/  2.4s | Train: loss=0.642, TAw acc= 78.9% | Valid: time=  0.5s loss=0.428, TAw acc= 87.0% |
| Epoch 139, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.626, TAw acc= 79.9% | Valid: time=  0.5s loss=0.423, TAw acc= 86.6% |
| Epoch 140, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.616, TAw acc= 80.2% | Valid: time=  0.4s loss=0.424, TAw acc= 86.8% |
| Epoch 141, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.634, TAw acc= 80.1% | Valid: time=  0.5s loss=0.435, TAw acc= 86.2% |
| Epoch 142, lr=2.9e-03 time=  1.4s/  2.1s | Train: loss=0.634, TAw acc= 79.3% | Valid: time=  0.4s loss=0.417, TAw acc= 87.0% |
| Epoch 143, lr=2.9e-03 time=  1.3s/  1.6s | Train: loss=0.607, TAw acc= 80.1% | Valid: time=  0.5s loss=0.435, TAw acc= 87.2% |
| Epoch 144, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.623, TAw acc= 79.4% | Valid: time=  0.5s loss=0.413, TAw acc= 87.4% |
| Epoch 145, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.633, TAw acc= 79.8% | Valid: time=  0.5s loss=0.442, TAw acc= 86.6% | lr=9.7e-04
| Epoch 146, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.670, TAw acc= 78.1% | Valid: time=  0.5s loss=0.400, TAw acc= 87.0% |
| Epoch 147, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.669, TAw acc= 77.7% | Valid: time=  0.5s loss=0.405, TAw acc= 87.2% |
| Epoch 148, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.664, TAw acc= 78.4% | Valid: time=  0.5s loss=0.411, TAw acc= 87.2% |
| Epoch 149, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.685, TAw acc= 77.2% | Valid: time=  0.5s loss=0.418, TAw acc= 87.4% |
| Epoch 150, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.650, TAw acc= 79.2% | Valid: time=  0.4s loss=0.414, TAw acc= 86.8% |
| Epoch 151, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.663, TAw acc= 78.7% | Valid: time=  0.5s loss=0.418, TAw acc= 86.8% |
| Epoch 152, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.655, TAw acc= 79.1% | Valid: time=  0.5s loss=0.424, TAw acc= 86.4% |
| Epoch 153, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.666, TAw acc= 78.3% | Valid: time=  0.5s loss=0.418, TAw acc= 87.0% |
| Epoch 154, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.637, TAw acc= 79.5% | Valid: time=  0.5s loss=0.422, TAw acc= 87.2% |
| Epoch 155, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.654, TAw acc= 78.8% | Valid: time=  0.5s loss=0.424, TAw acc= 87.2% |
| Epoch 156, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.648, TAw acc= 79.0% | Valid: time=  0.4s loss=0.418, TAw acc= 87.6% |
| Epoch 157, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.642, TAw acc= 79.3% | Valid: time=  0.5s loss=0.415, TAw acc= 87.4% |
| Epoch 158, lr=9.7e-04 time=  1.1s/  2.4s | Train: loss=0.653, TAw acc= 79.3% | Valid: time=  0.4s loss=0.419, TAw acc= 87.2% |
| Epoch 159, lr=9.7e-04 time=  1.4s/  2.0s | Train: loss=0.644, TAw acc= 78.6% | Valid: time=  0.4s loss=0.415, TAw acc= 87.6% |
| Epoch 160, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.650, TAw acc= 79.4% | Valid: time=  0.5s loss=0.415, TAw acc= 87.0% |
| Epoch 161, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.632, TAw acc= 79.2% | Valid: time=  0.5s loss=0.419, TAw acc= 87.0% |
| Epoch 162, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.650, TAw acc= 79.1% | Valid: time=  0.5s loss=0.418, TAw acc= 87.4% |
| Epoch 163, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.655, TAw acc= 79.3% | Valid: time=  0.5s loss=0.418, TAw acc= 87.4% |
| Epoch 164, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.660, TAw acc= 77.9% | Valid: time=  0.5s loss=0.419, TAw acc= 87.4% |
| Epoch 165, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.654, TAw acc= 79.3% | Valid: time=  0.5s loss=0.424, TAw acc= 87.4% |
| Epoch 166, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.638, TAw acc= 79.4% | Valid: time=  0.5s loss=0.423, TAw acc= 86.8% |
| Epoch 167, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.634, TAw acc= 79.7% | Valid: time=  0.5s loss=0.425, TAw acc= 86.4% |
| Epoch 168, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.643, TAw acc= 78.9% | Valid: time=  0.5s loss=0.421, TAw acc= 86.8% |
| Epoch 169, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.641, TAw acc= 79.0% | Valid: time=  0.5s loss=0.424, TAw acc= 86.6% |
| Epoch 170, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.656, TAw acc= 78.4% | Valid: time=  0.5s loss=0.415, TAw acc= 87.0% |
| Epoch 171, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.626, TAw acc= 79.6% | Valid: time=  0.5s loss=0.416, TAw acc= 87.2% |
| Epoch 172, lr=9.7e-04 time=  1.4s/  2.0s | Train: loss=0.640, TAw acc= 79.5% | Valid: time=  0.5s loss=0.412, TAw acc= 87.0% |
| Epoch 173, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.635, TAw acc= 79.2% | Valid: time=  0.5s loss=0.415, TAw acc= 87.0% |
| Epoch 174, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.643, TAw acc= 78.9% | Valid: time=  0.4s loss=0.418, TAw acc= 86.4% |
| Epoch 175, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.637, TAw acc= 78.9% | Valid: time=  0.5s loss=0.416, TAw acc= 86.4% | lr=3.2e-04
| Epoch 176, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.668, TAw acc= 77.9% | Valid: time=  0.5s loss=0.391, TAw acc= 87.6% |
| Epoch 177, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.681, TAw acc= 77.8% | Valid: time=  0.5s loss=0.395, TAw acc= 87.2% |
| Epoch 178, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.665, TAw acc= 78.1% | Valid: time=  0.5s loss=0.399, TAw acc= 87.0% |
| Epoch 179, lr=3.2e-04 time=  1.4s/  1.9s | Train: loss=0.669, TAw acc= 78.3% | Valid: time=  0.5s loss=0.400, TAw acc= 87.0% |
| Epoch 180, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=0.661, TAw acc= 78.5% | Valid: time=  0.5s loss=0.404, TAw acc= 87.2% |
| Epoch 181, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.669, TAw acc= 78.4% | Valid: time=  0.5s loss=0.408, TAw acc= 87.2% |
| Epoch 182, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.664, TAw acc= 78.6% | Valid: time=  0.5s loss=0.411, TAw acc= 87.2% |
| Epoch 183, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.684, TAw acc= 77.6% | Valid: time=  0.5s loss=0.411, TAw acc= 87.4% |
| Epoch 184, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.648, TAw acc= 79.2% | Valid: time=  0.5s loss=0.413, TAw acc= 87.0% |
| Epoch 185, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.654, TAw acc= 79.0% | Valid: time=  0.5s loss=0.413, TAw acc= 87.2% |
| Epoch 186, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.652, TAw acc= 78.8% | Valid: time=  0.5s loss=0.416, TAw acc= 87.4% |
| Epoch 187, lr=3.2e-04 time=  1.4s/  1.4s | Train: loss=0.668, TAw acc= 77.8% | Valid: time=  0.4s loss=0.416, TAw acc= 87.2% |
| Epoch 188, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.666, TAw acc= 78.5% | Valid: time=  0.5s loss=0.416, TAw acc= 87.4% |
| Epoch 189, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.662, TAw acc= 78.2% | Valid: time=  0.5s loss=0.416, TAw acc= 87.4% |
| Epoch 190, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.658, TAw acc= 78.5% | Valid: time=  0.4s loss=0.419, TAw acc= 87.2% |
| Epoch 191, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.651, TAw acc= 78.5% | Valid: time=  0.5s loss=0.417, TAw acc= 87.2% |
| Epoch 192, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.662, TAw acc= 78.2% | Valid: time=  0.5s loss=0.418, TAw acc= 87.2% |
| Epoch 193, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.668, TAw acc= 78.6% | Valid: time=  0.5s loss=0.420, TAw acc= 87.2% |
| Epoch 194, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.646, TAw acc= 79.4% | Valid: time=  0.5s loss=0.419, TAw acc= 87.4% |
| Epoch 195, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.659, TAw acc= 78.4% | Valid: time=  0.5s loss=0.419, TAw acc= 87.4% |
| Epoch 196, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.664, TAw acc= 78.2% | Valid: time=  0.5s loss=0.420, TAw acc= 87.4% |
| Epoch 197, lr=3.2e-04 time=  1.2s/  2.0s | Train: loss=0.657, TAw acc= 79.1% | Valid: time=  0.5s loss=0.419, TAw acc= 87.6% |
| Epoch 198, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.647, TAw acc= 79.9% | Valid: time=  0.5s loss=0.418, TAw acc= 87.2% |
| Epoch 199, lr=3.2e-04 time=  1.1s/  2.3s | Train: loss=0.680, TAw acc= 77.9% | Valid: time=  0.5s loss=0.419, TAw acc= 87.2% |
| Epoch 200, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.662, TAw acc= 78.0% | Valid: time=  0.5s loss=0.420, TAw acc= 87.4% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.783 | TAw acc= 74.2%, forg=  6.0%| TAg acc= 37.3%, forg= 42.9% <<<
>>> Test on task  1 : loss=1.128 | TAw acc= 63.6%, forg=  5.4%| TAg acc= 18.5%, forg= 31.5% <<<
>>> Test on task  2 : loss=0.598 | TAw acc= 80.5%, forg=  1.6%| TAg acc= 46.3%, forg= 18.0% <<<
>>> Test on task  3 : loss=0.602 | TAw acc= 78.9%, forg=  2.7%| TAg acc= 31.8%, forg= 11.1% <<<
>>> Test on task  4 : loss=0.420 | TAw acc= 87.2%, forg=  0.0%| TAg acc= 59.2%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  5
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-5): 6 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=1.139, TAw acc= 58.7% | Valid: time=  0.5s loss=1.084, TAw acc= 63.0% | *
| Epoch   2, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=1.086, TAw acc= 60.6% | Valid: time=  0.4s loss=0.937, TAw acc= 65.6% | *
| Epoch   3, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.068, TAw acc= 61.8% | Valid: time=  0.4s loss=0.958, TAw acc= 64.8% |
| Epoch   4, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=1.035, TAw acc= 61.9% | Valid: time=  0.5s loss=0.915, TAw acc= 66.6% | *
| Epoch   5, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.997, TAw acc= 64.2% | Valid: time=  0.5s loss=0.937, TAw acc= 65.8% |
| Epoch   6, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.048, TAw acc= 61.2% | Valid: time=  0.5s loss=0.926, TAw acc= 66.4% |
| Epoch   7, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=1.004, TAw acc= 63.4% | Valid: time=  0.5s loss=0.878, TAw acc= 68.6% | *
| Epoch   8, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.976, TAw acc= 64.4% | Valid: time=  0.5s loss=0.934, TAw acc= 67.6% |
| Epoch   9, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.966, TAw acc= 64.4% | Valid: time=  0.5s loss=0.939, TAw acc= 65.8% |
| Epoch  10, lr=2.6e-02 time=  1.2s/  1.8s | Train: loss=0.957, TAw acc= 66.0% | Valid: time=  0.5s loss=0.873, TAw acc= 68.0% | *
| Epoch  11, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.990, TAw acc= 63.3% | Valid: time=  0.4s loss=0.987, TAw acc= 68.0% |
| Epoch  12, lr=2.6e-02 time=  1.4s/  1.9s | Train: loss=0.945, TAw acc= 65.4% | Valid: time=  0.4s loss=0.911, TAw acc= 68.6% |
| Epoch  13, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.950, TAw acc= 64.2% | Valid: time=  0.5s loss=0.914, TAw acc= 66.4% |
| Epoch  14, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.960, TAw acc= 65.2% | Valid: time=  0.4s loss=0.876, TAw acc= 69.0% |
| Epoch  15, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.939, TAw acc= 65.6% | Valid: time=  0.5s loss=0.949, TAw acc= 65.4% |
| Epoch  16, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.944, TAw acc= 66.7% | Valid: time=  0.5s loss=0.866, TAw acc= 66.8% | *
| Epoch  17, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.922, TAw acc= 66.4% | Valid: time=  0.5s loss=0.854, TAw acc= 69.6% | *
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.924, TAw acc= 66.7% | Valid: time=  0.5s loss=0.917, TAw acc= 66.6% |
| Epoch  19, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.940, TAw acc= 66.8% | Valid: time=  0.5s loss=0.873, TAw acc= 70.0% |
| Epoch  20, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.911, TAw acc= 67.2% | Valid: time=  0.5s loss=0.925, TAw acc= 67.8% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.934, TAw acc= 66.1% | Valid: time=  0.5s loss=0.927, TAw acc= 69.0% |
| Epoch  22, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.917, TAw acc= 67.7% | Valid: time=  0.5s loss=0.901, TAw acc= 68.4% |
| Epoch  23, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.912, TAw acc= 66.6% | Valid: time=  0.5s loss=0.930, TAw acc= 66.6% |
| Epoch  24, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.919, TAw acc= 66.5% | Valid: time=  0.5s loss=0.936, TAw acc= 68.6% |
| Epoch  25, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.942, TAw acc= 65.9% | Valid: time=  0.4s loss=0.920, TAw acc= 69.4% |
| Epoch  26, lr=2.6e-02 time=  1.1s/  2.2s | Train: loss=0.885, TAw acc= 68.6% | Valid: time=  0.5s loss=0.944, TAw acc= 66.6% |
| Epoch  27, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.915, TAw acc= 67.3% | Valid: time=  0.5s loss=0.858, TAw acc= 70.6% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.912, TAw acc= 67.3% | Valid: time=  0.5s loss=0.870, TAw acc= 69.8% |
| Epoch  29, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.895, TAw acc= 68.3% | Valid: time=  0.5s loss=0.906, TAw acc= 67.4% |
| Epoch  30, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.911, TAw acc= 67.6% | Valid: time=  0.4s loss=0.833, TAw acc= 70.0% | *
| Epoch  31, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.883, TAw acc= 68.4% | Valid: time=  0.5s loss=0.894, TAw acc= 68.4% |
| Epoch  32, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.894, TAw acc= 67.5% | Valid: time=  0.4s loss=0.844, TAw acc= 70.4% |
| Epoch  33, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.884, TAw acc= 69.0% | Valid: time=  0.5s loss=0.889, TAw acc= 70.0% |
| Epoch  34, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.876, TAw acc= 69.6% | Valid: time=  0.5s loss=0.875, TAw acc= 69.8% |
| Epoch  35, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.883, TAw acc= 68.3% | Valid: time=  0.4s loss=0.876, TAw acc= 69.2% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.880, TAw acc= 68.7% | Valid: time=  0.5s loss=0.877, TAw acc= 69.0% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.885, TAw acc= 69.2% | Valid: time=  0.4s loss=0.883, TAw acc= 72.2% |
| Epoch  38, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.923, TAw acc= 67.5% | Valid: time=  0.5s loss=0.932, TAw acc= 68.2% |
| Epoch  39, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.876, TAw acc= 69.2% | Valid: time=  0.5s loss=0.941, TAw acc= 68.6% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.861, TAw acc= 69.3% | Valid: time=  0.4s loss=0.884, TAw acc= 69.0% |
| Epoch  41, lr=2.6e-02 time=  1.0s/  2.4s | Train: loss=0.856, TAw acc= 70.2% | Valid: time=  0.4s loss=0.886, TAw acc= 70.2% |
| Epoch  42, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=0.874, TAw acc= 69.7% | Valid: time=  0.3s loss=0.892, TAw acc= 71.0% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.849, TAw acc= 70.6% | Valid: time=  0.5s loss=0.873, TAw acc= 69.4% |
| Epoch  44, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.851, TAw acc= 69.5% | Valid: time=  0.4s loss=0.885, TAw acc= 70.8% |
| Epoch  45, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.873, TAw acc= 68.8% | Valid: time=  0.5s loss=0.842, TAw acc= 71.6% |
| Epoch  46, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.857, TAw acc= 69.5% | Valid: time=  0.5s loss=0.863, TAw acc= 72.6% |
| Epoch  47, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.867, TAw acc= 67.9% | Valid: time=  0.5s loss=0.954, TAw acc= 69.4% |
| Epoch  48, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.858, TAw acc= 69.8% | Valid: time=  0.5s loss=0.887, TAw acc= 71.8% |
| Epoch  49, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.875, TAw acc= 68.5% | Valid: time=  0.5s loss=0.907, TAw acc= 71.2% |
| Epoch  50, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.884, TAw acc= 67.2% | Valid: time=  0.5s loss=0.922, TAw acc= 69.4% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.894, TAw acc= 68.4% | Valid: time=  0.5s loss=0.930, TAw acc= 69.6% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.835, TAw acc= 70.4% | Valid: time=  0.5s loss=0.890, TAw acc= 71.0% |
| Epoch  53, lr=2.6e-02 time=  1.2s/  1.7s | Train: loss=0.825, TAw acc= 70.5% | Valid: time=  0.5s loss=0.916, TAw acc= 70.0% |
| Epoch  54, lr=2.6e-02 time=  1.4s/  1.9s | Train: loss=0.828, TAw acc= 70.4% | Valid: time=  0.3s loss=0.942, TAw acc= 67.8% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.859, TAw acc= 68.9% | Valid: time=  0.5s loss=0.920, TAw acc= 71.4% |
| Epoch  56, lr=2.6e-02 time=  1.4s/  1.9s | Train: loss=0.833, TAw acc= 70.6% | Valid: time=  0.5s loss=0.906, TAw acc= 70.6% |
| Epoch  57, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.851, TAw acc= 70.0% | Valid: time=  0.5s loss=0.910, TAw acc= 71.6% |
| Epoch  58, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.825, TAw acc= 71.1% | Valid: time=  0.5s loss=0.899, TAw acc= 70.6% |
| Epoch  59, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.823, TAw acc= 70.6% | Valid: time=  0.3s loss=0.966, TAw acc= 68.2% |
| Epoch  60, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=0.842, TAw acc= 69.8% | Valid: time=  0.5s loss=0.879, TAw acc= 69.8% | lr=8.8e-03
| Epoch  61, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.855, TAw acc= 69.9% | Valid: time=  0.5s loss=0.855, TAw acc= 69.4% |
| Epoch  62, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.862, TAw acc= 69.4% | Valid: time=  0.5s loss=0.852, TAw acc= 70.4% |
| Epoch  63, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.872, TAw acc= 69.3% | Valid: time=  0.5s loss=0.849, TAw acc= 72.0% |
| Epoch  64, lr=8.8e-03 time=  1.3s/  1.6s | Train: loss=0.848, TAw acc= 70.2% | Valid: time=  0.5s loss=0.883, TAw acc= 70.6% |
| Epoch  65, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.859, TAw acc= 69.3% | Valid: time=  0.5s loss=0.849, TAw acc= 71.4% |
| Epoch  66, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.857, TAw acc= 70.5% | Valid: time=  0.5s loss=0.875, TAw acc= 69.4% |
| Epoch  67, lr=8.8e-03 time=  1.2s/  1.6s | Train: loss=0.852, TAw acc= 69.8% | Valid: time=  0.4s loss=0.851, TAw acc= 71.0% |
| Epoch  68, lr=8.8e-03 time=  1.2s/  2.2s | Train: loss=0.843, TAw acc= 69.9% | Valid: time=  0.5s loss=0.883, TAw acc= 71.2% |
| Epoch  69, lr=8.8e-03 time=  1.3s/  1.8s | Train: loss=0.859, TAw acc= 69.8% | Valid: time=  0.3s loss=0.841, TAw acc= 71.6% |
| Epoch  70, lr=8.8e-03 time=  0.8s/  2.1s | Train: loss=0.847, TAw acc= 69.8% | Valid: time=  0.5s loss=0.844, TAw acc= 70.4% |
| Epoch  71, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 70.0% | Valid: time=  0.4s loss=0.863, TAw acc= 70.4% |
| Epoch  72, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.832, TAw acc= 70.6% | Valid: time=  0.4s loss=0.848, TAw acc= 70.6% |
| Epoch  73, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.840, TAw acc= 69.5% | Valid: time=  0.5s loss=0.884, TAw acc= 70.0% |
| Epoch  74, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.836, TAw acc= 70.0% | Valid: time=  0.5s loss=0.851, TAw acc= 70.6% |
| Epoch  75, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.845, TAw acc= 69.6% | Valid: time=  0.5s loss=0.896, TAw acc= 69.6% |
| Epoch  76, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.835, TAw acc= 70.2% | Valid: time=  0.5s loss=0.879, TAw acc= 71.0% |
| Epoch  77, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.842, TAw acc= 70.2% | Valid: time=  0.5s loss=0.885, TAw acc= 71.2% |
| Epoch  78, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.842, TAw acc= 68.9% | Valid: time=  0.5s loss=0.870, TAw acc= 71.0% |
| Epoch  79, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.845, TAw acc= 70.4% | Valid: time=  0.5s loss=0.897, TAw acc= 70.4% |
| Epoch  80, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.826, TAw acc= 71.4% | Valid: time=  0.5s loss=0.865, TAw acc= 71.2% |
| Epoch  81, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.819, TAw acc= 71.0% | Valid: time=  0.5s loss=0.892, TAw acc= 71.2% |
| Epoch  82, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.830, TAw acc= 70.8% | Valid: time=  0.5s loss=0.813, TAw acc= 72.0% | *
| Epoch  83, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.817, TAw acc= 70.9% | Valid: time=  0.5s loss=0.887, TAw acc= 69.8% |
| Epoch  84, lr=8.8e-03 time=  1.2s/  2.1s | Train: loss=0.838, TAw acc= 69.9% | Valid: time=  0.5s loss=0.842, TAw acc= 71.8% |
| Epoch  85, lr=8.8e-03 time=  1.7s/  2.3s | Train: loss=0.826, TAw acc= 70.5% | Valid: time=  0.5s loss=0.846, TAw acc= 72.4% |
| Epoch  86, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 70.4% | Valid: time=  0.5s loss=0.859, TAw acc= 71.2% |
| Epoch  87, lr=8.8e-03 time=  1.4s/  1.7s | Train: loss=0.814, TAw acc= 71.3% | Valid: time=  0.5s loss=0.860, TAw acc= 72.0% |
| Epoch  88, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.828, TAw acc= 71.9% | Valid: time=  0.5s loss=0.877, TAw acc= 70.4% |
| Epoch  89, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.818, TAw acc= 71.6% | Valid: time=  0.5s loss=0.863, TAw acc= 71.0% |
| Epoch  90, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.816, TAw acc= 70.7% | Valid: time=  0.5s loss=0.860, TAw acc= 71.6% |
| Epoch  91, lr=8.8e-03 time=  1.1s/  1.4s | Train: loss=0.820, TAw acc= 71.2% | Valid: time=  0.4s loss=0.827, TAw acc= 72.8% |
| Epoch  92, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.816, TAw acc= 70.8% | Valid: time=  0.5s loss=0.856, TAw acc= 71.4% |
| Epoch  93, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 70.5% | Valid: time=  0.4s loss=0.886, TAw acc= 71.2% |
| Epoch  94, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.801, TAw acc= 72.5% | Valid: time=  0.5s loss=0.873, TAw acc= 71.0% |
| Epoch  95, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 71.0% | Valid: time=  0.4s loss=0.858, TAw acc= 72.0% |
| Epoch  96, lr=8.8e-03 time=  1.2s/  1.7s | Train: loss=0.827, TAw acc= 71.2% | Valid: time=  0.5s loss=0.862, TAw acc= 71.6% |
| Epoch  97, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.801, TAw acc= 71.8% | Valid: time=  0.5s loss=0.871, TAw acc= 70.4% |
| Epoch  98, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.797, TAw acc= 71.8% | Valid: time=  0.5s loss=0.867, TAw acc= 70.2% |
| Epoch  99, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 70.8% | Valid: time=  0.5s loss=0.899, TAw acc= 68.8% |
| Epoch 100, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.800, TAw acc= 71.8% | Valid: time=  0.4s loss=0.885, TAw acc= 70.8% |
| Epoch 101, lr=8.8e-03 time=  1.0s/  1.5s | Train: loss=0.789, TAw acc= 71.9% | Valid: time=  0.4s loss=0.854, TAw acc= 71.6% |
| Epoch 102, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.800, TAw acc= 72.4% | Valid: time=  0.5s loss=0.831, TAw acc= 73.4% |
| Epoch 103, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.831, TAw acc= 70.5% | Valid: time=  0.5s loss=0.879, TAw acc= 71.4% |
| Epoch 104, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.805, TAw acc= 71.6% | Valid: time=  0.5s loss=0.868, TAw acc= 71.0% |
| Epoch 105, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.788, TAw acc= 72.0% | Valid: time=  0.5s loss=0.883, TAw acc= 70.0% |
| Epoch 106, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.788, TAw acc= 72.4% | Valid: time=  0.5s loss=0.866, TAw acc= 70.8% |
| Epoch 107, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.794, TAw acc= 72.3% | Valid: time=  0.5s loss=0.857, TAw acc= 71.6% |
| Epoch 108, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 71.8% | Valid: time=  0.5s loss=0.853, TAw acc= 71.6% |
| Epoch 109, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.791, TAw acc= 72.0% | Valid: time=  0.5s loss=0.917, TAw acc= 69.0% |
| Epoch 110, lr=8.8e-03 time=  1.4s/  1.5s | Train: loss=0.787, TAw acc= 72.1% | Valid: time=  0.4s loss=0.859, TAw acc= 72.4% |
| Epoch 111, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.795, TAw acc= 72.3% | Valid: time=  0.5s loss=0.847, TAw acc= 72.0% |
| Epoch 112, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.795, TAw acc= 71.8% | Valid: time=  0.5s loss=0.901, TAw acc= 70.4% | lr=2.9e-03
| Epoch 113, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.831, TAw acc= 71.2% | Valid: time=  0.5s loss=0.855, TAw acc= 72.8% |
| Epoch 114, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.825, TAw acc= 70.9% | Valid: time=  0.5s loss=0.862, TAw acc= 72.4% |
| Epoch 115, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 71.1% | Valid: time=  0.5s loss=0.860, TAw acc= 71.0% |
| Epoch 116, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.829, TAw acc= 70.7% | Valid: time=  0.5s loss=0.854, TAw acc= 72.8% |
| Epoch 117, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 71.1% | Valid: time=  0.5s loss=0.862, TAw acc= 71.6% |
| Epoch 118, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 71.4% | Valid: time=  0.5s loss=0.857, TAw acc= 72.0% |
| Epoch 119, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 71.8% | Valid: time=  0.5s loss=0.852, TAw acc= 72.0% |
| Epoch 120, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.787, TAw acc= 72.1% | Valid: time=  0.5s loss=0.875, TAw acc= 71.6% |
| Epoch 121, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.831, TAw acc= 71.3% | Valid: time=  0.5s loss=0.876, TAw acc= 71.4% |
| Epoch 122, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 72.0% | Valid: time=  0.5s loss=0.865, TAw acc= 71.2% |
| Epoch 123, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 71.6% | Valid: time=  0.5s loss=0.870, TAw acc= 72.0% |
| Epoch 124, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.795, TAw acc= 72.4% | Valid: time=  0.4s loss=0.868, TAw acc= 71.0% |
| Epoch 125, lr=2.9e-03 time=  1.1s/  2.1s | Train: loss=0.818, TAw acc= 70.8% | Valid: time=  0.5s loss=0.888, TAw acc= 70.4% |
| Epoch 126, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.812, TAw acc= 70.6% | Valid: time=  0.5s loss=0.900, TAw acc= 71.4% |
| Epoch 127, lr=2.9e-03 time=  1.4s/  1.6s | Train: loss=0.801, TAw acc= 71.8% | Valid: time=  0.4s loss=0.883, TAw acc= 70.8% |
| Epoch 128, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.816, TAw acc= 71.4% | Valid: time=  0.5s loss=0.861, TAw acc= 71.4% |
| Epoch 129, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.812, TAw acc= 71.3% | Valid: time=  0.5s loss=0.866, TAw acc= 72.0% |
| Epoch 130, lr=2.9e-03 time=  1.4s/  1.9s | Train: loss=0.823, TAw acc= 71.1% | Valid: time=  0.4s loss=0.857, TAw acc= 72.0% |
| Epoch 131, lr=2.9e-03 time=  1.3s/  2.0s | Train: loss=0.787, TAw acc= 72.5% | Valid: time=  0.4s loss=0.866, TAw acc= 72.4% |
| Epoch 132, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=0.789, TAw acc= 72.3% | Valid: time=  0.5s loss=0.866, TAw acc= 72.2% |
| Epoch 133, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.814, TAw acc= 71.6% | Valid: time=  0.4s loss=0.866, TAw acc= 72.0% |
| Epoch 134, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.796, TAw acc= 72.6% | Valid: time=  0.4s loss=0.896, TAw acc= 70.8% |
| Epoch 135, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.816, TAw acc= 71.0% | Valid: time=  0.5s loss=0.870, TAw acc= 72.0% |
| Epoch 136, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.811, TAw acc= 71.0% | Valid: time=  0.5s loss=0.864, TAw acc= 72.2% |
| Epoch 137, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.790, TAw acc= 71.7% | Valid: time=  0.5s loss=0.884, TAw acc= 71.0% |
| Epoch 138, lr=2.9e-03 time=  1.4s/  2.1s | Train: loss=0.825, TAw acc= 70.9% | Valid: time=  0.4s loss=0.868, TAw acc= 72.6% |
| Epoch 139, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.822, TAw acc= 70.8% | Valid: time=  0.5s loss=0.869, TAw acc= 71.4% |
| Epoch 140, lr=2.9e-03 time=  1.4s/  2.1s | Train: loss=0.801, TAw acc= 72.0% | Valid: time=  0.5s loss=0.872, TAw acc= 71.6% |
| Epoch 141, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.793, TAw acc= 72.4% | Valid: time=  0.5s loss=0.861, TAw acc= 71.8% |
| Epoch 142, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.780, TAw acc= 73.0% | Valid: time=  0.5s loss=0.856, TAw acc= 71.6% | lr=9.7e-04
| Epoch 143, lr=9.7e-04 time=  1.2s/  2.3s | Train: loss=0.842, TAw acc= 70.2% | Valid: time=  0.5s loss=0.836, TAw acc= 72.0% |
| Epoch 144, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 71.7% | Valid: time=  0.5s loss=0.849, TAw acc= 72.4% |
| Epoch 145, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.820, TAw acc= 71.4% | Valid: time=  0.5s loss=0.847, TAw acc= 72.6% |
| Epoch 146, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.831, TAw acc= 72.0% | Valid: time=  0.5s loss=0.849, TAw acc= 72.2% |
| Epoch 147, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 71.0% | Valid: time=  0.5s loss=0.853, TAw acc= 72.4% |
| Epoch 148, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.830, TAw acc= 70.9% | Valid: time=  0.5s loss=0.850, TAw acc= 72.6% |
| Epoch 149, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 70.3% | Valid: time=  0.4s loss=0.849, TAw acc= 73.0% |
| Epoch 150, lr=9.7e-04 time=  1.1s/  1.4s | Train: loss=0.819, TAw acc= 71.1% | Valid: time=  0.4s loss=0.854, TAw acc= 73.0% |
| Epoch 151, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.806, TAw acc= 72.0% | Valid: time=  0.4s loss=0.854, TAw acc= 72.2% |
| Epoch 152, lr=9.7e-04 time=  1.1s/  2.1s | Train: loss=0.790, TAw acc= 72.2% | Valid: time=  0.5s loss=0.861, TAw acc= 72.2% |
| Epoch 153, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.809, TAw acc= 71.8% | Valid: time=  0.5s loss=0.861, TAw acc= 72.8% |
| Epoch 154, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 71.5% | Valid: time=  0.4s loss=0.857, TAw acc= 72.2% |
| Epoch 155, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.818, TAw acc= 71.3% | Valid: time=  0.5s loss=0.858, TAw acc= 72.2% |
| Epoch 156, lr=9.7e-04 time=  1.4s/  1.9s | Train: loss=0.806, TAw acc= 71.9% | Valid: time=  0.4s loss=0.863, TAw acc= 72.4% |
| Epoch 157, lr=9.7e-04 time=  1.3s/  1.6s | Train: loss=0.805, TAw acc= 71.6% | Valid: time=  0.5s loss=0.865, TAw acc= 72.0% |
| Epoch 158, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.811, TAw acc= 71.3% | Valid: time=  0.5s loss=0.861, TAw acc= 72.2% |
| Epoch 159, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.818, TAw acc= 71.4% | Valid: time=  0.5s loss=0.865, TAw acc= 72.4% |
| Epoch 160, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.797, TAw acc= 72.2% | Valid: time=  0.5s loss=0.863, TAw acc= 71.6% |
| Epoch 161, lr=9.7e-04 time=  1.4s/  2.0s | Train: loss=0.816, TAw acc= 71.5% | Valid: time=  0.4s loss=0.866, TAw acc= 71.8% |
| Epoch 162, lr=9.7e-04 time=  1.0s/  2.1s | Train: loss=0.801, TAw acc= 71.7% | Valid: time=  0.5s loss=0.859, TAw acc= 72.6% |
| Epoch 163, lr=9.7e-04 time=  1.2s/  2.1s | Train: loss=0.835, TAw acc= 70.5% | Valid: time=  0.5s loss=0.865, TAw acc= 72.2% |
| Epoch 164, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.808, TAw acc= 71.7% | Valid: time=  0.5s loss=0.862, TAw acc= 73.2% |
| Epoch 165, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.806, TAw acc= 72.2% | Valid: time=  0.5s loss=0.865, TAw acc= 72.6% |
| Epoch 166, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.819, TAw acc= 71.4% | Valid: time=  0.5s loss=0.865, TAw acc= 72.4% |
| Epoch 167, lr=9.7e-04 time=  1.4s/  1.7s | Train: loss=0.793, TAw acc= 72.3% | Valid: time=  0.4s loss=0.860, TAw acc= 72.2% |
| Epoch 168, lr=9.7e-04 time=  1.2s/  2.1s | Train: loss=0.798, TAw acc= 71.9% | Valid: time=  0.5s loss=0.858, TAw acc= 72.8% |
| Epoch 169, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.802, TAw acc= 71.7% | Valid: time=  0.5s loss=0.858, TAw acc= 73.0% |
| Epoch 170, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.797, TAw acc= 72.0% | Valid: time=  0.5s loss=0.864, TAw acc= 73.2% |
| Epoch 171, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 72.1% | Valid: time=  0.5s loss=0.866, TAw acc= 72.2% |
| Epoch 172, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.1% | Valid: time=  0.5s loss=0.868, TAw acc= 72.2% | lr=3.2e-04
| Epoch 173, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.830, TAw acc= 70.8% | Valid: time=  0.5s loss=0.821, TAw acc= 72.6% |
| Epoch 174, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.3% | Valid: time=  0.5s loss=0.828, TAw acc= 72.6% |
| Epoch 175, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.832, TAw acc= 70.7% | Valid: time=  0.5s loss=0.834, TAw acc= 72.2% |
| Epoch 176, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 71.0% | Valid: time=  0.5s loss=0.837, TAw acc= 72.6% |
| Epoch 177, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.822, TAw acc= 71.0% | Valid: time=  0.5s loss=0.840, TAw acc= 72.4% |
| Epoch 178, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 71.4% | Valid: time=  0.5s loss=0.843, TAw acc= 72.8% |
| Epoch 179, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.815, TAw acc= 71.4% | Valid: time=  0.5s loss=0.846, TAw acc= 72.8% |
| Epoch 180, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.835, TAw acc= 70.1% | Valid: time=  0.5s loss=0.847, TAw acc= 72.4% |
| Epoch 181, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 71.2% | Valid: time=  0.5s loss=0.849, TAw acc= 72.6% |
| Epoch 182, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 71.9% | Valid: time=  0.5s loss=0.850, TAw acc= 72.4% |
| Epoch 183, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 71.1% | Valid: time=  0.5s loss=0.849, TAw acc= 72.4% |
| Epoch 184, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.849, TAw acc= 69.6% | Valid: time=  0.5s loss=0.847, TAw acc= 72.6% |
| Epoch 185, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.806, TAw acc= 71.7% | Valid: time=  0.5s loss=0.849, TAw acc= 72.6% |
| Epoch 186, lr=3.2e-04 time=  1.2s/  1.5s | Train: loss=0.811, TAw acc= 71.0% | Valid: time=  0.4s loss=0.848, TAw acc= 72.6% |
| Epoch 187, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.819, TAw acc= 70.8% | Valid: time=  0.5s loss=0.852, TAw acc= 72.6% |
| Epoch 188, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.836, TAw acc= 70.7% | Valid: time=  0.5s loss=0.852, TAw acc= 72.8% |
| Epoch 189, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.801, TAw acc= 71.8% | Valid: time=  0.5s loss=0.851, TAw acc= 73.0% |
| Epoch 190, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.816, TAw acc= 71.6% | Valid: time=  0.5s loss=0.853, TAw acc= 73.2% |
| Epoch 191, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.818, TAw acc= 71.3% | Valid: time=  0.5s loss=0.855, TAw acc= 72.6% |
| Epoch 192, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 71.2% | Valid: time=  0.5s loss=0.853, TAw acc= 72.6% |
| Epoch 193, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 71.9% | Valid: time=  0.5s loss=0.852, TAw acc= 73.2% |
| Epoch 194, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.834, TAw acc= 71.0% | Valid: time=  0.4s loss=0.850, TAw acc= 72.8% |
| Epoch 195, lr=3.2e-04 time=  1.2s/  1.5s | Train: loss=0.814, TAw acc= 71.3% | Valid: time=  0.4s loss=0.849, TAw acc= 73.0% |
| Epoch 196, lr=3.2e-04 time=  1.2s/  2.3s | Train: loss=0.812, TAw acc= 72.0% | Valid: time=  0.5s loss=0.848, TAw acc= 73.2% |
| Epoch 197, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.809, TAw acc= 71.6% | Valid: time=  0.4s loss=0.848, TAw acc= 73.6% |
| Epoch 198, lr=3.2e-04 time=  1.1s/  1.9s | Train: loss=0.829, TAw acc= 71.2% | Valid: time=  0.5s loss=0.849, TAw acc= 73.4% |
| Epoch 199, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 70.6% | Valid: time=  0.5s loss=0.855, TAw acc= 73.0% |
| Epoch 200, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 71.2% | Valid: time=  0.5s loss=0.853, TAw acc= 73.4% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.789 | TAw acc= 75.3%, forg=  4.9%| TAg acc= 34.5%, forg= 45.7% <<<
>>> Test on task  1 : loss=1.134 | TAw acc= 63.3%, forg=  5.7%| TAg acc= 18.6%, forg= 31.4% <<<
>>> Test on task  2 : loss=0.600 | TAw acc= 80.4%, forg=  1.7%| TAg acc= 37.0%, forg= 27.3% <<<
>>> Test on task  3 : loss=0.659 | TAw acc= 76.3%, forg=  5.3%| TAg acc= 25.4%, forg= 17.5% <<<
>>> Test on task  4 : loss=0.470 | TAw acc= 85.4%, forg=  1.8%| TAg acc= 53.8%, forg=  5.4% <<<
>>> Test on task  5 : loss=0.766 | TAw acc= 73.3%, forg=  0.0%| TAg acc= 32.7%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  6
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-6): 7 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.2s/  1.7s | Train: loss=1.072, TAw acc= 64.0% | Valid: time=  0.3s loss=0.738, TAw acc= 74.8% | *
| Epoch   2, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=1.004, TAw acc= 66.2% | Valid: time=  0.3s loss=0.675, TAw acc= 78.8% | *
| Epoch   3, lr=2.6e-02 time=  1.0s/  2.1s | Train: loss=0.983, TAw acc= 66.8% | Valid: time=  0.5s loss=0.769, TAw acc= 74.0% |
| Epoch   4, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.932, TAw acc= 68.8% | Valid: time=  0.4s loss=0.626, TAw acc= 78.8% | *
| Epoch   5, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.928, TAw acc= 68.4% | Valid: time=  0.3s loss=0.691, TAw acc= 77.6% |
| Epoch   6, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.917, TAw acc= 69.4% | Valid: time=  0.3s loss=0.622, TAw acc= 80.6% | *
| Epoch   7, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.926, TAw acc= 69.6% | Valid: time=  0.3s loss=0.687, TAw acc= 77.8% |
| Epoch   8, lr=2.6e-02 time=  1.1s/  2.2s | Train: loss=0.894, TAw acc= 69.5% | Valid: time=  0.5s loss=0.656, TAw acc= 77.8% |
| Epoch   9, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.880, TAw acc= 70.4% | Valid: time=  0.4s loss=0.707, TAw acc= 77.0% |
| Epoch  10, lr=2.6e-02 time=  1.0s/  1.0s | Train: loss=0.872, TAw acc= 70.2% | Valid: time=  0.3s loss=0.619, TAw acc= 79.4% | *
| Epoch  11, lr=2.6e-02 time=  0.8s/  2.4s | Train: loss=0.848, TAw acc= 71.1% | Valid: time=  0.5s loss=0.618, TAw acc= 80.4% | *
| Epoch  12, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.870, TAw acc= 71.4% | Valid: time=  0.3s loss=0.621, TAw acc= 79.6% |
| Epoch  13, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.854, TAw acc= 71.0% | Valid: time=  0.3s loss=0.662, TAw acc= 79.8% |
| Epoch  14, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.834, TAw acc= 72.1% | Valid: time=  0.3s loss=0.707, TAw acc= 77.6% |
| Epoch  15, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.854, TAw acc= 70.8% | Valid: time=  0.3s loss=0.606, TAw acc= 79.4% | *
| Epoch  16, lr=2.6e-02 time=  0.8s/  2.0s | Train: loss=0.835, TAw acc= 71.8% | Valid: time=  0.5s loss=0.643, TAw acc= 79.0% |
| Epoch  17, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.855, TAw acc= 71.3% | Valid: time=  0.3s loss=0.633, TAw acc= 79.8% |
| Epoch  18, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.818, TAw acc= 72.6% | Valid: time=  0.3s loss=0.753, TAw acc= 76.4% |
| Epoch  19, lr=2.6e-02 time=  0.8s/  1.7s | Train: loss=0.827, TAw acc= 71.7% | Valid: time=  0.5s loss=0.666, TAw acc= 79.6% |
| Epoch  20, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.841, TAw acc= 71.6% | Valid: time=  0.5s loss=0.601, TAw acc= 81.8% | *
| Epoch  21, lr=2.6e-02 time=  1.3s/  1.9s | Train: loss=0.800, TAw acc= 73.4% | Valid: time=  0.3s loss=0.634, TAw acc= 80.4% |
| Epoch  22, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.807, TAw acc= 72.7% | Valid: time=  0.3s loss=0.707, TAw acc= 78.8% |
| Epoch  23, lr=2.6e-02 time=  0.8s/  1.6s | Train: loss=0.847, TAw acc= 71.1% | Valid: time=  0.5s loss=0.604, TAw acc= 81.8% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 72.6% | Valid: time=  0.5s loss=0.657, TAw acc= 80.8% |
| Epoch  25, lr=2.6e-02 time=  1.2s/  1.3s | Train: loss=0.815, TAw acc= 71.9% | Valid: time=  0.3s loss=0.710, TAw acc= 79.4% |
| Epoch  26, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.829, TAw acc= 72.7% | Valid: time=  0.3s loss=0.669, TAw acc= 81.2% |
| Epoch  27, lr=2.6e-02 time=  0.8s/  1.4s | Train: loss=0.804, TAw acc= 72.2% | Valid: time=  0.5s loss=0.670, TAw acc= 80.2% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  1.9s | Train: loss=0.796, TAw acc= 72.8% | Valid: time=  0.4s loss=0.685, TAw acc= 79.0% |
| Epoch  29, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.777, TAw acc= 73.6% | Valid: time=  0.5s loss=0.623, TAw acc= 81.0% |
| Epoch  30, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.798, TAw acc= 72.7% | Valid: time=  0.5s loss=0.672, TAw acc= 81.4% |
| Epoch  31, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 73.4% | Valid: time=  0.5s loss=0.645, TAw acc= 80.8% |
| Epoch  32, lr=2.6e-02 time=  1.0s/  1.0s | Train: loss=0.799, TAw acc= 73.4% | Valid: time=  0.3s loss=0.764, TAw acc= 77.0% |
| Epoch  33, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.777, TAw acc= 74.2% | Valid: time=  0.5s loss=0.592, TAw acc= 82.0% | *
| Epoch  34, lr=2.6e-02 time=  1.4s/  1.1s | Train: loss=0.794, TAw acc= 73.0% | Valid: time=  0.3s loss=0.716, TAw acc= 77.0% |
| Epoch  35, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.768, TAw acc= 74.7% | Valid: time=  0.3s loss=0.628, TAw acc= 80.8% |
| Epoch  36, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.766, TAw acc= 73.9% | Valid: time=  0.3s loss=0.622, TAw acc= 80.6% |
| Epoch  37, lr=2.6e-02 time=  0.8s/  1.1s | Train: loss=0.797, TAw acc= 73.0% | Valid: time=  0.5s loss=0.623, TAw acc= 82.6% |
| Epoch  38, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.767, TAw acc= 73.7% | Valid: time=  0.5s loss=0.682, TAw acc= 79.4% |
| Epoch  39, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.774, TAw acc= 74.1% | Valid: time=  0.3s loss=0.664, TAw acc= 80.6% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.776, TAw acc= 74.0% | Valid: time=  0.5s loss=0.606, TAw acc= 80.6% |
| Epoch  41, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.779, TAw acc= 73.7% | Valid: time=  0.5s loss=0.601, TAw acc= 83.2% |
| Epoch  42, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.784, TAw acc= 74.1% | Valid: time=  0.5s loss=0.650, TAw acc= 79.6% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.764, TAw acc= 74.7% | Valid: time=  0.5s loss=0.568, TAw acc= 83.0% | *
| Epoch  44, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.747, TAw acc= 74.4% | Valid: time=  0.5s loss=0.674, TAw acc= 78.8% |
| Epoch  45, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.744, TAw acc= 75.2% | Valid: time=  0.5s loss=0.632, TAw acc= 80.4% |
| Epoch  46, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.746, TAw acc= 74.7% | Valid: time=  0.5s loss=0.654, TAw acc= 81.2% |
| Epoch  47, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.711, TAw acc= 76.2% | Valid: time=  0.5s loss=0.657, TAw acc= 81.0% |
| Epoch  48, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.763, TAw acc= 74.4% | Valid: time=  0.5s loss=0.621, TAw acc= 81.4% |
| Epoch  49, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.734, TAw acc= 75.5% | Valid: time=  0.5s loss=0.651, TAw acc= 81.0% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.746, TAw acc= 75.5% | Valid: time=  0.5s loss=0.748, TAw acc= 78.4% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.737, TAw acc= 76.0% | Valid: time=  0.5s loss=0.634, TAw acc= 79.8% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.738, TAw acc= 75.6% | Valid: time=  0.5s loss=0.663, TAw acc= 79.6% |
| Epoch  53, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=0.742, TAw acc= 74.6% | Valid: time=  0.5s loss=0.661, TAw acc= 80.4% |
| Epoch  54, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 75.7% | Valid: time=  0.5s loss=0.672, TAw acc= 81.0% |
| Epoch  55, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 75.6% | Valid: time=  0.5s loss=0.656, TAw acc= 80.8% |
| Epoch  56, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.744, TAw acc= 74.6% | Valid: time=  0.4s loss=0.666, TAw acc= 80.0% |
| Epoch  57, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.734, TAw acc= 75.7% | Valid: time=  0.4s loss=0.652, TAw acc= 81.6% |
| Epoch  58, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.735, TAw acc= 76.0% | Valid: time=  0.5s loss=0.632, TAw acc= 82.8% |
| Epoch  59, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.709, TAw acc= 76.6% | Valid: time=  0.5s loss=0.631, TAw acc= 82.4% |
| Epoch  60, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.691, TAw acc= 77.1% | Valid: time=  0.5s loss=0.664, TAw acc= 81.6% |
| Epoch  61, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.720, TAw acc= 76.3% | Valid: time=  0.5s loss=0.678, TAw acc= 80.0% |
| Epoch  62, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.719, TAw acc= 76.2% | Valid: time=  0.4s loss=0.678, TAw acc= 80.6% |
| Epoch  63, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.714, TAw acc= 76.3% | Valid: time=  0.4s loss=0.696, TAw acc= 79.2% |
| Epoch  64, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.712, TAw acc= 75.9% | Valid: time=  0.4s loss=0.744, TAw acc= 78.6% |
| Epoch  65, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.724, TAw acc= 75.8% | Valid: time=  0.5s loss=0.751, TAw acc= 80.0% |
| Epoch  66, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.700, TAw acc= 76.8% | Valid: time=  0.5s loss=0.630, TAw acc= 81.4% |
| Epoch  67, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.711, TAw acc= 75.8% | Valid: time=  0.5s loss=0.701, TAw acc= 78.0% |
| Epoch  68, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.705, TAw acc= 76.0% | Valid: time=  0.5s loss=0.632, TAw acc= 81.2% |
| Epoch  69, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.711, TAw acc= 75.8% | Valid: time=  0.5s loss=0.628, TAw acc= 79.4% |
| Epoch  70, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.713, TAw acc= 75.3% | Valid: time=  0.4s loss=0.679, TAw acc= 79.8% |
| Epoch  71, lr=2.6e-02 time=  1.0s/  1.5s | Train: loss=0.719, TAw acc= 76.2% | Valid: time=  0.5s loss=0.656, TAw acc= 80.0% |
| Epoch  72, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.709, TAw acc= 76.4% | Valid: time=  0.5s loss=0.661, TAw acc= 80.0% |
| Epoch  73, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.704, TAw acc= 76.0% | Valid: time=  0.5s loss=0.715, TAw acc= 78.4% | lr=8.8e-03
| Epoch  74, lr=8.8e-03 time=  1.2s/  2.0s | Train: loss=0.743, TAw acc= 75.7% | Valid: time=  0.5s loss=0.658, TAw acc= 79.8% |
| Epoch  75, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.721, TAw acc= 76.2% | Valid: time=  0.5s loss=0.648, TAw acc= 80.6% |
| Epoch  76, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.739, TAw acc= 75.1% | Valid: time=  0.5s loss=0.599, TAw acc= 82.0% |
| Epoch  77, lr=8.8e-03 time=  1.2s/  1.9s | Train: loss=0.713, TAw acc= 76.2% | Valid: time=  0.5s loss=0.622, TAw acc= 80.4% |
| Epoch  78, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.735, TAw acc= 76.3% | Valid: time=  0.5s loss=0.609, TAw acc= 81.4% |
| Epoch  79, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.709, TAw acc= 75.8% | Valid: time=  0.5s loss=0.613, TAw acc= 82.4% |
| Epoch  80, lr=8.8e-03 time=  1.3s/  1.4s | Train: loss=0.708, TAw acc= 76.2% | Valid: time=  0.4s loss=0.610, TAw acc= 82.4% |
| Epoch  81, lr=8.8e-03 time=  1.1s/  2.4s | Train: loss=0.710, TAw acc= 75.8% | Valid: time=  0.5s loss=0.630, TAw acc= 81.2% |
| Epoch  82, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.719, TAw acc= 76.2% | Valid: time=  0.5s loss=0.625, TAw acc= 81.4% |
| Epoch  83, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.713, TAw acc= 76.6% | Valid: time=  0.5s loss=0.612, TAw acc= 81.8% |
| Epoch  84, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 76.8% | Valid: time=  0.5s loss=0.607, TAw acc= 82.4% |
| Epoch  85, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.717, TAw acc= 76.4% | Valid: time=  0.5s loss=0.631, TAw acc= 82.0% |
| Epoch  86, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.720, TAw acc= 76.1% | Valid: time=  0.5s loss=0.680, TAw acc= 80.8% |
| Epoch  87, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.693, TAw acc= 76.9% | Valid: time=  0.5s loss=0.679, TAw acc= 80.0% |
| Epoch  88, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.700, TAw acc= 77.2% | Valid: time=  0.5s loss=0.634, TAw acc= 81.0% |
| Epoch  89, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.704, TAw acc= 76.8% | Valid: time=  0.5s loss=0.648, TAw acc= 80.8% |
| Epoch  90, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.719, TAw acc= 76.0% | Valid: time=  0.5s loss=0.584, TAw acc= 83.8% |
| Epoch  91, lr=8.8e-03 time=  1.4s/  1.6s | Train: loss=0.718, TAw acc= 75.8% | Valid: time=  0.5s loss=0.675, TAw acc= 81.4% |
| Epoch  92, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.689, TAw acc= 76.8% | Valid: time=  0.5s loss=0.648, TAw acc= 81.2% |
| Epoch  93, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.722, TAw acc= 76.3% | Valid: time=  0.4s loss=0.616, TAw acc= 81.6% |
| Epoch  94, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.728, TAw acc= 75.4% | Valid: time=  0.5s loss=0.621, TAw acc= 82.0% |
| Epoch  95, lr=8.8e-03 time=  1.4s/  1.9s | Train: loss=0.693, TAw acc= 76.7% | Valid: time=  0.5s loss=0.622, TAw acc= 82.8% |
| Epoch  96, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.692, TAw acc= 76.6% | Valid: time=  0.4s loss=0.635, TAw acc= 80.8% |
| Epoch  97, lr=8.8e-03 time=  1.2s/  1.5s | Train: loss=0.696, TAw acc= 77.0% | Valid: time=  0.5s loss=0.597, TAw acc= 82.4% |
| Epoch  98, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.685, TAw acc= 77.0% | Valid: time=  0.5s loss=0.616, TAw acc= 83.0% |
| Epoch  99, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.690, TAw acc= 76.7% | Valid: time=  0.5s loss=0.608, TAw acc= 82.2% |
| Epoch 100, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.693, TAw acc= 77.1% | Valid: time=  0.5s loss=0.626, TAw acc= 81.6% |
| Epoch 101, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.681, TAw acc= 77.3% | Valid: time=  0.4s loss=0.639, TAw acc= 81.4% |
| Epoch 102, lr=8.8e-03 time=  1.0s/  2.0s | Train: loss=0.708, TAw acc= 76.1% | Valid: time=  0.5s loss=0.580, TAw acc= 83.6% |
| Epoch 103, lr=8.8e-03 time=  1.4s/  2.1s | Train: loss=0.701, TAw acc= 76.2% | Valid: time=  0.5s loss=0.602, TAw acc= 82.0% | lr=2.9e-03
| Epoch 104, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 75.7% | Valid: time=  0.5s loss=0.605, TAw acc= 81.2% |
| Epoch 105, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.730, TAw acc= 76.1% | Valid: time=  0.5s loss=0.622, TAw acc= 80.4% |
| Epoch 106, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.712, TAw acc= 76.3% | Valid: time=  0.5s loss=0.609, TAw acc= 81.0% |
| Epoch 107, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.725, TAw acc= 76.0% | Valid: time=  0.5s loss=0.620, TAw acc= 81.0% |
| Epoch 108, lr=2.9e-03 time=  1.4s/  1.9s | Train: loss=0.745, TAw acc= 75.6% | Valid: time=  0.5s loss=0.641, TAw acc= 80.0% |
| Epoch 109, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.734, TAw acc= 75.6% | Valid: time=  0.5s loss=0.641, TAw acc= 80.2% |
| Epoch 110, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.711, TAw acc= 77.0% | Valid: time=  0.5s loss=0.654, TAw acc= 80.2% |
| Epoch 111, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.705, TAw acc= 76.7% | Valid: time=  0.4s loss=0.638, TAw acc= 79.8% |
| Epoch 112, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.719, TAw acc= 75.2% | Valid: time=  0.5s loss=0.644, TAw acc= 80.4% |
| Epoch 113, lr=2.9e-03 time=  1.3s/  1.5s | Train: loss=0.704, TAw acc= 76.9% | Valid: time=  0.5s loss=0.645, TAw acc= 79.6% |
| Epoch 114, lr=2.9e-03 time=  1.4s/  2.1s | Train: loss=0.738, TAw acc= 74.8% | Valid: time=  0.4s loss=0.659, TAw acc= 79.2% |
| Epoch 115, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.729, TAw acc= 76.1% | Valid: time=  0.5s loss=0.631, TAw acc= 80.2% |
| Epoch 116, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.715, TAw acc= 76.2% | Valid: time=  0.5s loss=0.632, TAw acc= 80.6% |
| Epoch 117, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.710, TAw acc= 76.4% | Valid: time=  0.4s loss=0.641, TAw acc= 80.4% |
| Epoch 118, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.709, TAw acc= 77.0% | Valid: time=  0.5s loss=0.619, TAw acc= 81.6% |
| Epoch 119, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.714, TAw acc= 76.0% | Valid: time=  0.5s loss=0.622, TAw acc= 81.2% |
| Epoch 120, lr=2.9e-03 time=  1.4s/  1.7s | Train: loss=0.702, TAw acc= 76.1% | Valid: time=  0.5s loss=0.633, TAw acc= 81.2% |
| Epoch 121, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 75.4% | Valid: time=  0.5s loss=0.626, TAw acc= 81.2% |
| Epoch 122, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.705, TAw acc= 76.1% | Valid: time=  0.5s loss=0.625, TAw acc= 81.2% |
| Epoch 123, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.705, TAw acc= 76.1% | Valid: time=  0.4s loss=0.609, TAw acc= 82.0% |
| Epoch 124, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.706, TAw acc= 76.4% | Valid: time=  0.5s loss=0.604, TAw acc= 81.8% |
| Epoch 125, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.698, TAw acc= 76.5% | Valid: time=  0.5s loss=0.621, TAw acc= 80.2% |
| Epoch 126, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.715, TAw acc= 75.8% | Valid: time=  0.5s loss=0.623, TAw acc= 80.4% |
| Epoch 127, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.708, TAw acc= 76.5% | Valid: time=  0.5s loss=0.631, TAw acc= 81.2% |
| Epoch 128, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.715, TAw acc= 76.8% | Valid: time=  0.5s loss=0.627, TAw acc= 81.4% |
| Epoch 129, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.711, TAw acc= 75.7% | Valid: time=  0.5s loss=0.617, TAw acc= 80.8% |
| Epoch 130, lr=2.9e-03 time=  1.4s/  2.0s | Train: loss=0.716, TAw acc= 76.1% | Valid: time=  0.4s loss=0.637, TAw acc= 80.6% |
| Epoch 131, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.708, TAw acc= 76.3% | Valid: time=  0.5s loss=0.627, TAw acc= 81.0% |
| Epoch 132, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.709, TAw acc= 76.3% | Valid: time=  0.5s loss=0.612, TAw acc= 80.8% |
| Epoch 133, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.704, TAw acc= 77.1% | Valid: time=  0.5s loss=0.612, TAw acc= 81.0% | lr=9.7e-04
| Epoch 134, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.731, TAw acc= 76.0% | Valid: time=  0.5s loss=0.589, TAw acc= 81.8% |
| Epoch 135, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.743, TAw acc= 75.2% | Valid: time=  0.5s loss=0.596, TAw acc= 81.8% |
| Epoch 136, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.739, TAw acc= 75.9% | Valid: time=  0.5s loss=0.598, TAw acc= 81.4% |
| Epoch 137, lr=9.7e-04 time=  1.4s/  2.0s | Train: loss=0.725, TAw acc= 75.5% | Valid: time=  0.4s loss=0.603, TAw acc= 80.8% |
| Epoch 138, lr=9.7e-04 time=  1.1s/  1.4s | Train: loss=0.737, TAw acc= 75.3% | Valid: time=  0.4s loss=0.622, TAw acc= 79.8% |
| Epoch 139, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.734, TAw acc= 75.6% | Valid: time=  0.5s loss=0.621, TAw acc= 80.2% |
| Epoch 140, lr=9.7e-04 time=  1.3s/  1.9s | Train: loss=0.743, TAw acc= 74.6% | Valid: time=  0.4s loss=0.629, TAw acc= 80.0% |
| Epoch 141, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.723, TAw acc= 76.2% | Valid: time=  0.5s loss=0.623, TAw acc= 80.0% |
| Epoch 142, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.731, TAw acc= 76.3% | Valid: time=  0.5s loss=0.617, TAw acc= 79.8% |
| Epoch 143, lr=9.7e-04 time=  1.3s/  1.3s | Train: loss=0.731, TAw acc= 75.2% | Valid: time=  0.3s loss=0.613, TAw acc= 80.4% |
| Epoch 144, lr=9.7e-04 time=  0.8s/  1.7s | Train: loss=0.731, TAw acc= 75.7% | Valid: time=  0.5s loss=0.609, TAw acc= 80.8% |
| Epoch 145, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.719, TAw acc= 76.6% | Valid: time=  0.3s loss=0.623, TAw acc= 80.0% |
| Epoch 146, lr=9.7e-04 time=  0.8s/  1.0s | Train: loss=0.713, TAw acc= 76.2% | Valid: time=  0.3s loss=0.625, TAw acc= 79.6% |
| Epoch 147, lr=9.7e-04 time=  0.8s/  1.3s | Train: loss=0.714, TAw acc= 76.0% | Valid: time=  0.5s loss=0.617, TAw acc= 80.4% |
| Epoch 148, lr=9.7e-04 time=  1.4s/  1.8s | Train: loss=0.725, TAw acc= 76.0% | Valid: time=  0.3s loss=0.622, TAw acc= 80.4% |
| Epoch 149, lr=9.7e-04 time=  0.9s/  1.4s | Train: loss=0.721, TAw acc= 75.8% | Valid: time=  0.4s loss=0.622, TAw acc= 80.2% |
| Epoch 150, lr=9.7e-04 time=  1.1s/  1.1s | Train: loss=0.741, TAw acc= 75.5% | Valid: time=  0.3s loss=0.619, TAw acc= 80.4% |
| Epoch 151, lr=9.7e-04 time=  0.8s/  1.0s | Train: loss=0.745, TAw acc= 75.4% | Valid: time=  0.3s loss=0.624, TAw acc= 80.2% |
| Epoch 152, lr=9.7e-04 time=  0.8s/  2.4s | Train: loss=0.711, TAw acc= 76.0% | Valid: time=  0.4s loss=0.616, TAw acc= 80.2% |
| Epoch 153, lr=9.7e-04 time=  1.4s/  1.6s | Train: loss=0.700, TAw acc= 76.7% | Valid: time=  0.3s loss=0.616, TAw acc= 80.8% |
| Epoch 154, lr=9.7e-04 time=  1.3s/  2.3s | Train: loss=0.718, TAw acc= 75.8% | Valid: time=  0.5s loss=0.617, TAw acc= 80.6% |
| Epoch 155, lr=9.7e-04 time=  1.4s/  1.7s | Train: loss=0.722, TAw acc= 75.8% | Valid: time=  0.5s loss=0.618, TAw acc= 81.0% |
| Epoch 156, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.712, TAw acc= 75.7% | Valid: time=  0.5s loss=0.616, TAw acc= 80.6% |
| Epoch 157, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.711, TAw acc= 76.8% | Valid: time=  0.5s loss=0.616, TAw acc= 81.4% |
| Epoch 158, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.708, TAw acc= 76.2% | Valid: time=  0.5s loss=0.617, TAw acc= 80.8% |
| Epoch 159, lr=9.7e-04 time=  1.4s/  2.1s | Train: loss=0.732, TAw acc= 75.9% | Valid: time=  0.4s loss=0.626, TAw acc= 80.4% |
| Epoch 160, lr=9.7e-04 time=  1.0s/  1.5s | Train: loss=0.736, TAw acc= 75.4% | Valid: time=  0.5s loss=0.616, TAw acc= 80.4% |
| Epoch 161, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.695, TAw acc= 76.9% | Valid: time=  0.5s loss=0.626, TAw acc= 80.4% |
| Epoch 162, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.741, TAw acc= 75.2% | Valid: time=  0.5s loss=0.616, TAw acc= 81.2% |
| Epoch 163, lr=9.7e-04 time=  1.2s/  1.6s | Train: loss=0.712, TAw acc= 75.8% | Valid: time=  0.5s loss=0.624, TAw acc= 80.6% | lr=3.2e-04
| Epoch 164, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.742, TAw acc= 75.4% | Valid: time=  0.5s loss=0.569, TAw acc= 82.4% |
| Epoch 165, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.752, TAw acc= 75.1% | Valid: time=  0.5s loss=0.578, TAw acc= 82.2% |
| Epoch 166, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.747, TAw acc= 74.5% | Valid: time=  0.5s loss=0.585, TAw acc= 81.6% |
| Epoch 167, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=0.734, TAw acc= 74.9% | Valid: time=  0.5s loss=0.592, TAw acc= 81.6% |
| Epoch 168, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.744, TAw acc= 75.4% | Valid: time=  0.5s loss=0.593, TAw acc= 81.6% |
| Epoch 169, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.744, TAw acc= 75.7% | Valid: time=  0.5s loss=0.594, TAw acc= 81.6% |
| Epoch 170, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.758, TAw acc= 74.7% | Valid: time=  0.5s loss=0.597, TAw acc= 81.6% |
| Epoch 171, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.708, TAw acc= 76.8% | Valid: time=  0.4s loss=0.600, TAw acc= 81.0% |
| Epoch 172, lr=3.2e-04 time=  1.2s/  2.3s | Train: loss=0.739, TAw acc= 75.1% | Valid: time=  0.5s loss=0.600, TAw acc= 81.2% |
| Epoch 173, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.713, TAw acc= 76.1% | Valid: time=  0.5s loss=0.600, TAw acc= 81.0% |
| Epoch 174, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=0.741, TAw acc= 75.2% | Valid: time=  0.5s loss=0.602, TAw acc= 80.6% |
| Epoch 175, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.745, TAw acc= 75.1% | Valid: time=  0.5s loss=0.605, TAw acc= 80.2% |
| Epoch 176, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.714, TAw acc= 75.8% | Valid: time=  0.5s loss=0.607, TAw acc= 80.4% |
| Epoch 177, lr=3.2e-04 time=  1.4s/  2.1s | Train: loss=0.710, TAw acc= 76.4% | Valid: time=  0.4s loss=0.608, TAw acc= 80.4% |
| Epoch 178, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 75.6% | Valid: time=  0.5s loss=0.613, TAw acc= 80.2% |
| Epoch 179, lr=3.2e-04 time=  1.3s/  2.2s | Train: loss=0.728, TAw acc= 75.8% | Valid: time=  0.5s loss=0.613, TAw acc= 80.0% |
| Epoch 180, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.734, TAw acc= 75.8% | Valid: time=  0.5s loss=0.615, TAw acc= 79.8% |
| Epoch 181, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.730, TAw acc= 75.9% | Valid: time=  0.5s loss=0.615, TAw acc= 80.2% |
| Epoch 182, lr=3.2e-04 time=  1.4s/  2.2s | Train: loss=0.750, TAw acc= 75.9% | Valid: time=  0.5s loss=0.616, TAw acc= 79.8% |
| Epoch 183, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.733, TAw acc= 75.8% | Valid: time=  0.5s loss=0.618, TAw acc= 79.8% |
| Epoch 184, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.727, TAw acc= 75.9% | Valid: time=  0.5s loss=0.613, TAw acc= 80.0% |
| Epoch 185, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.727, TAw acc= 75.8% | Valid: time=  0.3s loss=0.615, TAw acc= 79.8% |
| Epoch 186, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.735, TAw acc= 75.9% | Valid: time=  0.5s loss=0.620, TAw acc= 79.8% |
| Epoch 187, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.730, TAw acc= 75.9% | Valid: time=  0.5s loss=0.620, TAw acc= 79.6% |
| Epoch 188, lr=3.2e-04 time=  1.4s/  1.6s | Train: loss=0.718, TAw acc= 76.5% | Valid: time=  0.4s loss=0.620, TAw acc= 80.0% |
| Epoch 189, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.749, TAw acc= 75.4% | Valid: time=  0.5s loss=0.622, TAw acc= 79.8% |
| Epoch 190, lr=3.2e-04 time=  1.4s/  1.6s | Train: loss=0.735, TAw acc= 75.2% | Valid: time=  0.4s loss=0.623, TAw acc= 80.0% |
| Epoch 191, lr=3.2e-04 time=  1.2s/  2.3s | Train: loss=0.745, TAw acc= 74.8% | Valid: time=  0.5s loss=0.619, TAw acc= 80.2% |
| Epoch 192, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.719, TAw acc= 76.0% | Valid: time=  0.5s loss=0.618, TAw acc= 80.2% |
| Epoch 193, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.723, TAw acc= 75.8% | Valid: time=  0.5s loss=0.620, TAw acc= 80.0% | lr=1.1e-04
| Epoch 194, lr=1.1e-04 time=  1.2s/  2.1s | Train: loss=0.739, TAw acc= 75.5% | Valid: time=  0.5s loss=0.569, TAw acc= 82.4% |
| Epoch 195, lr=1.1e-04 time=  1.3s/  2.2s | Train: loss=0.751, TAw acc= 74.8% | Valid: time=  0.5s loss=0.570, TAw acc= 82.4% |
| Epoch 196, lr=1.1e-04 time=  1.4s/  1.9s | Train: loss=0.751, TAw acc= 75.1% | Valid: time=  0.5s loss=0.571, TAw acc= 82.4% |
| Epoch 197, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.761, TAw acc= 74.3% | Valid: time=  0.5s loss=0.574, TAw acc= 82.0% |
| Epoch 198, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.762, TAw acc= 74.4% | Valid: time=  0.4s loss=0.575, TAw acc= 82.0% |
| Epoch 199, lr=1.1e-04 time=  1.4s/  2.3s | Train: loss=0.752, TAw acc= 75.2% | Valid: time=  0.5s loss=0.577, TAw acc= 82.0% |
| Epoch 200, lr=1.1e-04 time=  1.3s/  2.2s | Train: loss=0.739, TAw acc= 75.8% | Valid: time=  0.5s loss=0.579, TAw acc= 82.0% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.742 | TAw acc= 75.3%, forg=  4.9%| TAg acc= 32.7%, forg= 47.5% <<<
>>> Test on task  1 : loss=1.061 | TAw acc= 64.9%, forg=  4.1%| TAg acc= 19.4%, forg= 30.6% <<<
>>> Test on task  2 : loss=0.611 | TAw acc= 79.4%, forg=  2.7%| TAg acc= 34.8%, forg= 29.5% <<<
>>> Test on task  3 : loss=0.690 | TAw acc= 75.5%, forg=  6.1%| TAg acc= 20.6%, forg= 22.3% <<<
>>> Test on task  4 : loss=0.468 | TAw acc= 85.3%, forg=  1.9%| TAg acc= 53.7%, forg=  5.5% <<<
>>> Test on task  5 : loss=0.796 | TAw acc= 71.4%, forg=  1.9%| TAg acc= 22.2%, forg= 10.5% <<<
>>> Test on task  6 : loss=0.567 | TAw acc= 82.5%, forg=  0.0%| TAg acc= 48.8%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  7
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-7): 8 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.3s/  1.6s | Train: loss=1.030, TAw acc= 64.7% | Valid: time=  0.4s loss=0.779, TAw acc= 72.0% | *
| Epoch   2, lr=2.6e-02 time=  1.1s/  2.5s | Train: loss=1.036, TAw acc= 64.1% | Valid: time=  0.5s loss=0.762, TAw acc= 72.8% | *
| Epoch   3, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.951, TAw acc= 66.6% | Valid: time=  0.5s loss=0.753, TAw acc= 71.4% | *
| Epoch   4, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.930, TAw acc= 67.9% | Valid: time=  0.5s loss=0.684, TAw acc= 74.4% | *
| Epoch   5, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.937, TAw acc= 67.2% | Valid: time=  0.5s loss=0.771, TAw acc= 71.2% |
| Epoch   6, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.931, TAw acc= 66.8% | Valid: time=  0.5s loss=0.710, TAw acc= 73.4% |
| Epoch   7, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.906, TAw acc= 68.7% | Valid: time=  0.5s loss=0.647, TAw acc= 77.0% | *
| Epoch   8, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.899, TAw acc= 68.7% | Valid: time=  0.5s loss=0.745, TAw acc= 74.2% |
| Epoch   9, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.881, TAw acc= 69.6% | Valid: time=  0.5s loss=0.662, TAw acc= 76.6% |
| Epoch  10, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.900, TAw acc= 68.4% | Valid: time=  0.5s loss=0.695, TAw acc= 74.2% |
| Epoch  11, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.884, TAw acc= 69.2% | Valid: time=  0.4s loss=0.689, TAw acc= 75.4% |
| Epoch  12, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.855, TAw acc= 70.1% | Valid: time=  0.4s loss=0.667, TAw acc= 76.6% |
| Epoch  13, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.878, TAw acc= 67.8% | Valid: time=  0.5s loss=0.692, TAw acc= 76.2% |
| Epoch  14, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.840, TAw acc= 71.3% | Valid: time=  0.5s loss=0.687, TAw acc= 75.6% |
| Epoch  15, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.844, TAw acc= 71.7% | Valid: time=  0.5s loss=0.713, TAw acc= 76.4% |
| Epoch  16, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.872, TAw acc= 68.8% | Valid: time=  0.4s loss=0.717, TAw acc= 75.4% |
| Epoch  17, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.845, TAw acc= 70.6% | Valid: time=  0.5s loss=0.680, TAw acc= 76.0% |
| Epoch  18, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.824, TAw acc= 70.6% | Valid: time=  0.5s loss=0.670, TAw acc= 75.2% |
| Epoch  19, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 70.8% | Valid: time=  0.5s loss=0.694, TAw acc= 75.4% |
| Epoch  20, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.831, TAw acc= 71.4% | Valid: time=  0.5s loss=0.740, TAw acc= 74.2% |
| Epoch  21, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=0.810, TAw acc= 71.4% | Valid: time=  0.5s loss=0.682, TAw acc= 77.0% |
| Epoch  22, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 72.1% | Valid: time=  0.5s loss=0.677, TAw acc= 77.8% |
| Epoch  23, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.805, TAw acc= 72.0% | Valid: time=  0.5s loss=0.673, TAw acc= 77.0% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.819, TAw acc= 71.9% | Valid: time=  0.5s loss=0.646, TAw acc= 76.8% | *
| Epoch  25, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.796, TAw acc= 72.4% | Valid: time=  0.5s loss=0.672, TAw acc= 77.8% |
| Epoch  26, lr=2.6e-02 time=  1.1s/  2.1s | Train: loss=0.790, TAw acc= 72.7% | Valid: time=  0.5s loss=0.665, TAw acc= 76.4% |
| Epoch  27, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.802, TAw acc= 72.1% | Valid: time=  0.5s loss=0.694, TAw acc= 76.4% |
| Epoch  28, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.789, TAw acc= 72.2% | Valid: time=  0.5s loss=0.646, TAw acc= 77.4% | *
| Epoch  29, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.806, TAw acc= 72.0% | Valid: time=  0.5s loss=0.755, TAw acc= 74.6% |
| Epoch  30, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=0.798, TAw acc= 71.7% | Valid: time=  0.3s loss=0.650, TAw acc= 76.6% |
| Epoch  31, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.806, TAw acc= 71.7% | Valid: time=  0.4s loss=0.645, TAw acc= 76.8% | *
| Epoch  32, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.792, TAw acc= 72.7% | Valid: time=  0.5s loss=0.671, TAw acc= 77.6% |
| Epoch  33, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.774, TAw acc= 73.8% | Valid: time=  0.5s loss=0.623, TAw acc= 78.2% | *
| Epoch  34, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.794, TAw acc= 72.5% | Valid: time=  0.4s loss=0.629, TAw acc= 77.0% |
| Epoch  35, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.772, TAw acc= 72.5% | Valid: time=  0.5s loss=0.665, TAw acc= 79.0% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.771, TAw acc= 73.2% | Valid: time=  0.5s loss=0.652, TAw acc= 79.8% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.775, TAw acc= 73.3% | Valid: time=  0.5s loss=0.633, TAw acc= 78.8% |
| Epoch  38, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.779, TAw acc= 72.6% | Valid: time=  0.5s loss=0.612, TAw acc= 80.4% | *
| Epoch  39, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.781, TAw acc= 72.4% | Valid: time=  0.5s loss=0.707, TAw acc= 76.6% |
| Epoch  40, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.789, TAw acc= 72.8% | Valid: time=  0.5s loss=0.724, TAw acc= 77.2% |
| Epoch  41, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.771, TAw acc= 73.5% | Valid: time=  0.5s loss=0.627, TAw acc= 77.8% |
| Epoch  42, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.756, TAw acc= 74.0% | Valid: time=  0.5s loss=0.662, TAw acc= 77.6% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.753, TAw acc= 73.3% | Valid: time=  0.5s loss=0.638, TAw acc= 78.0% |
| Epoch  44, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.778, TAw acc= 72.6% | Valid: time=  0.5s loss=0.685, TAw acc= 77.2% |
| Epoch  45, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.769, TAw acc= 73.7% | Valid: time=  0.5s loss=0.657, TAw acc= 77.2% |
| Epoch  46, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.746, TAw acc= 74.4% | Valid: time=  0.5s loss=0.648, TAw acc= 78.6% |
| Epoch  47, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.745, TAw acc= 74.4% | Valid: time=  0.5s loss=0.644, TAw acc= 78.8% |
| Epoch  48, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.752, TAw acc= 74.2% | Valid: time=  0.4s loss=0.651, TAw acc= 77.4% |
| Epoch  49, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.741, TAw acc= 74.1% | Valid: time=  0.5s loss=0.650, TAw acc= 78.6% |
| Epoch  50, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.758, TAw acc= 73.6% | Valid: time=  0.5s loss=0.612, TAw acc= 77.6% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.754, TAw acc= 72.8% | Valid: time=  0.5s loss=0.650, TAw acc= 78.4% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.739, TAw acc= 73.5% | Valid: time=  0.5s loss=0.634, TAw acc= 77.8% |
| Epoch  53, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.733, TAw acc= 74.4% | Valid: time=  0.5s loss=0.604, TAw acc= 80.2% | *
| Epoch  54, lr=2.6e-02 time=  1.2s/  2.3s | Train: loss=0.800, TAw acc= 70.9% | Valid: time=  0.5s loss=0.685, TAw acc= 76.4% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.759, TAw acc= 73.0% | Valid: time=  0.5s loss=0.640, TAw acc= 78.8% |
| Epoch  56, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.732, TAw acc= 75.5% | Valid: time=  0.5s loss=0.687, TAw acc= 75.8% |
| Epoch  57, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 74.8% | Valid: time=  0.5s loss=0.621, TAw acc= 78.0% |
| Epoch  58, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.756, TAw acc= 74.7% | Valid: time=  0.5s loss=0.630, TAw acc= 78.2% |
| Epoch  59, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.737, TAw acc= 74.7% | Valid: time=  0.5s loss=0.651, TAw acc= 78.0% |
| Epoch  60, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.714, TAw acc= 74.6% | Valid: time=  0.5s loss=0.647, TAw acc= 79.0% |
| Epoch  61, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.712, TAw acc= 76.2% | Valid: time=  0.5s loss=0.615, TAw acc= 79.0% |
| Epoch  62, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 75.0% | Valid: time=  0.5s loss=0.603, TAw acc= 79.4% | *
| Epoch  63, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.741, TAw acc= 74.2% | Valid: time=  0.4s loss=0.613, TAw acc= 79.8% |
| Epoch  64, lr=2.6e-02 time=  1.1s/  1.6s | Train: loss=0.743, TAw acc= 74.0% | Valid: time=  0.5s loss=0.641, TAw acc= 79.6% |
| Epoch  65, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=0.708, TAw acc= 75.6% | Valid: time=  0.5s loss=0.646, TAw acc= 78.6% |
| Epoch  66, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.749, TAw acc= 73.8% | Valid: time=  0.5s loss=0.696, TAw acc= 77.2% |
| Epoch  67, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.737, TAw acc= 73.6% | Valid: time=  0.5s loss=0.606, TAw acc= 80.8% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.718, TAw acc= 74.9% | Valid: time=  0.5s loss=0.666, TAw acc= 78.4% |
| Epoch  69, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.701, TAw acc= 76.0% | Valid: time=  0.5s loss=0.608, TAw acc= 78.4% |
| Epoch  70, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.703, TAw acc= 75.7% | Valid: time=  0.5s loss=0.620, TAw acc= 77.8% |
| Epoch  71, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.750, TAw acc= 73.5% | Valid: time=  0.5s loss=0.620, TAw acc= 79.6% |
| Epoch  72, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.743, TAw acc= 74.2% | Valid: time=  0.5s loss=0.637, TAw acc= 79.6% |
| Epoch  73, lr=2.6e-02 time=  1.1s/  2.4s | Train: loss=0.694, TAw acc= 75.7% | Valid: time=  0.3s loss=0.629, TAw acc= 79.2% |
| Epoch  74, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=0.699, TAw acc= 76.0% | Valid: time=  0.4s loss=0.605, TAw acc= 79.8% |
| Epoch  75, lr=2.6e-02 time=  1.0s/  1.0s | Train: loss=0.728, TAw acc= 74.7% | Valid: time=  0.3s loss=0.638, TAw acc= 79.4% |
| Epoch  76, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.741, TAw acc= 74.1% | Valid: time=  0.3s loss=0.673, TAw acc= 78.4% |
| Epoch  77, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.701, TAw acc= 75.2% | Valid: time=  0.5s loss=0.659, TAw acc= 79.4% |
| Epoch  78, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.712, TAw acc= 75.1% | Valid: time=  0.4s loss=0.646, TAw acc= 79.6% |
| Epoch  79, lr=2.6e-02 time=  0.9s/  1.0s | Train: loss=0.728, TAw acc= 74.4% | Valid: time=  0.3s loss=0.576, TAw acc= 81.4% | *
| Epoch  80, lr=2.6e-02 time=  0.8s/  1.3s | Train: loss=0.699, TAw acc= 76.5% | Valid: time=  0.5s loss=0.650, TAw acc= 76.8% |
| Epoch  81, lr=2.6e-02 time=  1.4s/  2.0s | Train: loss=0.679, TAw acc= 77.0% | Valid: time=  0.4s loss=0.608, TAw acc= 78.8% |
| Epoch  82, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.695, TAw acc= 76.6% | Valid: time=  0.4s loss=0.641, TAw acc= 77.2% |
| Epoch  83, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.698, TAw acc= 74.8% | Valid: time=  0.3s loss=0.650, TAw acc= 79.2% |
| Epoch  84, lr=2.6e-02 time=  1.1s/  2.1s | Train: loss=0.717, TAw acc= 74.9% | Valid: time=  0.5s loss=0.660, TAw acc= 78.8% |
| Epoch  85, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.731, TAw acc= 74.7% | Valid: time=  0.5s loss=0.646, TAw acc= 78.6% |
| Epoch  86, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.690, TAw acc= 76.6% | Valid: time=  0.5s loss=0.673, TAw acc= 76.2% |
| Epoch  87, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.696, TAw acc= 76.0% | Valid: time=  0.5s loss=0.662, TAw acc= 78.8% |
| Epoch  88, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 74.5% | Valid: time=  0.5s loss=0.638, TAw acc= 79.6% |
| Epoch  89, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.670, TAw acc= 76.9% | Valid: time=  0.5s loss=0.652, TAw acc= 77.6% |
| Epoch  90, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.692, TAw acc= 76.8% | Valid: time=  0.5s loss=0.685, TAw acc= 77.4% |
| Epoch  91, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.697, TAw acc= 75.5% | Valid: time=  0.5s loss=0.674, TAw acc= 77.4% |
| Epoch  92, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.684, TAw acc= 76.1% | Valid: time=  0.5s loss=0.595, TAw acc= 80.2% |
| Epoch  93, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.717, TAw acc= 74.7% | Valid: time=  0.5s loss=0.697, TAw acc= 76.8% |
| Epoch  94, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.696, TAw acc= 75.6% | Valid: time=  0.5s loss=0.640, TAw acc= 80.8% |
| Epoch  95, lr=2.6e-02 time=  1.4s/  2.0s | Train: loss=0.694, TAw acc= 76.6% | Valid: time=  0.5s loss=0.710, TAw acc= 79.0% |
| Epoch  96, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.688, TAw acc= 76.2% | Valid: time=  0.5s loss=0.620, TAw acc= 79.6% |
| Epoch  97, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.703, TAw acc= 76.2% | Valid: time=  0.5s loss=0.634, TAw acc= 78.2% |
| Epoch  98, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.671, TAw acc= 77.0% | Valid: time=  0.5s loss=0.690, TAw acc= 77.8% |
| Epoch  99, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.691, TAw acc= 75.6% | Valid: time=  0.5s loss=0.603, TAw acc= 80.8% |
| Epoch 100, lr=2.6e-02 time=  1.4s/  2.0s | Train: loss=0.695, TAw acc= 75.2% | Valid: time=  0.4s loss=0.629, TAw acc= 79.2% |
| Epoch 101, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=0.726, TAw acc= 74.9% | Valid: time=  0.4s loss=0.638, TAw acc= 80.6% |
| Epoch 102, lr=2.6e-02 time=  1.1s/  2.0s | Train: loss=0.706, TAw acc= 74.8% | Valid: time=  0.5s loss=0.653, TAw acc= 79.8% |
| Epoch 103, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=0.708, TAw acc= 75.8% | Valid: time=  0.5s loss=0.651, TAw acc= 78.6% |
| Epoch 104, lr=2.6e-02 time=  1.2s/  2.0s | Train: loss=0.701, TAw acc= 75.7% | Valid: time=  0.5s loss=0.635, TAw acc= 79.8% |
| Epoch 105, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.690, TAw acc= 75.7% | Valid: time=  0.5s loss=0.610, TAw acc= 79.8% |
| Epoch 106, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.681, TAw acc= 76.9% | Valid: time=  0.5s loss=0.631, TAw acc= 79.2% |
| Epoch 107, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.695, TAw acc= 75.4% | Valid: time=  0.5s loss=0.690, TAw acc= 79.6% |
| Epoch 108, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.676, TAw acc= 76.5% | Valid: time=  0.5s loss=0.630, TAw acc= 80.2% |
| Epoch 109, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.705, TAw acc= 75.5% | Valid: time=  0.5s loss=0.665, TAw acc= 78.6% | lr=8.8e-03
| Epoch 110, lr=8.8e-03 time=  1.4s/  1.5s | Train: loss=0.697, TAw acc= 75.3% | Valid: time=  0.5s loss=0.610, TAw acc= 79.8% |
| Epoch 111, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.677, TAw acc= 76.7% | Valid: time=  0.5s loss=0.622, TAw acc= 79.4% |
| Epoch 112, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.688, TAw acc= 75.7% | Valid: time=  0.5s loss=0.581, TAw acc= 80.2% |
| Epoch 113, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.688, TAw acc= 76.1% | Valid: time=  0.5s loss=0.607, TAw acc= 80.4% |
| Epoch 114, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.672, TAw acc= 77.2% | Valid: time=  0.5s loss=0.610, TAw acc= 80.0% |
| Epoch 115, lr=8.8e-03 time=  1.4s/  1.9s | Train: loss=0.674, TAw acc= 77.0% | Valid: time=  0.3s loss=0.627, TAw acc= 79.2% |
| Epoch 116, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.675, TAw acc= 76.4% | Valid: time=  0.5s loss=0.618, TAw acc= 79.8% |
| Epoch 117, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.674, TAw acc= 76.8% | Valid: time=  0.5s loss=0.627, TAw acc= 79.6% |
| Epoch 118, lr=8.8e-03 time=  1.2s/  2.1s | Train: loss=0.665, TAw acc= 77.1% | Valid: time=  0.5s loss=0.628, TAw acc= 79.2% |
| Epoch 119, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.671, TAw acc= 77.0% | Valid: time=  0.4s loss=0.612, TAw acc= 79.4% |
| Epoch 120, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.659, TAw acc= 76.8% | Valid: time=  0.5s loss=0.638, TAw acc= 78.8% |
| Epoch 121, lr=8.8e-03 time=  1.4s/  2.1s | Train: loss=0.674, TAw acc= 77.0% | Valid: time=  0.5s loss=0.637, TAw acc= 79.2% |
| Epoch 122, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.654, TAw acc= 77.6% | Valid: time=  0.5s loss=0.627, TAw acc= 79.8% |
| Epoch 123, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.669, TAw acc= 76.4% | Valid: time=  0.5s loss=0.636, TAw acc= 79.0% |
| Epoch 124, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.678, TAw acc= 76.9% | Valid: time=  0.5s loss=0.608, TAw acc= 79.8% |
| Epoch 125, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.663, TAw acc= 77.6% | Valid: time=  0.5s loss=0.623, TAw acc= 79.4% |
| Epoch 126, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.645, TAw acc= 78.8% | Valid: time=  0.5s loss=0.627, TAw acc= 79.4% |
| Epoch 127, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.656, TAw acc= 77.6% | Valid: time=  0.5s loss=0.640, TAw acc= 79.4% |
| Epoch 128, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.660, TAw acc= 77.3% | Valid: time=  0.4s loss=0.627, TAw acc= 79.8% |
| Epoch 129, lr=8.8e-03 time=  1.1s/  2.2s | Train: loss=0.648, TAw acc= 77.5% | Valid: time=  0.5s loss=0.625, TAw acc= 79.8% |
| Epoch 130, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.657, TAw acc= 77.5% | Valid: time=  0.5s loss=0.638, TAw acc= 79.0% |
| Epoch 131, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.673, TAw acc= 77.2% | Valid: time=  0.5s loss=0.651, TAw acc= 79.0% |
| Epoch 132, lr=8.8e-03 time=  1.3s/  1.7s | Train: loss=0.658, TAw acc= 77.6% | Valid: time=  0.4s loss=0.628, TAw acc= 80.2% |
| Epoch 133, lr=8.8e-03 time=  1.1s/  2.2s | Train: loss=0.667, TAw acc= 76.9% | Valid: time=  0.5s loss=0.621, TAw acc= 79.0% |
| Epoch 134, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.665, TAw acc= 76.9% | Valid: time=  0.5s loss=0.632, TAw acc= 80.6% |
| Epoch 135, lr=8.8e-03 time=  1.3s/  2.0s | Train: loss=0.670, TAw acc= 77.3% | Valid: time=  0.5s loss=0.618, TAw acc= 80.2% |
| Epoch 136, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.650, TAw acc= 78.2% | Valid: time=  0.5s loss=0.615, TAw acc= 79.2% |
| Epoch 137, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.662, TAw acc= 76.9% | Valid: time=  0.5s loss=0.631, TAw acc= 79.2% |
| Epoch 138, lr=8.8e-03 time=  1.4s/  1.6s | Train: loss=0.673, TAw acc= 77.4% | Valid: time=  0.5s loss=0.618, TAw acc= 80.2% |
| Epoch 139, lr=8.8e-03 time=  1.4s/  2.1s | Train: loss=0.667, TAw acc= 77.2% | Valid: time=  0.4s loss=0.611, TAw acc= 80.2% | lr=2.9e-03
| Epoch 140, lr=2.9e-03 time=  1.3s/  2.1s | Train: loss=0.687, TAw acc= 76.7% | Valid: time=  0.4s loss=0.596, TAw acc= 80.6% |
| Epoch 141, lr=2.9e-03 time=  1.2s/  2.3s | Train: loss=0.679, TAw acc= 77.0% | Valid: time=  0.5s loss=0.599, TAw acc= 80.0% |
| Epoch 142, lr=2.9e-03 time=  1.4s/  1.6s | Train: loss=0.699, TAw acc= 75.4% | Valid: time=  0.5s loss=0.596, TAw acc= 79.4% |
| Epoch 143, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.682, TAw acc= 76.6% | Valid: time=  0.5s loss=0.600, TAw acc= 79.0% |
| Epoch 144, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.678, TAw acc= 76.1% | Valid: time=  0.5s loss=0.600, TAw acc= 79.6% |
| Epoch 145, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.691, TAw acc= 76.8% | Valid: time=  0.4s loss=0.610, TAw acc= 79.4% |
| Epoch 146, lr=2.9e-03 time=  1.0s/  2.2s | Train: loss=0.679, TAw acc= 76.2% | Valid: time=  0.4s loss=0.615, TAw acc= 79.0% |
| Epoch 147, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.677, TAw acc= 77.2% | Valid: time=  0.5s loss=0.615, TAw acc= 79.2% |
| Epoch 148, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.669, TAw acc= 77.1% | Valid: time=  0.5s loss=0.600, TAw acc= 79.2% |
| Epoch 149, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.675, TAw acc= 78.1% | Valid: time=  0.5s loss=0.593, TAw acc= 79.4% |
| Epoch 150, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.665, TAw acc= 77.8% | Valid: time=  0.5s loss=0.610, TAw acc= 78.8% |
| Epoch 151, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.688, TAw acc= 76.6% | Valid: time=  0.5s loss=0.602, TAw acc= 79.8% |
| Epoch 152, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.684, TAw acc= 76.3% | Valid: time=  0.5s loss=0.601, TAw acc= 80.6% |
| Epoch 153, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.669, TAw acc= 76.5% | Valid: time=  0.5s loss=0.603, TAw acc= 79.4% |
| Epoch 154, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.666, TAw acc= 77.1% | Valid: time=  0.4s loss=0.613, TAw acc= 79.0% |
| Epoch 155, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.664, TAw acc= 77.6% | Valid: time=  0.5s loss=0.609, TAw acc= 79.6% |
| Epoch 156, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.673, TAw acc= 76.6% | Valid: time=  0.5s loss=0.603, TAw acc= 80.4% |
| Epoch 157, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.664, TAw acc= 77.9% | Valid: time=  0.5s loss=0.607, TAw acc= 78.8% |
| Epoch 158, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.669, TAw acc= 77.4% | Valid: time=  0.4s loss=0.610, TAw acc= 79.8% |
| Epoch 159, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.671, TAw acc= 77.0% | Valid: time=  0.4s loss=0.608, TAw acc= 79.0% |
| Epoch 160, lr=2.9e-03 time=  1.2s/  2.0s | Train: loss=0.689, TAw acc= 76.8% | Valid: time=  0.5s loss=0.609, TAw acc= 80.2% |
| Epoch 161, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.660, TAw acc= 77.8% | Valid: time=  0.4s loss=0.617, TAw acc= 79.8% |
| Epoch 162, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.661, TAw acc= 77.6% | Valid: time=  0.5s loss=0.608, TAw acc= 80.2% |
| Epoch 163, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.669, TAw acc= 77.4% | Valid: time=  0.5s loss=0.608, TAw acc= 80.8% |
| Epoch 164, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.653, TAw acc= 77.9% | Valid: time=  0.5s loss=0.608, TAw acc= 79.8% |
| Epoch 165, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.671, TAw acc= 76.9% | Valid: time=  0.5s loss=0.603, TAw acc= 80.4% |
| Epoch 166, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.649, TAw acc= 78.0% | Valid: time=  0.5s loss=0.600, TAw acc= 80.0% |
| Epoch 167, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.674, TAw acc= 76.8% | Valid: time=  0.5s loss=0.598, TAw acc= 79.2% |
| Epoch 168, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.664, TAw acc= 77.5% | Valid: time=  0.5s loss=0.599, TAw acc= 79.6% |
| Epoch 169, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.655, TAw acc= 77.3% | Valid: time=  0.5s loss=0.599, TAw acc= 79.8% | lr=9.7e-04
| Epoch 170, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.692, TAw acc= 76.1% | Valid: time=  0.5s loss=0.586, TAw acc= 80.6% |
| Epoch 171, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.710, TAw acc= 75.8% | Valid: time=  0.5s loss=0.593, TAw acc= 80.8% |
| Epoch 172, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.680, TAw acc= 76.7% | Valid: time=  0.5s loss=0.598, TAw acc= 80.6% |
| Epoch 173, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.699, TAw acc= 75.9% | Valid: time=  0.5s loss=0.599, TAw acc= 80.8% |
| Epoch 174, lr=9.7e-04 time=  1.4s/  2.1s | Train: loss=0.692, TAw acc= 76.2% | Valid: time=  0.5s loss=0.601, TAw acc= 80.2% |
| Epoch 175, lr=9.7e-04 time=  1.2s/  2.0s | Train: loss=0.684, TAw acc= 76.6% | Valid: time=  0.5s loss=0.597, TAw acc= 80.0% |
| Epoch 176, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.681, TAw acc= 76.7% | Valid: time=  0.5s loss=0.599, TAw acc= 80.2% |
| Epoch 177, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.695, TAw acc= 76.2% | Valid: time=  0.5s loss=0.603, TAw acc= 80.0% |
| Epoch 178, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.682, TAw acc= 76.1% | Valid: time=  0.5s loss=0.601, TAw acc= 79.6% |
| Epoch 179, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.690, TAw acc= 76.0% | Valid: time=  0.5s loss=0.602, TAw acc= 79.6% |
| Epoch 180, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.665, TAw acc= 77.3% | Valid: time=  0.5s loss=0.602, TAw acc= 79.8% |
| Epoch 181, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.666, TAw acc= 77.8% | Valid: time=  0.5s loss=0.600, TAw acc= 79.8% |
| Epoch 182, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.672, TAw acc= 77.4% | Valid: time=  0.5s loss=0.597, TAw acc= 80.0% |
| Epoch 183, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.670, TAw acc= 77.4% | Valid: time=  0.5s loss=0.598, TAw acc= 79.4% |
| Epoch 184, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.664, TAw acc= 77.5% | Valid: time=  0.5s loss=0.603, TAw acc= 79.6% |
| Epoch 185, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.661, TAw acc= 77.4% | Valid: time=  0.5s loss=0.603, TAw acc= 79.4% |
| Epoch 186, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.683, TAw acc= 76.7% | Valid: time=  0.5s loss=0.606, TAw acc= 79.4% |
| Epoch 187, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.690, TAw acc= 75.5% | Valid: time=  0.5s loss=0.606, TAw acc= 80.0% |
| Epoch 188, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.675, TAw acc= 76.8% | Valid: time=  0.5s loss=0.608, TAw acc= 79.4% |
| Epoch 189, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.674, TAw acc= 77.1% | Valid: time=  0.4s loss=0.603, TAw acc= 79.6% |
| Epoch 190, lr=9.7e-04 time=  1.1s/  1.7s | Train: loss=0.679, TAw acc= 76.3% | Valid: time=  0.5s loss=0.602, TAw acc= 79.6% |
| Epoch 191, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.682, TAw acc= 76.4% | Valid: time=  0.5s loss=0.605, TAw acc= 79.6% |
| Epoch 192, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.660, TAw acc= 77.7% | Valid: time=  0.5s loss=0.612, TAw acc= 79.4% |
| Epoch 193, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.662, TAw acc= 77.9% | Valid: time=  0.5s loss=0.607, TAw acc= 79.6% |
| Epoch 194, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.678, TAw acc= 76.2% | Valid: time=  0.5s loss=0.605, TAw acc= 79.8% |
| Epoch 195, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.656, TAw acc= 78.1% | Valid: time=  0.5s loss=0.608, TAw acc= 79.4% |
| Epoch 196, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.668, TAw acc= 77.2% | Valid: time=  0.5s loss=0.607, TAw acc= 79.4% |
| Epoch 197, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.682, TAw acc= 76.7% | Valid: time=  0.5s loss=0.608, TAw acc= 79.6% |
| Epoch 198, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.671, TAw acc= 77.2% | Valid: time=  0.5s loss=0.609, TAw acc= 79.2% |
| Epoch 199, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.654, TAw acc= 78.0% | Valid: time=  0.5s loss=0.610, TAw acc= 79.4% | lr=3.2e-04
| Epoch 200, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.695, TAw acc= 76.5% | Valid: time=  0.4s loss=0.578, TAw acc= 80.8% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.712 | TAw acc= 74.5%, forg=  5.7%| TAg acc= 27.1%, forg= 53.1% <<<
>>> Test on task  1 : loss=1.072 | TAw acc= 63.7%, forg=  5.3%| TAg acc= 15.1%, forg= 34.9% <<<
>>> Test on task  2 : loss=0.647 | TAw acc= 77.8%, forg=  4.3%| TAg acc= 32.4%, forg= 31.9% <<<
>>> Test on task  3 : loss=0.694 | TAw acc= 76.0%, forg=  5.6%| TAg acc= 20.4%, forg= 22.5% <<<
>>> Test on task  4 : loss=0.526 | TAw acc= 83.5%, forg=  3.7%| TAg acc= 44.5%, forg= 14.7% <<<
>>> Test on task  5 : loss=0.884 | TAw acc= 69.0%, forg=  4.3%| TAg acc= 17.3%, forg= 15.4% <<<
>>> Test on task  6 : loss=0.588 | TAw acc= 80.0%, forg=  2.5%| TAg acc= 39.2%, forg=  9.6% <<<
>>> Test on task  7 : loss=0.626 | TAw acc= 79.8%, forg=  0.0%| TAg acc= 40.4%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  8
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-8): 9 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.153, TAw acc= 61.1% | Valid: time=  0.5s loss=0.954, TAw acc= 67.0% | *
| Epoch   2, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.081, TAw acc= 62.7% | Valid: time=  0.5s loss=0.862, TAw acc= 70.6% | *
| Epoch   3, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.069, TAw acc= 63.4% | Valid: time=  0.5s loss=0.867, TAw acc= 72.0% |
| Epoch   4, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=1.040, TAw acc= 64.6% | Valid: time=  0.5s loss=0.854, TAw acc= 71.0% | *
| Epoch   5, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=1.014, TAw acc= 65.7% | Valid: time=  0.4s loss=0.808, TAw acc= 73.2% | *
| Epoch   6, lr=2.6e-02 time=  1.3s/  2.2s | Train: loss=1.020, TAw acc= 66.1% | Valid: time=  0.5s loss=0.844, TAw acc= 70.6% |
| Epoch   7, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.998, TAw acc= 66.0% | Valid: time=  0.5s loss=0.797, TAw acc= 73.2% | *
| Epoch   8, lr=2.6e-02 time=  1.2s/  1.9s | Train: loss=0.983, TAw acc= 66.5% | Valid: time=  0.5s loss=0.828, TAw acc= 71.8% |
| Epoch   9, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.986, TAw acc= 66.5% | Valid: time=  0.5s loss=0.743, TAw acc= 75.0% | *
| Epoch  10, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.975, TAw acc= 67.1% | Valid: time=  0.5s loss=0.727, TAw acc= 77.0% | *
| Epoch  11, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.937, TAw acc= 67.9% | Valid: time=  0.5s loss=0.827, TAw acc= 74.8% |
| Epoch  12, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.933, TAw acc= 68.2% | Valid: time=  0.5s loss=0.780, TAw acc= 77.4% |
| Epoch  13, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.933, TAw acc= 67.8% | Valid: time=  0.5s loss=0.791, TAw acc= 74.6% |
| Epoch  14, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.942, TAw acc= 68.4% | Valid: time=  0.5s loss=0.779, TAw acc= 74.2% |
| Epoch  15, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.953, TAw acc= 67.0% | Valid: time=  0.5s loss=0.761, TAw acc= 75.6% |
| Epoch  16, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.914, TAw acc= 68.7% | Valid: time=  0.5s loss=0.753, TAw acc= 76.8% |
| Epoch  17, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.913, TAw acc= 69.2% | Valid: time=  0.5s loss=0.790, TAw acc= 73.8% |
| Epoch  18, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.932, TAw acc= 68.4% | Valid: time=  0.4s loss=0.801, TAw acc= 74.2% |
| Epoch  19, lr=2.6e-02 time=  1.2s/  1.5s | Train: loss=0.921, TAw acc= 69.8% | Valid: time=  0.5s loss=0.759, TAw acc= 75.6% |
| Epoch  20, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.915, TAw acc= 70.1% | Valid: time=  0.5s loss=0.762, TAw acc= 75.4% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.905, TAw acc= 68.9% | Valid: time=  0.5s loss=0.770, TAw acc= 76.4% |
| Epoch  22, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.902, TAw acc= 70.5% | Valid: time=  0.5s loss=0.758, TAw acc= 77.4% |
| Epoch  23, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.873, TAw acc= 70.7% | Valid: time=  0.5s loss=0.755, TAw acc= 76.8% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.923, TAw acc= 67.9% | Valid: time=  0.5s loss=0.719, TAw acc= 76.8% | *
| Epoch  25, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.898, TAw acc= 69.8% | Valid: time=  0.5s loss=0.770, TAw acc= 76.2% |
| Epoch  26, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.885, TAw acc= 69.7% | Valid: time=  0.5s loss=0.718, TAw acc= 79.2% | *
| Epoch  27, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.893, TAw acc= 69.8% | Valid: time=  0.5s loss=0.772, TAw acc= 75.4% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.881, TAw acc= 69.9% | Valid: time=  0.5s loss=0.782, TAw acc= 75.4% |
| Epoch  29, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.901, TAw acc= 68.5% | Valid: time=  0.5s loss=0.741, TAw acc= 77.8% |
| Epoch  30, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.864, TAw acc= 69.9% | Valid: time=  0.5s loss=0.770, TAw acc= 76.0% |
| Epoch  31, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.869, TAw acc= 70.8% | Valid: time=  0.5s loss=0.830, TAw acc= 73.4% |
| Epoch  32, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.873, TAw acc= 70.5% | Valid: time=  0.5s loss=0.746, TAw acc= 77.0% |
| Epoch  33, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.875, TAw acc= 70.6% | Valid: time=  0.4s loss=0.741, TAw acc= 77.0% |
| Epoch  34, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.872, TAw acc= 70.5% | Valid: time=  0.5s loss=0.745, TAw acc= 76.8% |
| Epoch  35, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.882, TAw acc= 70.2% | Valid: time=  0.5s loss=0.779, TAw acc= 75.4% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.864, TAw acc= 69.9% | Valid: time=  0.5s loss=0.735, TAw acc= 78.2% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.874, TAw acc= 70.5% | Valid: time=  0.5s loss=0.727, TAw acc= 79.0% |
| Epoch  38, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.886, TAw acc= 70.2% | Valid: time=  0.5s loss=0.769, TAw acc= 77.0% |
| Epoch  39, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.887, TAw acc= 69.9% | Valid: time=  0.5s loss=0.779, TAw acc= 75.4% |
| Epoch  40, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.844, TAw acc= 71.4% | Valid: time=  0.5s loss=0.718, TAw acc= 76.6% |
| Epoch  41, lr=2.6e-02 time=  1.1s/  2.2s | Train: loss=0.851, TAw acc= 71.5% | Valid: time=  0.5s loss=0.735, TAw acc= 76.4% |
| Epoch  42, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.855, TAw acc= 69.8% | Valid: time=  0.5s loss=0.778, TAw acc= 76.8% |
| Epoch  43, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=0.821, TAw acc= 72.2% | Valid: time=  0.5s loss=0.729, TAw acc= 76.8% |
| Epoch  44, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.823, TAw acc= 72.7% | Valid: time=  0.5s loss=0.708, TAw acc= 77.0% | *
| Epoch  45, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.861, TAw acc= 69.9% | Valid: time=  0.5s loss=0.731, TAw acc= 77.6% |
| Epoch  46, lr=2.6e-02 time=  1.3s/  1.8s | Train: loss=0.833, TAw acc= 72.0% | Valid: time=  0.5s loss=0.759, TAw acc= 77.2% |
| Epoch  47, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.854, TAw acc= 70.1% | Valid: time=  0.5s loss=0.713, TAw acc= 79.2% |
| Epoch  48, lr=2.6e-02 time=  1.3s/  1.7s | Train: loss=0.833, TAw acc= 72.4% | Valid: time=  0.5s loss=0.719, TAw acc= 78.8% |
| Epoch  49, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.855, TAw acc= 71.1% | Valid: time=  0.5s loss=0.809, TAw acc= 74.8% |
| Epoch  50, lr=2.6e-02 time=  1.4s/  1.8s | Train: loss=0.867, TAw acc= 70.4% | Valid: time=  0.5s loss=0.815, TAw acc= 75.6% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.850, TAw acc= 71.2% | Valid: time=  0.5s loss=0.762, TAw acc= 76.8% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.851, TAw acc= 71.3% | Valid: time=  0.5s loss=0.731, TAw acc= 77.8% |
| Epoch  53, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.830, TAw acc= 71.5% | Valid: time=  0.5s loss=0.780, TAw acc= 76.0% |
| Epoch  54, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=0.803, TAw acc= 72.1% | Valid: time=  0.5s loss=0.743, TAw acc= 77.2% |
| Epoch  55, lr=2.6e-02 time=  1.3s/  2.3s | Train: loss=0.817, TAw acc= 72.5% | Valid: time=  0.5s loss=0.743, TAw acc= 78.8% |
| Epoch  56, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.825, TAw acc= 72.0% | Valid: time=  0.5s loss=0.726, TAw acc= 77.8% |
| Epoch  57, lr=2.6e-02 time=  1.3s/  1.4s | Train: loss=0.817, TAw acc= 72.2% | Valid: time=  0.5s loss=0.754, TAw acc= 77.6% |
| Epoch  58, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.836, TAw acc= 72.2% | Valid: time=  0.5s loss=0.740, TAw acc= 77.8% |
| Epoch  59, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.811, TAw acc= 71.9% | Valid: time=  0.5s loss=0.748, TAw acc= 77.2% |
| Epoch  60, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.4% | Valid: time=  0.5s loss=0.747, TAw acc= 77.6% |
| Epoch  61, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.794, TAw acc= 73.3% | Valid: time=  0.5s loss=0.767, TAw acc= 77.2% |
| Epoch  62, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.852, TAw acc= 71.4% | Valid: time=  0.5s loss=0.807, TAw acc= 75.6% |
| Epoch  63, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 72.5% | Valid: time=  0.5s loss=0.762, TAw acc= 77.0% |
| Epoch  64, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 72.6% | Valid: time=  0.5s loss=0.734, TAw acc= 78.2% |
| Epoch  65, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.796, TAw acc= 72.6% | Valid: time=  0.5s loss=0.796, TAw acc= 77.2% |
| Epoch  66, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.805, TAw acc= 73.2% | Valid: time=  0.5s loss=0.758, TAw acc= 76.2% |
| Epoch  67, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.800, TAw acc= 73.5% | Valid: time=  0.5s loss=0.755, TAw acc= 77.0% |
| Epoch  68, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.798, TAw acc= 72.7% | Valid: time=  0.5s loss=0.740, TAw acc= 76.8% |
| Epoch  69, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.6% | Valid: time=  0.5s loss=0.754, TAw acc= 76.6% |
| Epoch  70, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.793, TAw acc= 72.9% | Valid: time=  0.5s loss=0.745, TAw acc= 78.0% |
| Epoch  71, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.801, TAw acc= 73.2% | Valid: time=  0.5s loss=0.742, TAw acc= 77.0% |
| Epoch  72, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.793, TAw acc= 73.1% | Valid: time=  0.5s loss=0.695, TAw acc= 78.8% | *
| Epoch  73, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 72.8% | Valid: time=  0.5s loss=0.774, TAw acc= 77.6% |
| Epoch  74, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.796, TAw acc= 73.5% | Valid: time=  0.5s loss=0.763, TAw acc= 76.2% |
| Epoch  75, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.784, TAw acc= 73.4% | Valid: time=  0.5s loss=0.780, TAw acc= 75.8% |
| Epoch  76, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.770, TAw acc= 74.5% | Valid: time=  0.5s loss=0.756, TAw acc= 77.8% |
| Epoch  77, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.777, TAw acc= 73.8% | Valid: time=  0.5s loss=0.736, TAw acc= 77.6% |
| Epoch  78, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.6% | Valid: time=  0.5s loss=0.766, TAw acc= 76.0% |
| Epoch  79, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.797, TAw acc= 73.6% | Valid: time=  0.4s loss=0.761, TAw acc= 75.8% |
| Epoch  80, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.787, TAw acc= 74.1% | Valid: time=  0.5s loss=0.719, TAw acc= 77.2% |
| Epoch  81, lr=2.6e-02 time=  1.2s/  2.0s | Train: loss=0.784, TAw acc= 73.3% | Valid: time=  0.5s loss=0.722, TAw acc= 77.6% |
| Epoch  82, lr=2.6e-02 time=  1.3s/  1.6s | Train: loss=0.793, TAw acc= 72.5% | Valid: time=  0.3s loss=0.751, TAw acc= 75.4% |
| Epoch  83, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.793, TAw acc= 73.6% | Valid: time=  0.5s loss=0.767, TAw acc= 77.0% |
| Epoch  84, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.769, TAw acc= 74.4% | Valid: time=  0.5s loss=0.767, TAw acc= 77.6% |
| Epoch  85, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.790, TAw acc= 73.7% | Valid: time=  0.4s loss=0.714, TAw acc= 77.8% |
| Epoch  86, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.784, TAw acc= 73.7% | Valid: time=  0.5s loss=0.707, TAw acc= 79.6% |
| Epoch  87, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.772, TAw acc= 73.9% | Valid: time=  0.5s loss=0.714, TAw acc= 78.2% |
| Epoch  88, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.775, TAw acc= 73.5% | Valid: time=  0.5s loss=0.716, TAw acc= 76.6% |
| Epoch  89, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.775, TAw acc= 73.8% | Valid: time=  0.5s loss=0.723, TAw acc= 78.2% |
| Epoch  90, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.776, TAw acc= 74.2% | Valid: time=  0.5s loss=0.738, TAw acc= 77.4% |
| Epoch  91, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.773, TAw acc= 73.9% | Valid: time=  0.5s loss=0.683, TAw acc= 78.2% | *
| Epoch  92, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.758, TAw acc= 75.0% | Valid: time=  0.5s loss=0.735, TAw acc= 78.0% |
| Epoch  93, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.759, TAw acc= 73.9% | Valid: time=  0.5s loss=0.759, TAw acc= 77.2% |
| Epoch  94, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.773, TAw acc= 74.4% | Valid: time=  0.5s loss=0.769, TAw acc= 77.6% |
| Epoch  95, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.767, TAw acc= 74.0% | Valid: time=  0.5s loss=0.715, TAw acc= 78.2% |
| Epoch  96, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.768, TAw acc= 74.6% | Valid: time=  0.5s loss=0.802, TAw acc= 76.2% |
| Epoch  97, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.769, TAw acc= 74.6% | Valid: time=  0.5s loss=0.750, TAw acc= 78.0% |
| Epoch  98, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.755, TAw acc= 75.3% | Valid: time=  0.5s loss=0.743, TAw acc= 77.4% |
| Epoch  99, lr=2.6e-02 time=  1.4s/  2.2s | Train: loss=0.767, TAw acc= 73.7% | Valid: time=  0.5s loss=0.754, TAw acc= 75.8% |
| Epoch 100, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.745, TAw acc= 75.6% | Valid: time=  0.5s loss=0.769, TAw acc= 76.2% |
| Epoch 101, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.771, TAw acc= 74.2% | Valid: time=  0.5s loss=0.739, TAw acc= 77.8% |
| Epoch 102, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.780, TAw acc= 73.6% | Valid: time=  0.5s loss=0.755, TAw acc= 77.6% |
| Epoch 103, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.754, TAw acc= 75.0% | Valid: time=  0.5s loss=0.760, TAw acc= 76.6% |
| Epoch 104, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.768, TAw acc= 74.2% | Valid: time=  0.5s loss=0.750, TAw acc= 76.8% |
| Epoch 105, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.764, TAw acc= 74.5% | Valid: time=  0.5s loss=0.693, TAw acc= 77.4% |
| Epoch 106, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.765, TAw acc= 74.1% | Valid: time=  0.5s loss=0.742, TAw acc= 76.2% |
| Epoch 107, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.755, TAw acc= 74.2% | Valid: time=  0.5s loss=0.732, TAw acc= 77.6% |
| Epoch 108, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.756, TAw acc= 74.0% | Valid: time=  0.5s loss=0.759, TAw acc= 77.0% |
| Epoch 109, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.756, TAw acc= 74.4% | Valid: time=  0.5s loss=0.738, TAw acc= 76.4% |
| Epoch 110, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.766, TAw acc= 73.7% | Valid: time=  0.5s loss=0.724, TAw acc= 77.6% |
| Epoch 111, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.763, TAw acc= 74.8% | Valid: time=  0.5s loss=0.798, TAw acc= 75.4% |
| Epoch 112, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.741, TAw acc= 75.4% | Valid: time=  0.5s loss=0.740, TAw acc= 78.2% |
| Epoch 113, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.725, TAw acc= 75.8% | Valid: time=  0.5s loss=0.727, TAw acc= 78.0% |
| Epoch 114, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.734, TAw acc= 75.2% | Valid: time=  0.5s loss=0.812, TAw acc= 75.4% |
| Epoch 115, lr=2.6e-02 time=  1.4s/  2.3s | Train: loss=0.748, TAw acc= 74.9% | Valid: time=  0.5s loss=0.752, TAw acc= 77.2% |
| Epoch 116, lr=2.6e-02 time=  1.3s/  1.5s | Train: loss=0.755, TAw acc= 74.5% | Valid: time=  0.4s loss=0.772, TAw acc= 77.6% |
| Epoch 117, lr=2.6e-02 time=  1.4s/  1.9s | Train: loss=0.722, TAw acc= 75.6% | Valid: time=  0.3s loss=0.755, TAw acc= 78.4% |
| Epoch 118, lr=2.6e-02 time=  1.2s/  1.6s | Train: loss=0.745, TAw acc= 74.3% | Valid: time=  0.4s loss=0.787, TAw acc= 77.4% |
| Epoch 119, lr=2.6e-02 time=  1.4s/  1.6s | Train: loss=0.740, TAw acc= 74.9% | Valid: time=  0.3s loss=0.749, TAw acc= 77.2% |
| Epoch 120, lr=2.6e-02 time=  0.8s/  1.0s | Train: loss=0.760, TAw acc= 74.0% | Valid: time=  0.3s loss=0.788, TAw acc= 77.6% |
| Epoch 121, lr=2.6e-02 time=  0.8s/  1.3s | Train: loss=0.742, TAw acc= 74.5% | Valid: time=  0.4s loss=0.769, TAw acc= 78.2% | lr=8.8e-03
| Epoch 122, lr=8.8e-03 time=  1.2s/  1.5s | Train: loss=0.766, TAw acc= 74.9% | Valid: time=  0.5s loss=0.697, TAw acc= 79.0% |
| Epoch 123, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.756, TAw acc= 74.8% | Valid: time=  0.5s loss=0.693, TAw acc= 79.0% |
| Epoch 124, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.733, TAw acc= 75.1% | Valid: time=  0.5s loss=0.703, TAw acc= 79.8% |
| Epoch 125, lr=8.8e-03 time=  1.4s/  2.1s | Train: loss=0.751, TAw acc= 75.5% | Valid: time=  0.5s loss=0.717, TAw acc= 78.2% |
| Epoch 126, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.742, TAw acc= 75.6% | Valid: time=  0.5s loss=0.750, TAw acc= 78.0% |
| Epoch 127, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.740, TAw acc= 76.0% | Valid: time=  0.5s loss=0.708, TAw acc= 78.4% |
| Epoch 128, lr=8.8e-03 time=  1.4s/  2.0s | Train: loss=0.746, TAw acc= 75.1% | Valid: time=  0.4s loss=0.722, TAw acc= 78.4% |
| Epoch 129, lr=8.8e-03 time=  1.1s/  2.1s | Train: loss=0.737, TAw acc= 75.2% | Valid: time=  0.5s loss=0.736, TAw acc= 78.0% |
| Epoch 130, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.727, TAw acc= 75.8% | Valid: time=  0.5s loss=0.743, TAw acc= 78.6% |
| Epoch 131, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.737, TAw acc= 75.2% | Valid: time=  0.5s loss=0.745, TAw acc= 77.6% |
| Epoch 132, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.742, TAw acc= 75.2% | Valid: time=  0.5s loss=0.742, TAw acc= 79.2% |
| Epoch 133, lr=8.8e-03 time=  1.4s/  2.5s | Train: loss=0.710, TAw acc= 77.0% | Valid: time=  0.5s loss=0.703, TAw acc= 78.8% |
| Epoch 134, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.721, TAw acc= 76.2% | Valid: time=  0.5s loss=0.716, TAw acc= 78.4% |
| Epoch 135, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.728, TAw acc= 75.8% | Valid: time=  0.5s loss=0.716, TAw acc= 79.2% |
| Epoch 136, lr=8.8e-03 time=  1.3s/  1.6s | Train: loss=0.722, TAw acc= 76.5% | Valid: time=  0.4s loss=0.701, TAw acc= 78.8% |
| Epoch 137, lr=8.8e-03 time=  1.2s/  2.4s | Train: loss=0.718, TAw acc= 76.3% | Valid: time=  0.4s loss=0.712, TAw acc= 79.0% |
| Epoch 138, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.732, TAw acc= 75.5% | Valid: time=  0.4s loss=0.718, TAw acc= 78.6% |
| Epoch 139, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.732, TAw acc= 75.7% | Valid: time=  0.4s loss=0.731, TAw acc= 78.6% |
| Epoch 140, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.725, TAw acc= 75.6% | Valid: time=  0.5s loss=0.736, TAw acc= 79.6% |
| Epoch 141, lr=8.8e-03 time=  1.2s/  2.0s | Train: loss=0.743, TAw acc= 75.9% | Valid: time=  0.5s loss=0.730, TAw acc= 79.2% |
| Epoch 142, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.722, TAw acc= 75.8% | Valid: time=  0.5s loss=0.707, TAw acc= 78.6% |
| Epoch 143, lr=8.8e-03 time=  1.4s/  1.8s | Train: loss=0.710, TAw acc= 76.0% | Valid: time=  0.4s loss=0.719, TAw acc= 78.8% |
| Epoch 144, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.704, TAw acc= 77.5% | Valid: time=  0.5s loss=0.729, TAw acc= 78.4% |
| Epoch 145, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.724, TAw acc= 76.1% | Valid: time=  0.5s loss=0.722, TAw acc= 78.2% |
| Epoch 146, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.710, TAw acc= 76.0% | Valid: time=  0.5s loss=0.720, TAw acc= 77.8% |
| Epoch 147, lr=8.8e-03 time=  1.4s/  2.0s | Train: loss=0.725, TAw acc= 76.1% | Valid: time=  0.4s loss=0.711, TAw acc= 77.6% |
| Epoch 148, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.699, TAw acc= 76.7% | Valid: time=  0.5s loss=0.743, TAw acc= 78.4% |
| Epoch 149, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.720, TAw acc= 76.3% | Valid: time=  0.5s loss=0.727, TAw acc= 77.8% |
| Epoch 150, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.701, TAw acc= 76.6% | Valid: time=  0.5s loss=0.725, TAw acc= 77.8% |
| Epoch 151, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.724, TAw acc= 75.8% | Valid: time=  0.5s loss=0.754, TAw acc= 77.2% | lr=2.9e-03
| Epoch 152, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.758, TAw acc= 75.0% | Valid: time=  0.5s loss=0.702, TAw acc= 78.4% |
| Epoch 153, lr=2.9e-03 time=  1.4s/  2.0s | Train: loss=0.737, TAw acc= 76.3% | Valid: time=  0.4s loss=0.688, TAw acc= 78.4% |
| Epoch 154, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.759, TAw acc= 74.6% | Valid: time=  0.5s loss=0.698, TAw acc= 78.4% |
| Epoch 155, lr=2.9e-03 time=  1.4s/  2.0s | Train: loss=0.742, TAw acc= 75.2% | Valid: time=  0.5s loss=0.695, TAw acc= 78.6% |
| Epoch 156, lr=2.9e-03 time=  1.3s/  1.5s | Train: loss=0.722, TAw acc= 76.4% | Valid: time=  0.4s loss=0.718, TAw acc= 79.0% |
| Epoch 157, lr=2.9e-03 time=  1.0s/  2.4s | Train: loss=0.721, TAw acc= 75.8% | Valid: time=  0.3s loss=0.712, TAw acc= 78.8% |
| Epoch 158, lr=2.9e-03 time=  1.4s/  1.8s | Train: loss=0.717, TAw acc= 76.1% | Valid: time=  0.4s loss=0.702, TAw acc= 79.6% |
| Epoch 159, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.732, TAw acc= 75.6% | Valid: time=  0.5s loss=0.704, TAw acc= 79.4% |
| Epoch 160, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.740, TAw acc= 75.4% | Valid: time=  0.4s loss=0.709, TAw acc= 79.2% |
| Epoch 161, lr=2.9e-03 time=  1.2s/  2.2s | Train: loss=0.744, TAw acc= 75.3% | Valid: time=  0.5s loss=0.700, TAw acc= 79.0% |
| Epoch 162, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.723, TAw acc= 75.7% | Valid: time=  0.5s loss=0.707, TAw acc= 79.2% |
| Epoch 163, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.746, TAw acc= 75.5% | Valid: time=  0.5s loss=0.715, TAw acc= 78.6% |
| Epoch 164, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.736, TAw acc= 75.2% | Valid: time=  0.5s loss=0.710, TAw acc= 78.6% |
| Epoch 165, lr=2.9e-03 time=  1.4s/  1.5s | Train: loss=0.738, TAw acc= 75.8% | Valid: time=  0.4s loss=0.709, TAw acc= 78.4% |
| Epoch 166, lr=2.9e-03 time=  1.1s/  2.4s | Train: loss=0.738, TAw acc= 75.7% | Valid: time=  0.5s loss=0.712, TAw acc= 79.0% |
| Epoch 167, lr=2.9e-03 time=  1.4s/  2.3s | Train: loss=0.728, TAw acc= 76.1% | Valid: time=  0.5s loss=0.716, TAw acc= 79.0% |
| Epoch 168, lr=2.9e-03 time=  1.2s/  2.2s | Train: loss=0.731, TAw acc= 75.1% | Valid: time=  0.5s loss=0.709, TAw acc= 78.6% |
| Epoch 169, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.748, TAw acc= 74.8% | Valid: time=  0.5s loss=0.707, TAw acc= 78.4% |
| Epoch 170, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.714, TAw acc= 76.6% | Valid: time=  0.5s loss=0.706, TAw acc= 79.0% |
| Epoch 171, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.750, TAw acc= 74.8% | Valid: time=  0.5s loss=0.702, TAw acc= 78.8% |
| Epoch 172, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.726, TAw acc= 75.4% | Valid: time=  0.5s loss=0.698, TAw acc= 78.2% |
| Epoch 173, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.749, TAw acc= 74.8% | Valid: time=  0.5s loss=0.701, TAw acc= 78.2% |
| Epoch 174, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.706, TAw acc= 76.4% | Valid: time=  0.5s loss=0.708, TAw acc= 78.8% |
| Epoch 175, lr=2.9e-03 time=  1.3s/  1.4s | Train: loss=0.712, TAw acc= 76.0% | Valid: time=  0.4s loss=0.707, TAw acc= 79.0% |
| Epoch 176, lr=2.9e-03 time=  1.2s/  2.4s | Train: loss=0.737, TAw acc= 75.5% | Valid: time=  0.5s loss=0.692, TAw acc= 78.6% |
| Epoch 177, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.746, TAw acc= 74.9% | Valid: time=  0.5s loss=0.699, TAw acc= 79.2% |
| Epoch 178, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.713, TAw acc= 77.0% | Valid: time=  0.5s loss=0.693, TAw acc= 78.8% |
| Epoch 179, lr=2.9e-03 time=  1.4s/  1.8s | Train: loss=0.712, TAw acc= 76.3% | Valid: time=  0.5s loss=0.706, TAw acc= 79.2% |
| Epoch 180, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.717, TAw acc= 76.0% | Valid: time=  0.5s loss=0.701, TAw acc= 78.8% |
| Epoch 181, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.703, TAw acc= 76.9% | Valid: time=  0.4s loss=0.711, TAw acc= 79.8% | lr=9.7e-04
| Epoch 182, lr=9.7e-04 time=  1.4s/  1.8s | Train: loss=0.730, TAw acc= 75.8% | Valid: time=  0.3s loss=0.685, TAw acc= 78.0% |
| Epoch 183, lr=9.7e-04 time=  1.1s/  1.0s | Train: loss=0.755, TAw acc= 74.5% | Valid: time=  0.3s loss=0.690, TAw acc= 78.4% |
| Epoch 184, lr=9.7e-04 time=  0.8s/  1.0s | Train: loss=0.750, TAw acc= 75.2% | Valid: time=  0.3s loss=0.693, TAw acc= 78.6% |
| Epoch 185, lr=9.7e-04 time=  0.8s/  1.0s | Train: loss=0.740, TAw acc= 75.3% | Valid: time=  0.3s loss=0.692, TAw acc= 79.4% |
| Epoch 186, lr=9.7e-04 time=  0.8s/  2.0s | Train: loss=0.726, TAw acc= 75.9% | Valid: time=  0.5s loss=0.697, TAw acc= 78.8% |
| Epoch 187, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.732, TAw acc= 76.1% | Valid: time=  0.5s loss=0.694, TAw acc= 78.0% |
| Epoch 188, lr=9.7e-04 time=  1.1s/  2.4s | Train: loss=0.745, TAw acc= 75.1% | Valid: time=  0.5s loss=0.692, TAw acc= 79.0% |
| Epoch 189, lr=9.7e-04 time=  1.3s/  1.3s | Train: loss=0.767, TAw acc= 74.9% | Valid: time=  0.3s loss=0.692, TAw acc= 78.8% |
| Epoch 190, lr=9.7e-04 time=  0.8s/  1.4s | Train: loss=0.741, TAw acc= 75.1% | Valid: time=  0.5s loss=0.691, TAw acc= 79.0% |
| Epoch 191, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.740, TAw acc= 75.7% | Valid: time=  0.4s loss=0.690, TAw acc= 79.0% |
| Epoch 192, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.726, TAw acc= 75.3% | Valid: time=  0.5s loss=0.690, TAw acc= 78.4% |
| Epoch 193, lr=9.7e-04 time=  1.4s/  1.5s | Train: loss=0.731, TAw acc= 76.2% | Valid: time=  0.4s loss=0.688, TAw acc= 79.0% |
| Epoch 194, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.730, TAw acc= 75.7% | Valid: time=  0.5s loss=0.694, TAw acc= 79.2% |
| Epoch 195, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.736, TAw acc= 75.8% | Valid: time=  0.5s loss=0.694, TAw acc= 78.4% |
| Epoch 196, lr=9.7e-04 time=  1.3s/  2.2s | Train: loss=0.737, TAw acc= 75.9% | Valid: time=  0.5s loss=0.699, TAw acc= 78.6% |
| Epoch 197, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.734, TAw acc= 75.8% | Valid: time=  0.5s loss=0.698, TAw acc= 79.2% |
| Epoch 198, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.750, TAw acc= 75.0% | Valid: time=  0.5s loss=0.698, TAw acc= 78.4% |
| Epoch 199, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.753, TAw acc= 75.0% | Valid: time=  0.5s loss=0.696, TAw acc= 78.6% |
| Epoch 200, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.756, TAw acc= 75.0% | Valid: time=  0.5s loss=0.700, TAw acc= 78.6% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.778 | TAw acc= 73.2%, forg=  7.0%| TAg acc= 23.9%, forg= 56.3% <<<
>>> Test on task  1 : loss=1.071 | TAw acc= 62.2%, forg=  6.8%| TAg acc= 15.0%, forg= 35.0% <<<
>>> Test on task  2 : loss=0.704 | TAw acc= 76.9%, forg=  5.2%| TAg acc= 31.1%, forg= 33.2% <<<
>>> Test on task  3 : loss=0.701 | TAw acc= 75.2%, forg=  6.4%| TAg acc= 16.1%, forg= 26.8% <<<
>>> Test on task  4 : loss=0.544 | TAw acc= 83.1%, forg=  4.1%| TAg acc= 37.7%, forg= 21.5% <<<
>>> Test on task  5 : loss=0.859 | TAw acc= 68.9%, forg=  4.4%| TAg acc= 19.3%, forg= 13.4% <<<
>>> Test on task  6 : loss=0.699 | TAw acc= 76.6%, forg=  5.9%| TAg acc= 26.9%, forg= 21.9% <<<
>>> Test on task  7 : loss=0.643 | TAw acc= 77.1%, forg=  2.7%| TAg acc= 29.8%, forg= 10.6% <<<
>>> Test on task  8 : loss=0.645 | TAw acc= 80.3%, forg=  0.0%| TAg acc= 49.6%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
Task  9
************************************************************************************************************
LLL_Net(
  (model): ResNet50_32(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (4): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (5): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (3): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (4): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (5): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (6): Sequential(
        (0): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
        )
        (1): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
        (2): BottleNeck(
          (residual_function): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (5): LeakyReLU(negative_slope=0.01, inplace=True)
            (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (shortcut): Sequential()
        )
      )
      (7): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Sequential(
      (0): Dropout(p=0.417598542370663, inplace=False)
      (1): Linear(in_features=1024, out_features=1024, bias=False)
      (2): ReLU()
    )
    (fc): Sequential()
  )
  (heads): ModuleList(
    (0-9): 10 x Linear(in_features=1024, out_features=10, bias=True)
  )
)
| Epoch   1, lr=2.6e-02 time=  1.2s/  2.4s | Train: loss=1.156, TAw acc= 59.7% | Valid: time=  0.5s loss=0.922, TAw acc= 70.4% | *
| Epoch   2, lr=2.6e-02 time=  1.3s/  2.0s | Train: loss=1.111, TAw acc= 62.0% | Valid: time=  0.5s loss=0.909, TAw acc= 69.8% | *
| Epoch   3, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=1.055, TAw acc= 63.8% | Valid: time=  0.5s loss=0.970, TAw acc= 68.6% |
| Epoch   4, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=1.054, TAw acc= 64.4% | Valid: time=  0.5s loss=0.849, TAw acc= 71.0% | *
| Epoch   5, lr=2.6e-02 time=  1.2s/  2.0s | Train: loss=1.045, TAw acc= 63.8% | Valid: time=  0.4s loss=0.893, TAw acc= 70.6% |
| Epoch   6, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=1.013, TAw acc= 66.2% | Valid: time=  0.5s loss=0.893, TAw acc= 69.6% |
| Epoch   7, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.989, TAw acc= 66.2% | Valid: time=  0.5s loss=0.853, TAw acc= 71.0% |
| Epoch   8, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.998, TAw acc= 64.4% | Valid: time=  0.5s loss=0.850, TAw acc= 72.2% |
| Epoch   9, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.977, TAw acc= 66.1% | Valid: time=  0.5s loss=0.823, TAw acc= 72.2% | *
| Epoch  10, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.989, TAw acc= 65.8% | Valid: time=  0.5s loss=0.832, TAw acc= 71.4% |
| Epoch  11, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.940, TAw acc= 67.6% | Valid: time=  0.5s loss=0.821, TAw acc= 72.6% | *
| Epoch  12, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.946, TAw acc= 67.2% | Valid: time=  0.5s loss=0.923, TAw acc= 69.6% |
| Epoch  13, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.944, TAw acc= 67.6% | Valid: time=  0.5s loss=0.843, TAw acc= 72.4% |
| Epoch  14, lr=2.6e-02 time=  1.4s/  1.7s | Train: loss=0.934, TAw acc= 67.8% | Valid: time=  0.4s loss=0.861, TAw acc= 72.2% |
| Epoch  15, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.953, TAw acc= 67.4% | Valid: time=  0.5s loss=0.826, TAw acc= 73.4% |
| Epoch  16, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.938, TAw acc= 67.1% | Valid: time=  0.5s loss=0.849, TAw acc= 71.6% |
| Epoch  17, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.942, TAw acc= 67.4% | Valid: time=  0.5s loss=0.834, TAw acc= 71.0% |
| Epoch  18, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.937, TAw acc= 67.9% | Valid: time=  0.5s loss=1.018, TAw acc= 69.4% |
| Epoch  19, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.910, TAw acc= 68.3% | Valid: time=  0.5s loss=0.855, TAw acc= 71.8% |
| Epoch  20, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.924, TAw acc= 68.3% | Valid: time=  0.5s loss=0.847, TAw acc= 73.6% |
| Epoch  21, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.898, TAw acc= 69.2% | Valid: time=  0.5s loss=0.810, TAw acc= 73.0% | *
| Epoch  22, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.898, TAw acc= 69.6% | Valid: time=  0.5s loss=0.837, TAw acc= 71.8% |
| Epoch  23, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.892, TAw acc= 69.5% | Valid: time=  0.5s loss=0.837, TAw acc= 71.0% |
| Epoch  24, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.876, TAw acc= 69.2% | Valid: time=  0.5s loss=0.845, TAw acc= 71.8% |
| Epoch  25, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.906, TAw acc= 69.0% | Valid: time=  0.5s loss=0.864, TAw acc= 72.4% |
| Epoch  26, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.884, TAw acc= 69.7% | Valid: time=  0.5s loss=0.828, TAw acc= 74.4% |
| Epoch  27, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.902, TAw acc= 68.7% | Valid: time=  0.5s loss=0.836, TAw acc= 73.4% |
| Epoch  28, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.868, TAw acc= 69.5% | Valid: time=  0.5s loss=0.896, TAw acc= 70.4% |
| Epoch  29, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.878, TAw acc= 69.7% | Valid: time=  0.5s loss=0.895, TAw acc= 71.2% |
| Epoch  30, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.888, TAw acc= 69.0% | Valid: time=  0.5s loss=0.821, TAw acc= 73.8% |
| Epoch  31, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.878, TAw acc= 69.7% | Valid: time=  0.5s loss=0.815, TAw acc= 73.6% |
| Epoch  32, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.878, TAw acc= 69.8% | Valid: time=  0.5s loss=0.752, TAw acc= 75.2% | *
| Epoch  33, lr=2.6e-02 time=  1.2s/  2.0s | Train: loss=0.872, TAw acc= 70.2% | Valid: time=  0.5s loss=0.836, TAw acc= 73.2% |
| Epoch  34, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.869, TAw acc= 70.3% | Valid: time=  0.5s loss=0.854, TAw acc= 71.0% |
| Epoch  35, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.864, TAw acc= 70.6% | Valid: time=  0.5s loss=0.831, TAw acc= 72.6% |
| Epoch  36, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.836, TAw acc= 71.6% | Valid: time=  0.5s loss=0.837, TAw acc= 73.2% |
| Epoch  37, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.841, TAw acc= 72.2% | Valid: time=  0.5s loss=0.744, TAw acc= 74.4% | *
| Epoch  38, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.856, TAw acc= 70.9% | Valid: time=  0.5s loss=0.841, TAw acc= 73.8% |
| Epoch  39, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.855, TAw acc= 70.2% | Valid: time=  0.5s loss=0.880, TAw acc= 73.2% |
| Epoch  40, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.834, TAw acc= 72.1% | Valid: time=  0.5s loss=0.790, TAw acc= 73.6% |
| Epoch  41, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.857, TAw acc= 70.5% | Valid: time=  0.5s loss=0.794, TAw acc= 72.6% |
| Epoch  42, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.834, TAw acc= 71.2% | Valid: time=  0.5s loss=0.860, TAw acc= 74.2% |
| Epoch  43, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.841, TAw acc= 71.2% | Valid: time=  0.4s loss=0.798, TAw acc= 73.8% |
| Epoch  44, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.837, TAw acc= 70.5% | Valid: time=  0.5s loss=0.810, TAw acc= 73.2% |
| Epoch  45, lr=2.6e-02 time=  1.2s/  2.2s | Train: loss=0.845, TAw acc= 71.3% | Valid: time=  0.4s loss=0.927, TAw acc= 71.4% |
| Epoch  46, lr=2.6e-02 time=  1.4s/  2.1s | Train: loss=0.840, TAw acc= 71.8% | Valid: time=  0.4s loss=0.829, TAw acc= 74.4% |
| Epoch  47, lr=2.6e-02 time=  1.3s/  2.4s | Train: loss=0.821, TAw acc= 72.5% | Valid: time=  0.5s loss=0.876, TAw acc= 74.6% |
| Epoch  48, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.819, TAw acc= 72.3% | Valid: time=  0.5s loss=0.824, TAw acc= 73.6% |
| Epoch  49, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.811, TAw acc= 72.8% | Valid: time=  0.5s loss=0.844, TAw acc= 72.6% |
| Epoch  50, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.858, TAw acc= 70.0% | Valid: time=  0.5s loss=0.931, TAw acc= 72.8% |
| Epoch  51, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.810, TAw acc= 72.7% | Valid: time=  0.5s loss=0.842, TAw acc= 73.4% |
| Epoch  52, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 72.2% | Valid: time=  0.5s loss=0.829, TAw acc= 74.2% |
| Epoch  53, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.827, TAw acc= 71.6% | Valid: time=  0.5s loss=0.843, TAw acc= 73.2% |
| Epoch  54, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.814, TAw acc= 72.3% | Valid: time=  0.5s loss=0.821, TAw acc= 74.6% |
| Epoch  55, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.833, TAw acc= 71.3% | Valid: time=  0.5s loss=0.833, TAw acc= 75.4% |
| Epoch  56, lr=2.6e-02 time=  1.2s/  2.1s | Train: loss=0.818, TAw acc= 72.7% | Valid: time=  0.5s loss=0.834, TAw acc= 72.6% |
| Epoch  57, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.8% | Valid: time=  0.5s loss=0.814, TAw acc= 75.4% |
| Epoch  58, lr=2.6e-02 time=  1.4s/  1.5s | Train: loss=0.806, TAw acc= 72.1% | Valid: time=  0.4s loss=0.786, TAw acc= 74.2% |
| Epoch  59, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.796, TAw acc= 72.5% | Valid: time=  0.5s loss=0.857, TAw acc= 73.6% |
| Epoch  60, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 71.7% | Valid: time=  0.5s loss=0.834, TAw acc= 74.6% |
| Epoch  61, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 71.9% | Valid: time=  0.5s loss=0.825, TAw acc= 74.2% |
| Epoch  62, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.801, TAw acc= 72.8% | Valid: time=  0.5s loss=0.799, TAw acc= 75.2% |
| Epoch  63, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.5% | Valid: time=  0.5s loss=0.843, TAw acc= 74.8% |
| Epoch  64, lr=2.6e-02 time=  1.3s/  2.1s | Train: loss=0.813, TAw acc= 72.3% | Valid: time=  0.5s loss=0.921, TAw acc= 71.4% |
| Epoch  65, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.797, TAw acc= 72.3% | Valid: time=  0.5s loss=0.967, TAw acc= 72.0% |
| Epoch  66, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.792, TAw acc= 73.4% | Valid: time=  0.5s loss=0.854, TAw acc= 73.8% |
| Epoch  67, lr=2.6e-02 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 72.6% | Valid: time=  0.5s loss=0.899, TAw acc= 73.2% | lr=8.8e-03
| Epoch  68, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 72.2% | Valid: time=  0.5s loss=0.819, TAw acc= 73.0% |
| Epoch  69, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 72.0% | Valid: time=  0.5s loss=0.771, TAw acc= 74.6% |
| Epoch  70, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 73.0% | Valid: time=  0.5s loss=0.814, TAw acc= 73.6% |
| Epoch  71, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.819, TAw acc= 72.5% | Valid: time=  0.5s loss=0.814, TAw acc= 73.4% |
| Epoch  72, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.811, TAw acc= 72.7% | Valid: time=  0.5s loss=0.774, TAw acc= 74.4% |
| Epoch  73, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.835, TAw acc= 71.3% | Valid: time=  0.5s loss=0.818, TAw acc= 75.6% |
| Epoch  74, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.816, TAw acc= 71.7% | Valid: time=  0.5s loss=0.801, TAw acc= 74.4% |
| Epoch  75, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.810, TAw acc= 72.7% | Valid: time=  0.5s loss=0.795, TAw acc= 74.4% |
| Epoch  76, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 72.8% | Valid: time=  0.5s loss=0.769, TAw acc= 74.6% |
| Epoch  77, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.804, TAw acc= 72.2% | Valid: time=  0.4s loss=0.819, TAw acc= 73.2% |
| Epoch  78, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.822, TAw acc= 72.4% | Valid: time=  0.5s loss=0.774, TAw acc= 73.4% |
| Epoch  79, lr=8.8e-03 time=  1.4s/  2.2s | Train: loss=0.812, TAw acc= 72.2% | Valid: time=  0.5s loss=0.816, TAw acc= 74.4% |
| Epoch  80, lr=8.8e-03 time=  1.3s/  2.2s | Train: loss=0.804, TAw acc= 72.4% | Valid: time=  0.4s loss=0.780, TAw acc= 73.6% |
| Epoch  81, lr=8.8e-03 time=  1.2s/  1.5s | Train: loss=0.787, TAw acc= 73.0% | Valid: time=  0.4s loss=0.817, TAw acc= 73.0% |
| Epoch  82, lr=8.8e-03 time=  1.3s/  2.1s | Train: loss=0.801, TAw acc= 73.4% | Valid: time=  0.5s loss=0.784, TAw acc= 74.6% |
| Epoch  83, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.793, TAw acc= 73.1% | Valid: time=  0.4s loss=0.794, TAw acc= 74.4% |
| Epoch  84, lr=8.8e-03 time=  1.3s/  2.4s | Train: loss=0.793, TAw acc= 72.9% | Valid: time=  0.5s loss=0.807, TAw acc= 73.4% |
| Epoch  85, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.801, TAw acc= 72.9% | Valid: time=  0.5s loss=0.784, TAw acc= 74.0% |
| Epoch  86, lr=8.8e-03 time=  1.2s/  2.3s | Train: loss=0.810, TAw acc= 72.4% | Valid: time=  0.5s loss=0.789, TAw acc= 73.6% |
| Epoch  87, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.773, TAw acc= 74.8% | Valid: time=  0.4s loss=0.779, TAw acc= 73.4% |
| Epoch  88, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.9% | Valid: time=  0.5s loss=0.791, TAw acc= 73.6% |
| Epoch  89, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.795, TAw acc= 73.1% | Valid: time=  0.5s loss=0.810, TAw acc= 73.4% |
| Epoch  90, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.786, TAw acc= 73.7% | Valid: time=  0.5s loss=0.827, TAw acc= 73.0% |
| Epoch  91, lr=8.8e-03 time=  1.4s/  2.3s | Train: loss=0.803, TAw acc= 72.9% | Valid: time=  0.5s loss=0.805, TAw acc= 73.8% |
| Epoch  92, lr=8.8e-03 time=  1.3s/  2.3s | Train: loss=0.774, TAw acc= 73.2% | Valid: time=  0.5s loss=0.772, TAw acc= 74.0% |
| Epoch  93, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 72.9% | Valid: time=  0.5s loss=0.796, TAw acc= 74.0% |
| Epoch  94, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.789, TAw acc= 72.5% | Valid: time=  0.5s loss=0.759, TAw acc= 73.8% |
| Epoch  95, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.773, TAw acc= 73.0% | Valid: time=  0.5s loss=0.781, TAw acc= 73.2% |
| Epoch  96, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.781, TAw acc= 73.5% | Valid: time=  0.5s loss=0.780, TAw acc= 74.8% |
| Epoch  97, lr=8.8e-03 time=  1.4s/  2.4s | Train: loss=0.783, TAw acc= 73.4% | Valid: time=  0.5s loss=0.806, TAw acc= 73.4% | lr=2.9e-03
| Epoch  98, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.842, TAw acc= 70.7% | Valid: time=  0.5s loss=0.795, TAw acc= 73.8% |
| Epoch  99, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.824, TAw acc= 72.0% | Valid: time=  0.5s loss=0.772, TAw acc= 74.2% |
| Epoch 100, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.820, TAw acc= 72.6% | Valid: time=  0.5s loss=0.776, TAw acc= 75.0% |
| Epoch 101, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.833, TAw acc= 71.8% | Valid: time=  0.5s loss=0.788, TAw acc= 74.0% |
| Epoch 102, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.822, TAw acc= 72.2% | Valid: time=  0.5s loss=0.782, TAw acc= 73.8% |
| Epoch 103, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 72.0% | Valid: time=  0.5s loss=0.788, TAw acc= 73.8% |
| Epoch 104, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.811, TAw acc= 72.7% | Valid: time=  0.4s loss=0.782, TAw acc= 74.2% |
| Epoch 105, lr=2.9e-03 time=  1.2s/  2.2s | Train: loss=0.792, TAw acc= 73.6% | Valid: time=  0.4s loss=0.771, TAw acc= 73.8% |
| Epoch 106, lr=2.9e-03 time=  1.3s/  2.3s | Train: loss=0.807, TAw acc= 72.5% | Valid: time=  0.5s loss=0.786, TAw acc= 73.6% |
| Epoch 107, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.800, TAw acc= 73.1% | Valid: time=  0.5s loss=0.784, TAw acc= 73.4% |
| Epoch 108, lr=2.9e-03 time=  1.3s/  2.4s | Train: loss=0.796, TAw acc= 72.9% | Valid: time=  0.5s loss=0.800, TAw acc= 73.2% |
| Epoch 109, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.7% | Valid: time=  0.5s loss=0.788, TAw acc= 73.2% |
| Epoch 110, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 72.6% | Valid: time=  0.5s loss=0.802, TAw acc= 72.6% |
| Epoch 111, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.795, TAw acc= 73.4% | Valid: time=  0.5s loss=0.806, TAw acc= 73.2% |
| Epoch 112, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 73.2% | Valid: time=  0.5s loss=0.776, TAw acc= 73.4% |
| Epoch 113, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.3% | Valid: time=  0.5s loss=0.783, TAw acc= 73.2% |
| Epoch 114, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.803, TAw acc= 72.5% | Valid: time=  0.5s loss=0.795, TAw acc= 73.0% |
| Epoch 115, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 72.1% | Valid: time=  0.5s loss=0.790, TAw acc= 73.0% |
| Epoch 116, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.783, TAw acc= 73.7% | Valid: time=  0.5s loss=0.782, TAw acc= 73.2% |
| Epoch 117, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.794, TAw acc= 73.2% | Valid: time=  0.5s loss=0.797, TAw acc= 73.4% |
| Epoch 118, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.808, TAw acc= 72.4% | Valid: time=  0.5s loss=0.798, TAw acc= 73.6% |
| Epoch 119, lr=2.9e-03 time=  1.2s/  2.1s | Train: loss=0.790, TAw acc= 73.9% | Valid: time=  0.5s loss=0.780, TAw acc= 74.2% |
| Epoch 120, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.793, TAw acc= 73.3% | Valid: time=  0.5s loss=0.789, TAw acc= 73.2% |
| Epoch 121, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.806, TAw acc= 72.9% | Valid: time=  0.5s loss=0.801, TAw acc= 73.0% |
| Epoch 122, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.800, TAw acc= 73.9% | Valid: time=  0.5s loss=0.780, TAw acc= 73.2% |
| Epoch 123, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.802, TAw acc= 72.8% | Valid: time=  0.5s loss=0.790, TAw acc= 73.6% |
| Epoch 124, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.784, TAw acc= 73.8% | Valid: time=  0.5s loss=0.790, TAw acc= 73.2% |
| Epoch 125, lr=2.9e-03 time=  1.4s/  2.2s | Train: loss=0.801, TAw acc= 72.7% | Valid: time=  0.5s loss=0.784, TAw acc= 74.0% |
| Epoch 126, lr=2.9e-03 time=  1.3s/  2.2s | Train: loss=0.791, TAw acc= 73.8% | Valid: time=  0.5s loss=0.790, TAw acc= 73.8% |
| Epoch 127, lr=2.9e-03 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 72.8% | Valid: time=  0.5s loss=0.798, TAw acc= 73.0% | lr=9.7e-04
| Epoch 128, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.845, TAw acc= 70.4% | Valid: time=  0.5s loss=0.767, TAw acc= 74.2% |
| Epoch 129, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.830, TAw acc= 71.7% | Valid: time=  0.5s loss=0.777, TAw acc= 73.4% |
| Epoch 130, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.836, TAw acc= 71.8% | Valid: time=  0.5s loss=0.782, TAw acc= 73.4% |
| Epoch 131, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.832, TAw acc= 71.4% | Valid: time=  0.5s loss=0.779, TAw acc= 73.8% |
| Epoch 132, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.826, TAw acc= 71.8% | Valid: time=  0.5s loss=0.777, TAw acc= 73.6% |
| Epoch 133, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.818, TAw acc= 72.2% | Valid: time=  0.5s loss=0.783, TAw acc= 73.6% |
| Epoch 134, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.840, TAw acc= 71.6% | Valid: time=  0.5s loss=0.784, TAw acc= 74.0% |
| Epoch 135, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.833, TAw acc= 71.8% | Valid: time=  0.5s loss=0.786, TAw acc= 73.8% |
| Epoch 136, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 71.8% | Valid: time=  0.5s loss=0.786, TAw acc= 73.6% |
| Epoch 137, lr=9.7e-04 time=  1.4s/  1.9s | Train: loss=0.829, TAw acc= 72.0% | Valid: time=  0.4s loss=0.785, TAw acc= 73.4% |
| Epoch 138, lr=9.7e-04 time=  1.1s/  2.3s | Train: loss=0.812, TAw acc= 72.2% | Valid: time=  0.5s loss=0.783, TAw acc= 74.0% |
| Epoch 139, lr=9.7e-04 time=  1.3s/  2.4s | Train: loss=0.813, TAw acc= 72.8% | Valid: time=  0.5s loss=0.784, TAw acc= 73.6% |
| Epoch 140, lr=9.7e-04 time=  1.2s/  2.4s | Train: loss=0.819, TAw acc= 72.4% | Valid: time=  0.4s loss=0.780, TAw acc= 73.8% |
| Epoch 141, lr=9.7e-04 time=  1.4s/  1.7s | Train: loss=0.817, TAw acc= 71.8% | Valid: time=  0.4s loss=0.782, TAw acc= 74.2% |
| Epoch 142, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 72.7% | Valid: time=  0.5s loss=0.782, TAw acc= 73.6% |
| Epoch 143, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.804, TAw acc= 72.7% | Valid: time=  0.5s loss=0.787, TAw acc= 74.2% |
| Epoch 144, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.820, TAw acc= 71.7% | Valid: time=  0.5s loss=0.788, TAw acc= 74.2% |
| Epoch 145, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 71.5% | Valid: time=  0.5s loss=0.788, TAw acc= 74.0% |
| Epoch 146, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.823, TAw acc= 71.9% | Valid: time=  0.5s loss=0.791, TAw acc= 73.6% |
| Epoch 147, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 72.2% | Valid: time=  0.5s loss=0.792, TAw acc= 73.6% |
| Epoch 148, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.798, TAw acc= 73.3% | Valid: time=  0.5s loss=0.783, TAw acc= 73.8% |
| Epoch 149, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.810, TAw acc= 72.8% | Valid: time=  0.5s loss=0.781, TAw acc= 74.0% |
| Epoch 150, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.824, TAw acc= 72.5% | Valid: time=  0.5s loss=0.786, TAw acc= 74.0% |
| Epoch 151, lr=9.7e-04 time=  1.4s/  2.4s | Train: loss=0.822, TAw acc= 72.2% | Valid: time=  0.5s loss=0.783, TAw acc= 73.8% |
| Epoch 152, lr=9.7e-04 time=  1.4s/  2.3s | Train: loss=0.804, TAw acc= 72.5% | Valid: time=  0.5s loss=0.791, TAw acc= 73.6% |
| Epoch 153, lr=9.7e-04 time=  1.4s/  2.2s | Train: loss=0.815, TAw acc= 72.2% | Valid: time=  0.5s loss=0.790, TAw acc= 73.6% |
| Epoch 154, lr=9.7e-04 time=  1.4s/  2.1s | Train: loss=0.818, TAw acc= 72.8% | Valid: time=  0.4s loss=0.789, TAw acc= 74.0% |
| Epoch 155, lr=9.7e-04 time=  1.2s/  2.0s | Train: loss=0.778, TAw acc= 74.1% | Valid: time=  0.5s loss=0.782, TAw acc= 74.2% |
| Epoch 156, lr=9.7e-04 time=  1.2s/  2.3s | Train: loss=0.801, TAw acc= 73.6% | Valid: time=  0.5s loss=0.788, TAw acc= 74.0% |
| Epoch 157, lr=9.7e-04 time=  1.4s/  1.9s | Train: loss=0.805, TAw acc= 72.4% | Valid: time=  0.4s loss=0.785, TAw acc= 73.8% | lr=3.2e-04
| Epoch 158, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.847, TAw acc= 71.6% | Valid: time=  0.5s loss=0.751, TAw acc= 74.2% |
| Epoch 159, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.831, TAw acc= 71.4% | Valid: time=  0.5s loss=0.760, TAw acc= 74.2% |
| Epoch 160, lr=3.2e-04 time=  1.3s/  2.3s | Train: loss=0.824, TAw acc= 72.2% | Valid: time=  0.5s loss=0.769, TAw acc= 74.0% |
| Epoch 161, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.835, TAw acc= 72.0% | Valid: time=  0.5s loss=0.777, TAw acc= 73.4% |
| Epoch 162, lr=3.2e-04 time=  1.3s/  2.0s | Train: loss=0.837, TAw acc= 71.5% | Valid: time=  0.5s loss=0.780, TAw acc= 73.4% |
| Epoch 163, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.820, TAw acc= 72.1% | Valid: time=  0.5s loss=0.782, TAw acc= 73.4% |
| Epoch 164, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.835, TAw acc= 72.3% | Valid: time=  0.5s loss=0.786, TAw acc= 73.6% |
| Epoch 165, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.830, TAw acc= 71.8% | Valid: time=  0.5s loss=0.786, TAw acc= 73.6% |
| Epoch 166, lr=3.2e-04 time=  1.4s/  1.7s | Train: loss=0.826, TAw acc= 71.8% | Valid: time=  0.4s loss=0.788, TAw acc= 73.4% |
| Epoch 167, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.830, TAw acc= 71.4% | Valid: time=  0.5s loss=0.788, TAw acc= 73.4% |
| Epoch 168, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.832, TAw acc= 72.1% | Valid: time=  0.5s loss=0.785, TAw acc= 73.4% |
| Epoch 169, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.809, TAw acc= 72.3% | Valid: time=  0.5s loss=0.783, TAw acc= 73.4% |
| Epoch 170, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.828, TAw acc= 72.5% | Valid: time=  0.5s loss=0.783, TAw acc= 73.4% |
| Epoch 171, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.836, TAw acc= 71.6% | Valid: time=  0.5s loss=0.782, TAw acc= 73.6% |
| Epoch 172, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.832, TAw acc= 71.9% | Valid: time=  0.5s loss=0.783, TAw acc= 73.4% |
| Epoch 173, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 72.5% | Valid: time=  0.4s loss=0.782, TAw acc= 73.4% |
| Epoch 174, lr=3.2e-04 time=  1.4s/  1.9s | Train: loss=0.819, TAw acc= 72.7% | Valid: time=  0.4s loss=0.787, TAw acc= 73.4% |
| Epoch 175, lr=3.2e-04 time=  1.3s/  2.4s | Train: loss=0.826, TAw acc= 71.9% | Valid: time=  0.4s loss=0.786, TAw acc= 73.4% |
| Epoch 176, lr=3.2e-04 time=  1.2s/  2.0s | Train: loss=0.823, TAw acc= 72.0% | Valid: time=  0.5s loss=0.784, TAw acc= 73.4% |
| Epoch 177, lr=3.2e-04 time=  1.4s/  2.3s | Train: loss=0.817, TAw acc= 72.4% | Valid: time=  0.4s loss=0.785, TAw acc= 74.0% |
| Epoch 178, lr=3.2e-04 time=  1.4s/  2.1s | Train: loss=0.832, TAw acc= 71.9% | Valid: time=  0.5s loss=0.786, TAw acc= 73.4% |
| Epoch 179, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.7% | Valid: time=  0.5s loss=0.786, TAw acc= 73.6% |
| Epoch 180, lr=3.2e-04 time=  1.2s/  2.4s | Train: loss=0.829, TAw acc= 71.2% | Valid: time=  0.5s loss=0.784, TAw acc= 73.6% |
| Epoch 181, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.824, TAw acc= 72.1% | Valid: time=  0.5s loss=0.782, TAw acc= 73.6% |
| Epoch 182, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.812, TAw acc= 72.8% | Valid: time=  0.5s loss=0.781, TAw acc= 73.6% |
| Epoch 183, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.818, TAw acc= 72.7% | Valid: time=  0.5s loss=0.780, TAw acc= 73.8% |
| Epoch 184, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.817, TAw acc= 72.0% | Valid: time=  0.5s loss=0.780, TAw acc= 73.8% |
| Epoch 185, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.806, TAw acc= 73.2% | Valid: time=  0.5s loss=0.781, TAw acc= 73.4% |
| Epoch 186, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.813, TAw acc= 72.4% | Valid: time=  0.5s loss=0.781, TAw acc= 73.2% |
| Epoch 187, lr=3.2e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 72.6% | Valid: time=  0.5s loss=0.780, TAw acc= 73.6% | lr=1.1e-04
| Epoch 188, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.843, TAw acc= 71.0% | Valid: time=  0.5s loss=0.746, TAw acc= 74.4% |
| Epoch 189, lr=1.1e-04 time=  1.4s/  2.0s | Train: loss=0.846, TAw acc= 71.2% | Valid: time=  0.4s loss=0.749, TAw acc= 74.4% |
| Epoch 190, lr=1.1e-04 time=  1.4s/  1.9s | Train: loss=0.829, TAw acc= 71.2% | Valid: time=  0.3s loss=0.751, TAw acc= 74.4% |
| Epoch 191, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.846, TAw acc= 71.4% | Valid: time=  0.5s loss=0.754, TAw acc= 74.4% |
| Epoch 192, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.845, TAw acc= 71.6% | Valid: time=  0.5s loss=0.757, TAw acc= 74.4% |
| Epoch 193, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.838, TAw acc= 71.2% | Valid: time=  0.5s loss=0.760, TAw acc= 74.2% |
| Epoch 194, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.838, TAw acc= 72.1% | Valid: time=  0.5s loss=0.763, TAw acc= 74.2% |
| Epoch 195, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.826, TAw acc= 71.9% | Valid: time=  0.5s loss=0.765, TAw acc= 74.2% |
| Epoch 196, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.835, TAw acc= 71.0% | Valid: time=  0.5s loss=0.767, TAw acc= 74.0% |
| Epoch 197, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.816, TAw acc= 72.2% | Valid: time=  0.5s loss=0.769, TAw acc= 73.8% |
| Epoch 198, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.841, TAw acc= 71.5% | Valid: time=  0.5s loss=0.770, TAw acc= 73.8% |
| Epoch 199, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.835, TAw acc= 71.7% | Valid: time=  0.5s loss=0.772, TAw acc= 73.6% |
| Epoch 200, lr=1.1e-04 time=  1.4s/  2.4s | Train: loss=0.821, TAw acc= 72.6% | Valid: time=  0.5s loss=0.774, TAw acc= 73.4% |
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.803 | TAw acc= 73.4%, forg=  6.8%| TAg acc= 19.4%, forg= 60.8% <<<
>>> Test on task  1 : loss=1.118 | TAw acc= 63.2%, forg=  5.8%| TAg acc= 12.8%, forg= 37.2% <<<
>>> Test on task  2 : loss=0.773 | TAw acc= 75.9%, forg=  6.2%| TAg acc= 28.2%, forg= 36.1% <<<
>>> Test on task  3 : loss=0.755 | TAw acc= 74.9%, forg=  6.7%| TAg acc= 14.6%, forg= 28.3% <<<
>>> Test on task  4 : loss=0.637 | TAw acc= 81.2%, forg=  6.0%| TAg acc= 33.7%, forg= 25.5% <<<
>>> Test on task  5 : loss=0.891 | TAw acc= 67.5%, forg=  5.8%| TAg acc= 16.8%, forg= 15.9% <<<
>>> Test on task  6 : loss=0.768 | TAw acc= 75.0%, forg=  7.5%| TAg acc= 22.7%, forg= 26.1% <<<
>>> Test on task  7 : loss=0.743 | TAw acc= 76.5%, forg=  3.3%| TAg acc= 27.3%, forg= 13.1% <<<
>>> Test on task  8 : loss=0.804 | TAw acc= 76.3%, forg=  4.0%| TAg acc= 40.7%, forg=  8.9% <<<
>>> Test on task  9 : loss=0.770 | TAw acc= 75.2%, forg=  0.0%| TAg acc= 37.7%, forg=  0.0% <<<
Save at ../RESULT_AAAI2026/CR10/0/cifar100_finetuning
************************************************************************************************************
TAw Acc
	 80.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 80.2% 
	 79.4%  69.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 74.2% 
	 78.4%  64.5%  82.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 75.0% 
	 77.5%  66.8%  81.8%  81.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 76.9% 
	 74.2%  63.6%  80.5%  78.9%  87.2%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 76.9% 
	 75.3%  63.3%  80.4%  76.3%  85.4%  73.3%   0.0%   0.0%   0.0%   0.0% 	Avg.: 75.7% 
	 75.3%  64.9%  79.4%  75.5%  85.3%  71.4%  82.5%   0.0%   0.0%   0.0% 	Avg.: 76.3% 
	 74.5%  63.7%  77.8%  76.0%  83.5%  69.0%  80.0%  79.8%   0.0%   0.0% 	Avg.: 75.5% 
	 73.2%  62.2%  76.9%  75.2%  83.1%  68.9%  76.6%  77.1%  80.3%   0.0% 	Avg.: 74.8% 
	 73.4%  63.2%  75.9%  74.9%  81.2%  67.5%  75.0%  76.5%  76.3%  75.2% 	Avg.: 73.9% 
************************************************************************************************************
TAg Acc
	 80.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 80.2% 
	 65.9%  50.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 58.0% 
	 54.0%  32.3%  64.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 50.2% 
	 42.0%  25.6%  56.5%  42.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 41.8% 
	 37.3%  18.5%  46.3%  31.8%  59.2%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 38.6% 
	 34.5%  18.6%  37.0%  25.4%  53.8%  32.7%   0.0%   0.0%   0.0%   0.0% 	Avg.: 33.7% 
	 32.7%  19.4%  34.8%  20.6%  53.7%  22.2%  48.8%   0.0%   0.0%   0.0% 	Avg.: 33.2% 
	 27.1%  15.1%  32.4%  20.4%  44.5%  17.3%  39.2%  40.4%   0.0%   0.0% 	Avg.: 29.6% 
	 23.9%  15.0%  31.1%  16.1%  37.7%  19.3%  26.9%  29.8%  49.6%   0.0% 	Avg.: 27.7% 
	 19.4%  12.8%  28.2%  14.6%  33.7%  16.8%  22.7%  27.3%  40.7%  37.7% 	Avg.: 25.4% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	  0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.8% 
	  1.8%   4.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.1% 
	  2.7%   2.2%   0.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.7% 
	  6.0%   5.4%   1.6%   2.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.9% 
	  4.9%   5.7%   1.7%   5.3%   1.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.9% 
	  4.9%   4.1%   2.7%   6.1%   1.9%   1.9%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.6% 
	  5.7%   5.3%   4.3%   5.6%   3.7%   4.3%   2.5%   0.0%   0.0%   0.0% 	Avg.:  4.5% 
	  7.0%   6.8%   5.2%   6.4%   4.1%   4.4%   5.9%   2.7%   0.0%   0.0% 	Avg.:  5.3% 
	  6.8%   5.8%   6.2%   6.7%   6.0%   5.8%   7.5%   3.3%   4.0%   0.0% 	Avg.:  5.8% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	 14.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 14.3% 
	 26.2%  17.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 21.9% 
	 38.2%  24.4%   7.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 23.5% 
	 42.9%  31.5%  18.0%  11.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 25.9% 
	 45.7%  31.4%  27.3%  17.5%   5.4%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 25.5% 
	 47.5%  30.6%  29.5%  22.3%   5.5%  10.5%   0.0%   0.0%   0.0%   0.0% 	Avg.: 24.3% 
	 53.1%  34.9%  31.9%  22.5%  14.7%  15.4%   9.6%   0.0%   0.0%   0.0% 	Avg.: 26.0% 
	 56.3%  35.0%  33.2%  26.8%  21.5%  13.4%  21.9%  10.6%   0.0%   0.0% 	Avg.: 27.3% 
	 60.8%  37.2%  36.1%  28.3%  25.5%  15.9%  26.1%  13.1%   8.9%   0.0% 	Avg.: 28.0% 
************************************************************************************************************
[Elapsed time = 2.2 h]
Done!
