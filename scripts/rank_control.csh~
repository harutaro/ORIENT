#!/bin/csh -f

# Usage:
#   aaai2025.csh
#	--approach { joint | finetuning | ewc | path_integral | sow | supsup | wsn | hat }
#	--dataset { cifar100 | tiny-imagenet-200 }
#	--network { alexnet_32 | resnet50_32 | alexnet_32sow | resnet50_32sow | alexnet_32supsup | resnet50_32supsup | alexnet_32wsn | resnet50_32wsn}
#	--tasks { 10 | 20 }
#	--seed { 0 | 1 | 2 }
#	--gpu { 0 | 1 | 2 | ... }
#

unsetenv LANG
# Set RESULT_TOP & FACIL_DIR
set RESULT_TOP = '../RESULT_AAAI2025'
set FACIL_DIR = '..'

set i = 1
while($i <= $#argv)
    switch($argv[$i])
	case --dataset :
	    @ i ++
	    set dataset = $argv[$i]
	    if (($dataset != 'cifar100') && ($dataset != 'tiny-imagenet-200')) then
		echo $dataset is N/A
		exit
	    endif
	breaksw
	case --network :
	    @ i ++
	    set network = $argv[$i]
	    if (($approach != 'sow' && $approach != 'supsup' && $approach != 'wsn') && ($network != 'alexnet_32') && ($network != 'resnet50_32')) then
		echo $network is N/A for $approach
		exit
	    endif
	    if (($approach == 'sow') && ($network != 'alexnet_32sow') && ($network != 'resnet50_32sow')) then
		echo $network is N/A for $approach
		exit
	    endif
	    if (($approach == 'supsup') && ($network != 'alexnet_32supsup') && ($network != 'resnet50_32supsup')) then
		echo $network is N/A for $approach
		exit
	    endif
	    if (($approach == 'wsn') && ($network != 'alexnet_32wsn') && ($network != 'resnet50_32wsn')) then
		echo $network is N/A for $approach
		exit
	    endif
	breaksw
	case --tasks :
	    @ i ++
	    set tasks = $argv[$i]
	    if (($tasks != '1') && ($tasks != '10') && ($tasks != '20')) then
		echo tasks \({$tasks}\) is N/A
		exit
	    endif
	breaksw
	case --seed :
	    @ i ++
	    set seed = $argv[$i]
	    if (($seed != '0') && ($seed != '1') && ($seed != '2')) then
		echo -- seed ${seed} is N/A
		exit
	    endif
	breaksw
	case --approach :
	    @ i ++
	    set approach = $argv[$i]
	breaksw
	case --gpu :
	    @ i ++
	    set gpu = $argv[$i]
	    if (!(($gpu > -1) && ($gpu < 8))) then
		echo --gpu ${gpu} is N/A
		exit
	    endif
	breaksw
	default :
	    exit
        breaksw
    endsw
    @ i ++
end
if (($dataset == 'cifar100') && (($network == 'alexnet_32') || ($network == 'alexnet_32sow') || ($network == 'alexnet_32supsup') || ($network == 'alexnet_32wsn'))) then
    set PRETRAINED_PATH = '../Conv-Model/AlexNet32-TinyImageNet.pt'
    set lr = 0.0533650667424485
    set dropout = '0.4994406633065671 0.45738857436755226'
    set OUTPUT_DIR = ${RESULT_TOP}/CA${tasks}/${seed}
endif
if (($dataset == 'cifar100') && (($network == 'resnet50_32') || ($network == 'resnet50_32sow') || ($network == 'resnet50_32supsup') || ($network == 'resnet50_32wsn'))) then
    set PRETRAINED_PATH = '../Conv-Model/ResNet50-TinyImageNet.pt'
    set lr = 0.0263039750973134
    set dropout = '0.417598542370663'
    set OUTPUT_DIR = ${RESULT_TOP}/CR${tasks}/${seed}
endif
if (($dataset == 'tiny-imagenet-200') && (($network == 'alexnet_32') || ($network == 'alexnet_32sow') || ($network == 'alexnet_32supsup') || ($network == 'alexnet_32wsn'))) then
    set PRETRAINED_PATH = '../Conv-Model/AlexNet32-CIFAR100.pt'
    set lr = 0.0820981082098968
    set dropout = '0.44038714776548993 0.4561583460665354'
    set OUTPUT_DIR = ${RESULT_TOP}/TA${tasks}/${seed}
endif
if (($dataset == 'tiny-imagenet-200') && (($network == 'resnet50_32') || ($network == 'resnet50_32sow') || ($network == 'resnet50_32supsup') || ($network == 'resnet50_32wsn'))) then
    set PRETRAINED_PATH = '../Conv-Model/ResNet50-CIFAR100.pt'
    set lr = 0.0251064769261627
    set dropout = '0.398415120026451'
    set OUTPUT_DIR = ${RESULT_TOP}/TR${tasks}/${seed}
endif
echo 'run:' ${dataset} ${network} ${tasks} ${seed} ${approach} ${PRETRAINED_PATH} ${dropout} ${OUTPUT_DIR} ${gpu}

set nepochs=200
set batch_size=64
set stop_at_task=0
set validation=0.1
set lr_min=0.00001
set lr_factor=3
set lr_patience=30
set clipping=1.0
set momentum=0.9
set weight_decay=0.0

set sow_lr = 0.0263039750973134
set sow_mo = 0.90
set loss_margin = 0.006
set acc_margin = 0.004

switch($approach)
    case sow :
	python ${FACIL_DIR}/src/rank_control.py \
	    --approach $approach --network $network --datasets $dataset \
	    --num-tasks $tasks --stop-at-task $stop_at_task \
	    --gpu ${gpu} --seed ${seed} \
	    --pin-memory --save-models --eval-on-train \
	    --nepochs $nepochs --batch-size $batch_size --multi-softmax --fix-bn \
	    --lr $lr --lr-min $lr_min --lr-factor $lr_factor --lr-patience $lr_patience \
	    --momentum $momentum --weight-decay $weight_decay --validation $validation \
	    --clipping $clipping --dropout $dropout \
	    --pretrained-path $PRETRAINED_PATH --load-features --fix-features \
	    --results-path ${OUTPUT_DIR} \
	    --sow-lr $sow_lr --sow-mo $sow_mo \
	    --loss-margin $loss_margin --acc-margin $acc_margin
    breaksw
    default :
	python ${FACIL_DIR}/src/main_incremental.py \
	    --approach $approach --network $network --datasets $dataset \
	    --num-tasks $tasks --stop-at-task $stop_at_task \
	    --gpu ${gpu} --seed ${seed} \
	    --pin-memory --save-models --eval-on-train \
	    --nepochs $nepochs --batch-size $batch_size --multi-softmax --fix-bn \
	    --lr $lr --lr-min $lr_min --lr-factor $lr_factor --lr-patience $lr_patience \
	    --momentum $momentum --weight-decay $weight_decay --validation $validation \
	    --clipping $clipping --dropout $dropout \
	    --pretrained-path $PRETRAINED_PATH --load-features --fix-features \
	    --results-path ${OUTPUT_DIR}
    breaksw
endsw
exit
